"[{\"title\":\"Hierarchical Bayesian inference in the visual cortex\",\"year\":\"2003\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Tai Sing\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Mumford\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Traditional views of visual processing suggest that early visual neurons in areas V1 and V2 are static spatiotemporal filters that extract local features from a visual scene. The extracted information is then channeled through a feedforward chain of modules in successively higher visual areas for further analysis. Recent electrophysiological recordings from early visual neurons in awake behaving monkeys reveal that there are many levels of complexity in the information processing of the early visual cortex, as seen in the long-latency responses of its neurons. These new findings suggest that activity in the early visual cortex is tightly coupled and highly interactive with the rest of the visual system. They lead us to propose a new theoretical setting based on the mathematical framework of hierarchical Bayesian inference for reasoning about the visual system. In this framework, the recurrent feedforward\\/feedback loops in the cortex serve to integrate top-down contextual priors and bottom-up observations so as to implement concurrent probabilistic inference along the visual hierarchy. We suggest that the algorithms of particle filtering and Bayesian-belief propagation might model these interactive cortical computations. We review some recent neurophysiological evidences that support the plausibility of these ideas.\",\"publicationTitle\":\"JOSA A\"},{\"title\":\"Improved Conditional VRNNs for Video Prediction\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Lluis\",\"lastName\":\"Castrejon\"},{\"creatorType\":\"author\",\"firstName\":\"Nicolas\",\"lastName\":\"Ballas\"},{\"creatorType\":\"author\",\"firstName\":\"Aaron\",\"lastName\":\"Courville\"}],\"topic\":\"Variational Inference\",\"notes\":\"Predicting future frames for a video sequence is a challenging generative modeling task. Promising approaches include probabilistic latent variable models such as the Variational Auto-Encoder. While VAEs can handle uncertainty and model multiple possible future outcomes, they have a tendency to produce blurry predictions. In this work we argue that this is a sign of underfitting. To address this issue, we propose to increase the expressiveness of the latent distributions and to use higher capacity likelihood models. Our approach relies on a hierarchy of latent variables, which defines a family of flexible prior and posterior distributions in order to better model the probability of future sequences. We validate our proposal through a series of ablation experiments and compare our approach to current state-of-the-art latent variable models. Our method performs favorably under several metrics in three different datasets.\",\"publicationTitle\":\"arXiv:1904.12165 [cs]\"},{\"title\":\"Mouse Motor Cortex Coordinates the Behavioral Response to Unpredicted Sensory Feedback\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Matthias\",\"lastName\":\"Heindorf\"},{\"creatorType\":\"author\",\"firstName\":\"Silvia\",\"lastName\":\"Arber\"},{\"creatorType\":\"author\",\"firstName\":\"Georg B.\",\"lastName\":\"Keller\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Motor cortex (M1) lesions result in motor impairments, yet how M1 contributes to the control of movement remains controversial. To investigate the role of M1 in sensory guided motor coordination, we trained mice to navigate a virtual corridor using a spherical treadmill. This task required directional adjustments through spontaneous turning, while unexpected visual offset perturbations prompted induced turning. We found that M1 is essential for execution and learning of this visually guided task. Turn-selective layer 2\\/3 and layer 5 pyramidal tract (PT) neuron activation was shaped differentially with learning but scaled linearly with turn acceleration during spontaneous turns. During induced turns, however, layer 2\\/3 neurons were activated independent of behavioral response, while PT neurons still encoded behavioral response magnitude. Our results are consistent with a role of M1 in the detection of sensory perturbations that result in deviations from intended motor state and the initiation of an appropriate corrective response.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"A Recurrent Latent Variable Model for Sequential Data\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Junyoung\",\"lastName\":\"Chung\"},{\"creatorType\":\"author\",\"firstName\":\"Kyle\",\"lastName\":\"Kastner\"},{\"creatorType\":\"author\",\"firstName\":\"Laurent\",\"lastName\":\"Dinh\"},{\"creatorType\":\"author\",\"firstName\":\"Kratarth\",\"lastName\":\"Goel\"},{\"creatorType\":\"author\",\"firstName\":\"Aaron\",\"lastName\":\"Courville\"},{\"creatorType\":\"author\",\"firstName\":\"Yoshua\",\"lastName\":\"Bengio\"}],\"topic\":\"Variational Inference\",\"notes\":\"In this paper, we explore the inclusion of latent random variables into the dynamic hidden state of a recurrent neural network (RNN) by combining elements of the variational autoencoder. We argue that through the use of high-level latent random variables, the variational RNN (VRNN)1 can model the kind of variability observed in highly structured sequential data such as natural speech. We empirically evaluate the proposed model against related sequential models on four speech datasets and one handwriting dataset. Our results show the important roles that latent random variables can play in the RNN dynamic hidden state.\",\"publicationTitle\":\"arXiv:1506.02216 [cs]\"},{\"title\":\"Pruning of memories by context-based prediction error\",\"year\":\"2014\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Ghootae\",\"lastName\":\"Kim\"},{\"creatorType\":\"author\",\"firstName\":\"Jarrod A.\",\"lastName\":\"Lewis-Peacock\"},{\"creatorType\":\"author\",\"firstName\":\"Kenneth A.\",\"lastName\":\"Norman\"},{\"creatorType\":\"author\",\"firstName\":\"Nicholas B.\",\"lastName\":\"Turk-Browne\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The capacity of long-term memory is thought to be virtually unlimited. However, our memory bank may need to be pruned regularly to ensure that the information most important for behavior can be stored and accessed efficiently. Using functional magnetic resonance imaging of the human brain, we report the discovery of a context-based mechanism for determining which memories to prune. Specifically, when a previously experienced context is reencountered, the brain automatically generates predictions about which items should appear in that context. If an item fails to appear when strongly expected, its representation in memory is weakened, and it is more likely to be forgotten. We find robust support for this mechanism using multivariate pattern classification and pattern similarity analyses. The results are explained by a model in which context-based predictions activate item representations just enough for them to be weakened during a misprediction. These findings reveal an ongoing and adaptive process for pruning unreliable memories.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Mnemonic prediction errors bias hippocampal states\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Oded\",\"lastName\":\"Bein\"},{\"creatorType\":\"author\",\"firstName\":\"Katherine\",\"lastName\":\"Duncan\"},{\"creatorType\":\"author\",\"firstName\":\"Lila\",\"lastName\":\"Davachi\"}],\"topic\":\"Predictive Coding\",\"notes\":\"When our experience violates our predictions, it is adaptive to upregulate encoding of novel information, while down-weighting retrieval of erroneous memory predictions to promote an updated representation of the world. We asked whether mnemonic prediction errors promote hippocampal encoding versus retrieval states, as marked by distinct network connectivity between hippocampal subfields. During fMRI scanning, participants were cued to internally retrieve well-learned complex room-images and were then presented with either an identical or a modified image (0-4 changes). In the left hemisphere, we find that CA1-entorhinal connectivity increases, and CA1-CA3 connectivity decreases, with the number of changes. Further, in the left CA1, the similarity between activity patterns during cued-retrieval of the learned room and during the image is lower when the image includes changes, consistent with a prediction error signal in CA1. Our findings provide a mechanism by which mnemonic prediction errors may drive memory updating\\u2014by biasing hippocampal states.\",\"publicationTitle\":\"Nature Communications\"},{\"title\":\"Prediction Error and Memory Reactivation: How Incomplete Reminders Drive Reconsolidation\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Alyssa H.\",\"lastName\":\"Sinclair\"},{\"creatorType\":\"author\",\"firstName\":\"Morgan D.\",\"lastName\":\"Barense\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Memories are readily distorted. What conditions allow memories to be altered? Converging evidence implicates prediction error, or surprise, as a key mechanism that renders memories malleable. Recent reconsolidation studies have used incomplete reminders to elicit prediction error; retrieval cues that partially replicate an encoding experience allow memories to be distorted, updated, and strengthened. Here, we review diverse evidence that incomplete reminders govern human memory updating, ranging from classical conditioning to naturalistic episodes. Through the unifying theme of predictive coding, we discuss evidence from reconsolidation theory and nonmonotonic plasticity. We argue that both animal and human reconsolidation research can benefit from critically examining prediction error and incomplete reminders. These findings bear implications for pathological fear memories, false memories, misinformation, and education.\",\"publicationTitle\":\"Trends in Neurosciences\"},{\"title\":\"Shape perception reduces activity in human primary visual cortex\",\"year\":\"2002\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Scott O.\",\"lastName\":\"Murray\"},{\"creatorType\":\"author\",\"firstName\":\"Daniel\",\"lastName\":\"Kersten\"},{\"creatorType\":\"author\",\"firstName\":\"Bruno A.\",\"lastName\":\"Olshausen\"},{\"creatorType\":\"author\",\"firstName\":\"Paul\",\"lastName\":\"Schrater\"},{\"creatorType\":\"author\",\"firstName\":\"David L.\",\"lastName\":\"Woods\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Visual perception involves the grouping of individual elements into coherent patterns that reduce the descriptive complexity of a visual scene. The physiological basis of this perceptual simplification remains poorly understood. We used functional MRI to measure activity in a higher object processing area, the lateral occipital complex, and in primary visual cortex in response to visual elements that were either grouped into objects or randomly arranged. We observed significant activity increases in the lateral occipital complex and concurrent reductions of activity in primary visual cortex when elements formed coherent shapes, suggesting that activity in early visual areas is reduced as a result of grouping processes performed in higher areas. These findings are consistent with predictive coding models of vision that postulate that inferences of high-level areas are subtracted from incoming sensory information in lower areas through cortical feedback.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Functional Compartmentalization and Viewpoint Generalization Within the Macaque Face-Processing System\",\"year\":\"2010\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Winrich A.\",\"lastName\":\"Freiwald\"},{\"creatorType\":\"author\",\"firstName\":\"Doris Y.\",\"lastName\":\"Tsao\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Tuned for Faces\\nThe temporal lobe of macaques' brains contains six patches of face-selective cortex. This observation has prompted systems neuroscientists to ask, why so many and what do they do? Freiwald and Tsao (p. 845; see the Perspective by Connor) targeted four of these regions for single-unit recordings and found that the different face-selective patches in macaques have independent functions. The areas where earliest processing occurred were most sharply tuned for individual views and least sharply tuned for identity. The mid-level area was more sharply tuned for identity, and the highest processing stage was strongly tuned for identity in a strikingly view-invariant way. These results yield fundamental insights into the computational process of object recognition, the functional organization of the brain, and how representations are transformed through processing hierarchies.\\nPrimates can recognize faces across a range of viewing conditions. Representations of individual identity should thus exist that are invariant to accidental image transformations like view direction. We targeted the recently discovered face-processing network of the macaque monkey that consists of six interconnected face-selective regions and recorded from the two middle patches (ML, middle lateral, and MF, middle fundus) and two anterior patches (AL, anterior lateral, and AM, anterior medial). We found that the anatomical position of a face patch was associated with a unique functional identity: Face patches differed qualitatively in how they represented identity across head orientations. Neurons in ML and MF were view-specific; neurons in AL were tuned to identity mirror-symetrically across views, thus achieving partial view invariance; and neurons in AM, the most anterior face patch, achieved almost full view invariance.\\nRecognition of faces from different viewpoints involves several distinct stages of neural processing.\\nRecognition of faces from different viewpoints involves several distinct stages of neural processing.\",\"publicationTitle\":\"Science\"},{\"title\":\"A Cortical Region Consisting Entirely of Face-Selective Cells\",\"year\":\"2006\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Doris Y.\",\"lastName\":\"Tsao\"},{\"creatorType\":\"author\",\"firstName\":\"Winrich A.\",\"lastName\":\"Freiwald\"},{\"creatorType\":\"author\",\"firstName\":\"Roger B. H.\",\"lastName\":\"Tootell\"},{\"creatorType\":\"author\",\"firstName\":\"Margaret S.\",\"lastName\":\"Livingstone\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Face perception is a skill crucial to primates. In both humans and macaque monkeys, functional magnetic resonance imaging (fMRI) reveals a system of cortical regions that show increased blood flow when the subject views images of faces, compared with images of objects. However, the stimulus selectivity of single neurons within these fMRI-identified regions has not been studied. We used fMRI to identify and target the largest face-selective region in two macaques for single-unit recording. Almost all (97%) of the visually responsive neurons in this region were strongly face selective, indicating that a dedicated cortical area exists to support face processing in the macaque.\\nAll of the neurons within a discrete part of the cortex of the macaque monkey are activated exclusively by faces.\\nAll of the neurons within a discrete part of the cortex of the macaque monkey are activated exclusively by faces.\",\"publicationTitle\":\"Science\"},{\"title\":\"Neural dynamics at successive stages of the ventral visual stream are consistent with hierarchical error signals\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Elias B\",\"lastName\":\"Issa\"},{\"creatorType\":\"author\",\"firstName\":\"Charles F\",\"lastName\":\"Cadieu\"},{\"creatorType\":\"author\",\"firstName\":\"James J\",\"lastName\":\"DiCarlo\"},{\"creatorType\":\"editor\",\"firstName\":\"Ed\",\"lastName\":\"Connor\"},{\"creatorType\":\"editor\",\"firstName\":\"Eve\",\"lastName\":\"Marder\"},{\"creatorType\":\"editor\",\"firstName\":\"Ed\",\"lastName\":\"Connor\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Ventral visual stream neural responses are dynamic, even for static image presentations. However, dynamical neural models of visual cortex are lacking as most progress has been made modeling static, time-averaged responses. Here, we studied population neural dynamics during face detection across three cortical processing stages. Remarkably,~30 milliseconds after the initially evoked response, we found that neurons in intermediate level areas decreased their responses to typical configurations of their preferred face parts relative to their response for atypical configurations even while neurons in higher areas achieved and maintained a preference for typical configurations. These hierarchical neural dynamics were inconsistent with standard feedforward circuits. Rather, recurrent models computing prediction errors between stages captured the observed temporal signatures. This model of neural dynamics, which simply augments the standard feedforward model of online vision, suggests that neural responses to static images may encode top-down prediction errors in addition to bottom-up feature estimates.\",\"publicationTitle\":\"eLife\"},{\"title\":\"High-Level Prediction Signals in a Low-Level Area of the Macaque Face-Processing Hierarchy\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Caspar M.\",\"lastName\":\"Schwiedrzik\"},{\"creatorType\":\"author\",\"firstName\":\"Winrich A.\",\"lastName\":\"Freiwald\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"A Bayesian model of imitation in infants and robots\",\"year\":\"2007\",\"author\":[{\"creatorType\":\"editor\",\"firstName\":\"Chrystopher L.\",\"lastName\":\"Nehaniv\"},{\"creatorType\":\"editor\",\"firstName\":\"Kerstin\",\"lastName\":\"Dautenhahn\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Aaron P.\",\"lastName\":\"Shon\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew N.\",\"lastName\":\"Meltzoff\"}],\"topic\":\"Misc\",\"notes\":\"IntroductionHumans are often characterized as the most behaviourally flexible of all animals. Evolution has stumbled upon an unlikely but very effective trick for achieving this state. Relative to most other animals, we are born \\u2018immature\\u2019 and helpless. Our extended period of infantile immaturity, however, confers us with benefits. It allows us to learn and adapt to the specific physical and cultural environment into which we are born. Instead of relying on fixed reflexes adapted for specific environments, our learning capacities allow us to adapt to a wide range of ecological niches, from Alaska to Africa, modifying our shelter, skills, dress and customs accordingly. A crucial component of evolution's design for human beings is imitative learning, the ability to learn behaviours by observing the actions of others.Human adults effortlessly learn new behaviours from watching others. Parents provide their young with an apprenticeship in how to behave as a member of the culture long before verbal instruction is possible. In Western culture, toddlers hold telephones to their ears and babble into thin air. There is no innate proclivity to treat hunks of plastic in this manner, nor is it due to trial-and-error learning. Imitation is chiefly responsible.Over the past decade, imitative learning has received considerable attention from cognitive scientists, evolutionary biologists, neuroscientists and robotics researchers. Discoveries in developmental psychology have altered theories about the origins of imitation and its place in human nature.\",\"publicationTitle\":null},{\"title\":\"Dynamic Routing Between Capsules\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Sara\",\"lastName\":\"Sabour\"},{\"creatorType\":\"author\",\"firstName\":\"Nicholas\",\"lastName\":\"Frosst\"},{\"creatorType\":\"author\",\"firstName\":\"Geoffrey E\",\"lastName\":\"Hinton\"},{\"creatorType\":\"editor\",\"firstName\":\"I.\",\"lastName\":\"Guyon\"},{\"creatorType\":\"editor\",\"firstName\":\"U. V.\",\"lastName\":\"Luxburg\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Bengio\"},{\"creatorType\":\"editor\",\"firstName\":\"H.\",\"lastName\":\"Wallach\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Fergus\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Vishwanathan\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Garnett\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Transforming Auto-Encoders\",\"year\":\"2011\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Geoffrey E.\",\"lastName\":\"Hinton\"},{\"creatorType\":\"author\",\"firstName\":\"Alex\",\"lastName\":\"Krizhevsky\"},{\"creatorType\":\"author\",\"firstName\":\"Sida D.\",\"lastName\":\"Wang\"},{\"creatorType\":\"editor\",\"firstName\":\"Timo\",\"lastName\":\"Honkela\"},{\"creatorType\":\"editor\",\"firstName\":\"W\\u0142odzis\\u0142aw\",\"lastName\":\"Duch\"},{\"creatorType\":\"editor\",\"firstName\":\"Mark\",\"lastName\":\"Girolami\"},{\"creatorType\":\"editor\",\"firstName\":\"Samuel\",\"lastName\":\"Kaski\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The artificial neural networks that are used to recognize shapes typically use one or more layers of learned feature detectors that produce scalar outputs. By contrast, the computer vision community uses complicated, hand-engineered features, like SIFT [6], that produce a whole vector of outputs including an explicit representation of the pose of the feature. We show how neural networks can be used to learn features that output a whole vector of instantiation parameters and we argue that this is a much more promising way of dealing with variations in position, orientation, scale and lighting than the methods currently employed in the neural networks community. It is also more promising than the hand-engineered features currently used in computer vision because it provides an efficient way of adapting the features to the domain.\",\"publicationTitle\":null},{\"title\":\"Cortical-like dynamics in recurrent circuits optimized for sampling-based probabilistic inference\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rodrigo\",\"lastName\":\"Echeveste\"},{\"creatorType\":\"author\",\"firstName\":\"Laurence\",\"lastName\":\"Aitchison\"},{\"creatorType\":\"author\",\"firstName\":\"Guillaume\",\"lastName\":\"Hennequin\"},{\"creatorType\":\"author\",\"firstName\":\"M\\u00e1t\\u00e9\",\"lastName\":\"Lengyel\"}],\"topic\":\"Neural Variability\",\"notes\":\"Sensory cortices display a suite of ubiquitous dynamical features, such as ongoing noise variability, transient overshoots and oscillations, that have so far escaped a common, principled theoretical account. We developed a unifying model for these phenomena by training a recurrent excitatory\\u2013inhibitory neural circuit model of a visual cortical hypercolumn to perform sampling-based probabilistic inference. The optimized network displayed several key biological properties, including divisive normalization and stimulus-modulated noise variability, inhibition-dominated transients at stimulus onset and strong gamma oscillations. These dynamical features had distinct functional roles in speeding up inferences and made predictions that we confirmed in novel analyses of recordings from awake monkeys. Our results suggest that the basic motifs of cortical dynamics emerge as a consequence of the efficient implementation of the same computational function\\u2014fast sampling-based inference\\u2014and predict further properties of these motifs that can be tested in future experiments.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"A hierarchy of intrinsic timescales across primate cortex\",\"year\":\"2014\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"John D.\",\"lastName\":\"Murray\"},{\"creatorType\":\"author\",\"firstName\":\"Alberto\",\"lastName\":\"Bernacchia\"},{\"creatorType\":\"author\",\"firstName\":\"David J.\",\"lastName\":\"Freedman\"},{\"creatorType\":\"author\",\"firstName\":\"Ranulfo\",\"lastName\":\"Romo\"},{\"creatorType\":\"author\",\"firstName\":\"Jonathan D.\",\"lastName\":\"Wallis\"},{\"creatorType\":\"author\",\"firstName\":\"Xinying\",\"lastName\":\"Cai\"},{\"creatorType\":\"author\",\"firstName\":\"Camillo\",\"lastName\":\"Padoa-Schioppa\"},{\"creatorType\":\"author\",\"firstName\":\"Tatiana\",\"lastName\":\"Pasternak\"},{\"creatorType\":\"author\",\"firstName\":\"Hyojung\",\"lastName\":\"Seo\"},{\"creatorType\":\"author\",\"firstName\":\"Daeyeol\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Xiao-Jing\",\"lastName\":\"Wang\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Primate cortex can be organized with specialization and hierarchical principles, but presently there is little evidence for how it is organized temporally. Across six separate datasets, the authors find a hierarchical ordering of intrinsic fluctuation of spiking activity, with timescales that increase from sensory to prefrontal areas.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Layer and rhythm specificity for predictive routing\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Andr\\u00e9 M.\",\"lastName\":\"Bastos\"},{\"creatorType\":\"author\",\"firstName\":\"Mikael\",\"lastName\":\"Lundqvist\"},{\"creatorType\":\"author\",\"firstName\":\"Ayan S.\",\"lastName\":\"Waite\"},{\"creatorType\":\"author\",\"firstName\":\"Nancy\",\"lastName\":\"Kopell\"},{\"creatorType\":\"author\",\"firstName\":\"Earl K.\",\"lastName\":\"Miller\"}],\"topic\":\"Predictive Coding\",\"notes\":\"In predictive coding, experience generates predictions that attenuate the feeding forward of predicted stimuli while passing forward unpredicted \\u201cerrors.\\u201d Different models have suggested distinct cortical layers, and rhythms implement predictive coding. We recorded spikes and local field potentials from laminar electrodes in five cortical areas (visual area 4 [V4], lateral intraparietal [LIP], posterior parietal area 7A, frontal eye field [FEF], and prefrontal cortex [PFC]) while monkeys performed a task that modulated visual stimulus predictability. During predictable blocks, there was enhanced alpha (8 to 14 Hz) or beta (15 to 30 Hz) power in all areas during stimulus processing and prestimulus beta (15 to 30 Hz) functional connectivity in deep layers of PFC to the other areas. Unpredictable stimuli were associated with increases in spiking and in gamma-band (40 to 90 Hz) power\\/connectivity that fed forward up the cortical hierarchy via superficial-layer cortex. Power and spiking modulation by predictability was stimulus specific. Alpha\\/beta power in LIP, FEF, and PFC inhibited spiking in deep layers of V4. Area 7A uniquely showed increases in high-beta (\\u223c22 to 28 Hz) power\\/connectivity to unpredictable stimuli. These results motivate a conceptual model, predictive routing. It suggests that predictive coding may be implemented via lower-frequency alpha\\/beta rhythms that \\u201cprepare\\u201d pathways processing-predicted inputs by inhibiting feedforward gamma rhythms and associated spiking.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Cortical oscillations and sensory predictions\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Luc H.\",\"lastName\":\"Arnal\"},{\"creatorType\":\"author\",\"firstName\":\"Anne-Lise\",\"lastName\":\"Giraud\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Many theories of perception are anchored in the central notion that the brain continuously updates an internal model of the world to infer the probable causes of sensory events. In this framework, the brain needs not only to predict the causes of sensory input, but also when they are most likely to happen. In this article, we review the neurophysiological bases of sensory predictions of \\u201cwhat\\u2019 (predictive coding) and \\u2018when\\u2019 (predictive timing), with an emphasis on low-level oscillatory mechanisms. We argue that neural rhythms offer distinct and adapted computational solutions to predicting \\u2018what\\u2019 is going to happen in the sensory environment and \\u2018when\\u2019.\",\"publicationTitle\":\"Trends in Cognitive Sciences\"},{\"title\":\"Neuropixels 2.0: A miniaturized high-density probe for stable, long-term brain recordings\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Nicholas A.\",\"lastName\":\"Steinmetz\"},{\"creatorType\":\"author\",\"firstName\":\"Cagatay\",\"lastName\":\"Aydin\"},{\"creatorType\":\"author\",\"firstName\":\"Anna\",\"lastName\":\"Lebedeva\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"Okun\"},{\"creatorType\":\"author\",\"firstName\":\"Marius\",\"lastName\":\"Pachitariu\"},{\"creatorType\":\"author\",\"firstName\":\"Marius\",\"lastName\":\"Bauza\"},{\"creatorType\":\"author\",\"firstName\":\"Maxime\",\"lastName\":\"Beau\"},{\"creatorType\":\"author\",\"firstName\":\"Jai\",\"lastName\":\"Bhagat\"},{\"creatorType\":\"author\",\"firstName\":\"Claudia\",\"lastName\":\"B\\u00f6hm\"},{\"creatorType\":\"author\",\"firstName\":\"Martijn\",\"lastName\":\"Broux\"},{\"creatorType\":\"author\",\"firstName\":\"Susu\",\"lastName\":\"Chen\"},{\"creatorType\":\"author\",\"firstName\":\"Jennifer\",\"lastName\":\"Colonell\"},{\"creatorType\":\"author\",\"firstName\":\"Richard J.\",\"lastName\":\"Gardner\"},{\"creatorType\":\"author\",\"firstName\":\"Bill\",\"lastName\":\"Karsh\"},{\"creatorType\":\"author\",\"firstName\":\"Fabian\",\"lastName\":\"Kloosterman\"},{\"creatorType\":\"author\",\"firstName\":\"Dimitar\",\"lastName\":\"Kostadinov\"},{\"creatorType\":\"author\",\"firstName\":\"Carolina\",\"lastName\":\"Mora-Lopez\"},{\"creatorType\":\"author\",\"firstName\":\"John\",\"lastName\":\"O\\u2019Callaghan\"},{\"creatorType\":\"author\",\"firstName\":\"Junchol\",\"lastName\":\"Park\"},{\"creatorType\":\"author\",\"firstName\":\"Jan\",\"lastName\":\"Putzeys\"},{\"creatorType\":\"author\",\"firstName\":\"Britton\",\"lastName\":\"Sauerbrei\"},{\"creatorType\":\"author\",\"firstName\":\"Rik J. J. van\",\"lastName\":\"Daal\"},{\"creatorType\":\"author\",\"firstName\":\"Abraham Z.\",\"lastName\":\"Vollan\"},{\"creatorType\":\"author\",\"firstName\":\"Shiwei\",\"lastName\":\"Wang\"},{\"creatorType\":\"author\",\"firstName\":\"Marleen\",\"lastName\":\"Welkenhuysen\"},{\"creatorType\":\"author\",\"firstName\":\"Zhiwen\",\"lastName\":\"Ye\"},{\"creatorType\":\"author\",\"firstName\":\"Joshua T.\",\"lastName\":\"Dudman\"},{\"creatorType\":\"author\",\"firstName\":\"Barundeb\",\"lastName\":\"Dutta\"},{\"creatorType\":\"author\",\"firstName\":\"Adam W.\",\"lastName\":\"Hantman\"},{\"creatorType\":\"author\",\"firstName\":\"Kenneth D.\",\"lastName\":\"Harris\"},{\"creatorType\":\"author\",\"firstName\":\"Albert K.\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Edvard I.\",\"lastName\":\"Moser\"},{\"creatorType\":\"author\",\"firstName\":\"John\",\"lastName\":\"O\\u2019Keefe\"},{\"creatorType\":\"author\",\"firstName\":\"Alfonso\",\"lastName\":\"Renart\"},{\"creatorType\":\"author\",\"firstName\":\"Karel\",\"lastName\":\"Svoboda\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"H\\u00e4usser\"},{\"creatorType\":\"author\",\"firstName\":\"Sebastian\",\"lastName\":\"Haesler\"},{\"creatorType\":\"author\",\"firstName\":\"Matteo\",\"lastName\":\"Carandini\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy D.\",\"lastName\":\"Harris\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Recording many neurons for a long time\\nThe ultimate aim of chronic recordings is to sample from the same neuron over days and weeks. However, this goal has been difficult to achieve for large populations of neurons. Steinmetz et al. describe the development and testing of Neuropixels 2.0. This new electrophysiological recording tool is a miniaturized, high-density probe for both acute and long-term experiments combined with sophisticated software algorithms for fully automatic post hoc computational stabilization. The technique also provides a strategy for extending the number of recorded sites beyond the number of available recording channels. In freely moving animals, extremely large numbers of individual neurons could thus be followed and tracked with the same probe for weeks and occasionally months.\\nScience, this issue p. eabf4588\\nStructured Abstract\\nINTRODUCTIONElectrode arrays based on complementary metal-oxide semiconductor silicon fabrication technology, such as Neuropixels probes, have enabled recordings of thousands of individual neurons in the living brain. These tools have led to discoveries about the brain-wide correlates of perception and action, primarily when used in acute, head-fixed recordings. To study the dynamics of neuronal processing across time scales, however, it is necessary to record from neurons over weeks and months, ideally during unrestrained behavior and in small animals, such as mice.\\nRATIONALETo this end, we designed a miniaturized probe, called Neuropixels 2.0, with 5120 recording sites distributed over four shanks. The probe and headstage were miniaturized to about one-third of the original size (i.e., the size of the Neuropixels 1.0 probe), so that two probes and their single headstage weigh only ~1.1 g, without loss of channel count (384 channels per probe). Using two four-shank probes provides 10,240 recording sites in one implant. To achieve stable recordings despite brain movement, we optimized the recording site arrangement. The probe has a denser, linearized geometry that allows for post hoc computational motion correction using a newly designed algorithm. This algorithm, implemented in the Kilosort 2.5 software package, determines the motion over time from the spiking data and corrects it with spatial resampling, as in image registration.\\nRESULTSTo validate these probes for long-term recordings, we implanted them chronically in 21 rats and mice in six laboratories. Twenty of these 21 implants succeeded and yielded neurons over weeks and months while retaining good signal quality. The probes were reliably recoverable using newly engineered implant fixture designs.To test the performance of the motion correction algorithm, we performed recordings with known imposed motion of the probe relative to the brain. The algorithm improved the yield of stable neurons and largely eliminated the impact of motion on the recording.A version of this algorithm allowed the recording of neurons stably across days. We assessed this by \\u201cfingerprinting\\u201d individual chronically recorded neurons in the primary visual cortex using their distinctive visual responses to a battery of images. Neuron tracking was >90% successful for up to 2 weeks and >80% successful for up to 2 months.\\nCONCLUSIONThis work demonstrates a suite of electrophysiological tools comprising a miniaturized high-density probe, recoverable chronic implant fixtures, and algorithms for automatic post hoc motion correction. These tools enable an order-of-magnitude increase in the number of sites that can be recorded in small animals, such as mice, and the ability to record from them stably over long time scales. <img class=\\\"fragment-image\\\" aria-describedby=\\\"F1-caption\\\" src=\\\"https:\\/\\/science.sciencemag.org\\/content\\/sci\\/372\\/6539\\/eabf4588\\/F1.medium.gif\\\"\\/> Download high-res image Open in new tab Download Powerpoint Neuropixels 2.0 probes allow unprecedented recordings.(A) Comparison of the Neuropixels 1.0 and 2.0 device designs. The Neuropixels 2.0 device is miniaturized and has four shanks. Two probes can be hosted per headstage. (B) Pattern of spiking activity across the cortex (Ctx), hippocampus (HC), and thalamus (Th) recorded over >300 days. (C) Example spiking rasters from two Neuropixels 2.0 probes chronically implanted in a mouse, showing spikes recorded on 6144 of the 10,240 sites available across the two probes. Eight sequential recordings (different colors) were performed from 768 channels each.\\nMeasuring the dynamics of neural processing across time scales requires following the spiking of thousands of individual neurons over milliseconds and months. To address this need, we introduce the Neuropixels 2.0 probe together with newly designed analysis algorithms. The probe has more than 5000 sites and is miniaturized to facilitate chronic implants in small mammals and recording during unrestrained behavior. High-quality recordings over long time scales were reliably obtained in mice and rats in six laboratories. Improved site density and arrangement combined with newly created data processing methods enable automatic post hoc correction for brain movements, allowing recording from the same neurons for more than 2 months. These probes and algorithms enable stable recordings from thousands of sites during free behavior, even in small animals such as mice.\\nAn approach has been developed that allows recording from the same neurons in a freely behaving animal for weeks and months.\\nAn approach has been developed that allows recording from the same neurons in a freely behaving animal for weeks and months.\",\"publicationTitle\":\"Science\"},{\"title\":\"Fully integrated silicon probes for high-density recording of neural activity\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"James J.\",\"lastName\":\"Jun\"},{\"creatorType\":\"author\",\"firstName\":\"Nicholas A.\",\"lastName\":\"Steinmetz\"},{\"creatorType\":\"author\",\"firstName\":\"Joshua H.\",\"lastName\":\"Siegle\"},{\"creatorType\":\"author\",\"firstName\":\"Daniel J.\",\"lastName\":\"Denman\"},{\"creatorType\":\"author\",\"firstName\":\"Marius\",\"lastName\":\"Bauza\"},{\"creatorType\":\"author\",\"firstName\":\"Brian\",\"lastName\":\"Barbarits\"},{\"creatorType\":\"author\",\"firstName\":\"Albert K.\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Costas A.\",\"lastName\":\"Anastassiou\"},{\"creatorType\":\"author\",\"firstName\":\"Alexandru\",\"lastName\":\"Andrei\"},{\"creatorType\":\"author\",\"firstName\":\"\\u00c7a\\u011fatay\",\"lastName\":\"Ayd\\u0131n\"},{\"creatorType\":\"author\",\"firstName\":\"Mladen\",\"lastName\":\"Barbic\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy J.\",\"lastName\":\"Blanche\"},{\"creatorType\":\"author\",\"firstName\":\"Vincent\",\"lastName\":\"Bonin\"},{\"creatorType\":\"author\",\"firstName\":\"Jo\\u00e3o\",\"lastName\":\"Couto\"},{\"creatorType\":\"author\",\"firstName\":\"Barundeb\",\"lastName\":\"Dutta\"},{\"creatorType\":\"author\",\"firstName\":\"Sergey L.\",\"lastName\":\"Gratiy\"},{\"creatorType\":\"author\",\"firstName\":\"Diego A.\",\"lastName\":\"Gutnisky\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"H\\u00e4usser\"},{\"creatorType\":\"author\",\"firstName\":\"Bill\",\"lastName\":\"Karsh\"},{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Ledochowitsch\"},{\"creatorType\":\"author\",\"firstName\":\"Carolina Mora\",\"lastName\":\"Lopez\"},{\"creatorType\":\"author\",\"firstName\":\"Catalin\",\"lastName\":\"Mitelut\"},{\"creatorType\":\"author\",\"firstName\":\"Silke\",\"lastName\":\"Musa\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"Okun\"},{\"creatorType\":\"author\",\"firstName\":\"Marius\",\"lastName\":\"Pachitariu\"},{\"creatorType\":\"author\",\"firstName\":\"Jan\",\"lastName\":\"Putzeys\"},{\"creatorType\":\"author\",\"firstName\":\"P. Dylan\",\"lastName\":\"Rich\"},{\"creatorType\":\"author\",\"firstName\":\"Cyrille\",\"lastName\":\"Rossant\"},{\"creatorType\":\"author\",\"firstName\":\"Wei-lung\",\"lastName\":\"Sun\"},{\"creatorType\":\"author\",\"firstName\":\"Karel\",\"lastName\":\"Svoboda\"},{\"creatorType\":\"author\",\"firstName\":\"Matteo\",\"lastName\":\"Carandini\"},{\"creatorType\":\"author\",\"firstName\":\"Kenneth D.\",\"lastName\":\"Harris\"},{\"creatorType\":\"author\",\"firstName\":\"Christof\",\"lastName\":\"Koch\"},{\"creatorType\":\"author\",\"firstName\":\"John\",\"lastName\":\"O\\u2019Keefe\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy D.\",\"lastName\":\"Harris\"}],\"topic\":\"Neurophysiology\",\"notes\":\"New silicon probes known as Neuropixels are shown to record from hundreds of neurons simultaneously in awake and freely moving rodents.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Bayesian Computation in Recurrent Neural Circuits\",\"year\":\"2004\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"}],\"topic\":\"Neural Variability\",\"notes\":\"A large number of human psychophysical results have been successfully explained in recent years using Bayesian models. However, the neural implementation of such models remains largely unclear. In this article, we show that a network architecture commonly used to model the cerebral cortex can implement Bayesian inference for an arbitrary hidden Markov model. We illustrate the approach using an orientation discrimination task and a visual motion detection task. In the case of orientation discrimination, we show that the model network can infer the posterior distribution over orientations and correctly estimate stimulus orientation in the presence of significant noise. In the case of motion detection, we show that the resulting model network exhibits direction selectivity and correctly computes the posterior probabilities over motion direction and position. When used to solve the well-known random dots motion discrimination task, the model generates responses that mimic the activities of evidence-accumulating neurons in cortical areas LIP and FEF. The framework we introduce posits a new interpretation of cortical activities in terms of log posterior probabilities of stimuli occurring in the natural world.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Distinct timescales of population coding across cortex\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Caroline A.\",\"lastName\":\"Runyan\"},{\"creatorType\":\"author\",\"firstName\":\"Eugenio\",\"lastName\":\"Piasini\"},{\"creatorType\":\"author\",\"firstName\":\"Stefano\",\"lastName\":\"Panzeri\"},{\"creatorType\":\"author\",\"firstName\":\"Christopher D.\",\"lastName\":\"Harvey\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Calcium imaging data from mice performing a virtual reality auditory decision-making task are used to analyse the population codes in primary auditory and posterior parietal cortex that support choice behaviour.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Predictive coding as a model of response properties in cortical area V1\",\"year\":\"2010\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Michael W.\",\"lastName\":\"Spratling\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A simple model is shown to account for a large range of V1 classical, and nonclassical, receptive field properties including orientation tuning, spatial and temporal frequency tuning, cross-orientation suppression, surround suppression, and facilitation and inhibition by flankers and textured surrounds. The model is an implementation of the predictive coding theory of cortical function and thus provides a single computational explanation for a diverse range of neurophysiological findings. Furthermore, since predictive coding can be related to the biased competition theory and is a specific example of more general theories of hierarchical perceptual inference, the current results relate V1 response properties to a wider, more unified, framework for understanding cortical function.\",\"publicationTitle\":\"The Journal of Neuroscience: The Official Journal of the Society for Neuroscience\"},{\"title\":\"Reconciling Predictive Coding and Biased Competition Models of Cortical Function\",\"year\":\"2008\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Michael W.\",\"lastName\":\"Spratling\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A simple variation of the standard biased competition model is shown, via some trivial mathematical manipulations, to be identical to predictive coding. Specifically, it is shown that a particular implementation of the biased competition model, in which nodes compete via inhibition that targets the inputs to a cortical region, is mathematically equivalent to the linear predictive coding model. This observation demonstrates that these two important and influential rival theories of cortical function are minor variations on the same underlying mathematical model.\",\"publicationTitle\":\"Frontiers in Computational Neuroscience\"},{\"title\":\"Contextual Modulation in Primary Visual Cortex\",\"year\":\"1996\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Zipser\"},{\"creatorType\":\"author\",\"firstName\":\"Victor A. F.\",\"lastName\":\"Lamme\"},{\"creatorType\":\"author\",\"firstName\":\"Peter H.\",\"lastName\":\"Schiller\"}],\"topic\":\"Neurophysiology\",\"notes\":\"We studied extra-receptive field contextual modulation in area V1 of awake, behaving macaque monkeys. Contextual modulation was studied using texture displays in which texture covering the receptive field (RF) was the same in all trials, but the perceptual context of this texture could vary depending on the configuration of extra-RF texture elements. We found robust contextual modulation when disparity, color, luminance, and orientation cues variously defined a textured figure centered on the RF of V1 neurons. We found contextual modulation to have a spatial extent of \\u223c8 to 10\\u00b0 diameter parafoveally. Contextual modulation correlated with perceptual experience of both binocularly rivalrous texture displays and of displays with a simple example of surface occlusion. We found contextual modulation in V1 to have a characteristic latency of 80\\u2013100 msec after stimulus onset, potentially allowing feedback from extrastriate areas to underlie to this effect.\",\"publicationTitle\":\"Journal of Neuroscience\"},{\"title\":\"Visual properties of neurons in area V4 of the macaque: sensitivity to stimulus form\",\"year\":\"1987\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"R.\",\"lastName\":\"Desimone\"},{\"creatorType\":\"author\",\"firstName\":\"S. J.\",\"lastName\":\"Schein\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Area V4, a visuotopically organized area in prestriate cortex of the macaque, is the major source of visual input to the inferior temporal cortex, known to be crucial for object recognition. To examine the selectivity of cells in V4 for stimulus form, we quantitatively measured the responses of 322 cells to bars varying in length, width, orientation, and polarity of contrast, and sinusoidal gratings varying in spatial frequency, phase, orientation, and overall size. All of the cells recorded in V4 were located on the lower portion of the prelunate gyrus. Receptive fields were located almost exclusively within the representation of the central 5 degrees of the lower visual field, and receptive field size, in linear dimension, was 4-7 times greater than that in the corresponding representation of striate cortex (V1). Nearly all receptive fields consisted of overlapping dark and light zones, like \\u201cclassic\\u201d complex fields in V1, but the relative strengths of the dark and light zones often differed. A few cells responded exclusively to light or dark stimuli. Many cells in V4 were selective for stimulus orientation, and a few were selective for direction of motion as well. Although the median orientation bandwidth of the orientation-selective cells (52 degrees) was wider than that reported for oriented cells in V1, approximately 8% of the oriented cells had bandwidths of less than 30 degrees, which is nearly as narrow as the most narrowly tuned cells in V1. The proportion of cells selective for direction of motion (13%) was not markedly different from that reported in V1. The large majority of V4 cells were tuned to the length and width of bars, and the \\u201cshape\\u201d of the optimal bar varied from cell to cell, as has been reported for cells in the dorsolateral visual area (DL) of the owl monkey, a possible homologue of V4 in the macaque. Preferred lengths and widths varied independently from approximately 0.05 to 6 degrees, with the smallest preferred bars about the size of the smallest receptive fields in V1 and the largest preferred bars larger than any fields in V1. The relationship between the size of the optimal bar and the size of the receptive field varied from cell to cell. Some cells, for example, responded best to bars much narrower or shorter than the field, whereas other cells responded best to bars that filled (but did not extend beyond) the excitatory field in the length, width, or both dimensions.(ABSTRACT TRUNCATED AT 400 WORDS)\",\"publicationTitle\":\"Journal of Neurophysiology\"},{\"title\":\"Generation of end-inhibition in the visual cortex via interlaminar connections\",\"year\":\"1986\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"J\\u00fcrgen\",\"lastName\":\"Bolz\"},{\"creatorType\":\"author\",\"firstName\":\"Charles D.\",\"lastName\":\"Gilbert\"}],\"topic\":\"Neurophysiology\",\"notes\":\"To understand the mechanisms by which the receptive field properties of visual cortical cells are generated, one must consider both the thalamic input to the cortex and the intrinsic cortical connections. In the cat striate cortex, layer 4 is the main recipient of input from the lateral geniculate nucleus, yet the cells in that layer possess several receptive field properties that are distinct from the geniculate input, including orientation specificity, binocularity, directionality and end-inhibition, the last of which allows cells to respond to edges of a restricted length1\\u20134. These properties could be generated by connections within the layer, by its input from the claustrum5 or by the massive projection that layer 4 receives from layer 6 (refs 6\\u20139). In the present study, we attempted to determine the functional role of the layer 6 to layer 4 projection by reversible inactivation of layer 6 using the inhibitory transmitter \\u03b3-aminobutyric acid (GABA). After inactivating layer 6, cells in layer 4 lost end-inhibition. Cells in layer 2+3, which receive their principal input from layer 4, were similarly affected. The elimination of end-inhibition was specific, other receptive field properties, such as direction selectivity or orientation specificity, remaining intact.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Receptive fields and functional architecture of monkey striate cortex\",\"year\":\"1968\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"D. H.\",\"lastName\":\"Hubel\"},{\"creatorType\":\"author\",\"firstName\":\"T. N.\",\"lastName\":\"Wiesel\"}],\"topic\":\"Neurophysiology\",\"notes\":\"1. The striate cortex was studied in lightly anaesthetized macaque and spider monkeys by recording extracellularly from single units and stimulating the retinas with spots or patterns of light. Most cells can be categorized as simple, complex, or hypercomplex, with response properties very similar to those previously described in the cat. On the average, however, receptive fields are smaller, and there is a greater sensitivity to changes in stimulus orientation. A small proportion of the cells are colour coded.2. Evidence is presented for at least two independent systems of columns extending vertically from surface to white matter. Columns of the first type contain cells with common receptive-field orientations. They are similar to the orientation columns described in the cat, but are probably smaller in cross-sectional area. In the second system cells are aggregated into columns according to eye preference. The ocular dominance columns are larger than the orientation columns, and the two sets of boundaries seem to be independent.3. There is a tendency for cells to be grouped according to symmetry of responses to movement; in some regions the cells respond equally well to the two opposite directions of movement of a line, but other regions contain a mixture of cells favouring one direction and cells favouring the other.4. A horizontal organization corresponding to the cortical layering can also be discerned. The upper layers (II and the upper two-thirds of III) contain complex and hypercomplex cells, but simple cells are virtually absent. The cells are mostly binocularly driven. Simple cells are found deep in layer III, and in IV A and IV B. In layer IV B they form a large proportion of the population, whereas complex cells are rare. In layers IV A and IV B one finds units lacking orientation specificity; it is not clear whether these are cell bodies or axons of geniculate cells. In layer IV most cells are driven by one eye only; this layer consists of a mosaic with cells of some regions responding to one eye only, those of other regions responding to the other eye. Layers V and VI contain mostly complex and hypercomplex cells, binocularly driven.5. The cortex is seen as a system organized vertically and horizontally in entirely different ways. In the vertical system (in which cells lying along a vertical line in the cortex have common features) stimulus dimensions such as retinal position, line orientation, ocular dominance, and perhaps directionality of movement, are mapped in sets of superimposed but independent mosaics. The horizontal system segregates cells in layers by hierarchical orders, the lowest orders (simple cells monocularly driven) located in and near layer IV, the higher orders in the upper and lower layers.\",\"publicationTitle\":\"The Journal of Physiology\"},{\"title\":\"Planning and Acting in Uncertain Environments using Probabilistic Inference\",\"year\":\"2006\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Deepak\",\"lastName\":\"Verma\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P.\",\"lastName\":\"N. Rao\"}],\"topic\":\"Reinforcement Learning\",\"notes\":\"An important problem in robotics is planning and selecting actions for goal-directed behavior in noisy uncertain environments. The problem is typically addressed within the framework of partially observable Markov decision processes (POMDPs). Although efficient algorithms exist for learning policies for MDPs, these algorithms do not generalize easily to POMDPs. In this paper, we propose a framework for planning and action selection based on probabilistic inference in graphical models. Unlike previous approaches based on MAP inference, our approach utilizes the most probable explanation (MPE) of variables in a graphical model, allowing tractable and efficient inference of actions. It generalizes easily to complex partially observable environments. Furthermore, it allows rewards and costs to be incorporated in a straightforward manner as part of the inference process. We investigate the application of our approach to the problem of robot navigation by testing it on a suite of well-known POMDP benchmarks. Our results demonstrate that the proposed method can beat or match the performance of recently proposed specialized POMDP solvers\",\"publicationTitle\":null},{\"title\":\"Goal-Based Imitation as Probabilistic Inference over Graphical Models\",\"year\":\"2005\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Deepak\",\"lastName\":\"Verma\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P.\",\"lastName\":\"Rao\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"\",\"publicationTitle\":\"Advances in Neural Information Processing Systems\"},{\"title\":\"Planning as inference\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Matthew\",\"lastName\":\"Botvinick\"},{\"creatorType\":\"author\",\"firstName\":\"Marc\",\"lastName\":\"Toussaint\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"Recent developments in decision-making research are bringing the topic of planning back to center stage in cognitive science. This renewed interest reopens an old, but still unanswered question: how exactly does planning happen? What are the underlying information processing operations and how are they implemented in the brain? Although a range of interesting possibilities exists, recent work has introduced a potentially transformative new idea, according to which planning is accomplished through probabilistic inference.\",\"publicationTitle\":\"Trends in Cognitive Sciences\"},{\"title\":\"Planning by Probabilistic Inference\",\"year\":\"2003\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Hagai\",\"lastName\":\"Attias\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"This paper presents and demonstrates a new approach to the problem of planning under uncertainty. Actions are treated as hidden variables, with their own prior distributions, in a probabilistic gen...\",\"publicationTitle\":null},{\"title\":\"Active Inference: A Process Theory\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"FitzGerald\"},{\"creatorType\":\"author\",\"firstName\":\"Francesco\",\"lastName\":\"Rigoli\"},{\"creatorType\":\"author\",\"firstName\":\"Philipp\",\"lastName\":\"Schwartenbeck\"},{\"creatorType\":\"author\",\"firstName\":\"Giovanni\",\"lastName\":\"Pezzulo\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"This article describes a process theory based on active inference and belief propagation. Starting from the premise that all neuronal processing (and action selection) can be explained by maximizing Bayesian model evidence\\u2014or minimizing variational free energy\\u2014we ask whether neuronal responses can be described as a gradient descent on variational free energy. Using a standard (Markov decision process) generative model, we derive the neuronal dynamics implicit in this description and reproduce a remarkable range of well-characterized neuronal phenomena. These include repetition suppression, mismatch negativity, violation responses, place-cell activity, phase precession, theta sequences, theta-gamma coupling, evidence accumulation, race-to-bound dynamics, and transfer of dopamine responses. Furthermore, the (approximately Bayes\\u2019 optimal) behavior prescribed by these dynamics has a degree of face validity, providing a formal explanation for reward seeking, context learning, and epistemic foraging. Technically, the fact that a gradient descent appears to be a valid description of neuronal activity means that variational free energy is a Lyapunov function for neuronal dynamics, which therefore conform to Hamilton\\u2019s principle of least action.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Action understanding and active inference\",\"year\":\"2011\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"},{\"creatorType\":\"author\",\"firstName\":\"J\\u00e9r\\u00e9mie\",\"lastName\":\"Mattout\"},{\"creatorType\":\"author\",\"firstName\":\"James\",\"lastName\":\"Kilner\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"We have suggested that the mirror-neuron system might be usefully understood as implementing Bayes-optimal perception of actions emitted by oneself or others. To substantiate this claim, we present neuronal simulations that show the same representations can prescribe motor behavior and encode motor intentions during action\\u2013observation. These simulations are based on the free-energy formulation of active inference, which is formally related to predictive coding. In this scheme, (generalised) states of the world are represented as trajectories. When these states include motor trajectories they implicitly entail intentions (future motor states). Optimizing the representation of these intentions enables predictive coding in a prospective sense. Crucially, the same generative models used to make predictions can be deployed to predict the actions of self or others by simply changing the bias or precision (i.e. attention) afforded to proprioceptive signals. We illustrate these points using simulations of handwriting to illustrate neuronally plausible generation and recognition of itinerant (wandering) motor trajectories. We then use the same simulations to produce synthetic electrophysiological responses to violations of intentional expectations. Our results affirm that a Bayes-optimal approach provides a principled framework, which accommodates current thinking about the mirror-neuron system. Furthermore, it endorses the general formulation of action as active inference.\",\"publicationTitle\":\"Biological Cybernetics\"},{\"title\":\"Deep active inference agents using Monte-Carlo methods\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Zafeirios\",\"lastName\":\"Fountas\"},{\"creatorType\":\"author\",\"firstName\":\"Noor\",\"lastName\":\"Sajid\"},{\"creatorType\":\"author\",\"firstName\":\"Pedro\",\"lastName\":\"Mediano\"},{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"\",\"publicationTitle\":\"Advances in Neural Information Processing Systems\"},{\"title\":\"A theory of cortical responses\",\"year\":\"2005\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"This article concerns the nature of evoked brain responses and the principles underlying their generation. We start with the premise that the sensory brain has evolved to represent or infer the causes of changes in its sensory inputs. The problem of inference is well formulated in statistical terms. The statistical fundaments of inference may therefore afford important constraints on neuronal implementation. By formulating the original ideas of Helmholtz on perception, in terms of modern-day statistical theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts.It turns out that the problems of inferring the causes of sensory input (perceptual inference) and learning the relationship between input and cause (perceptual learning) can be resolved using exactly the same principle. Specifically, both inference and learning rest on minimizing the brain's free energy, as defined in statistical physics. Furthermore, inference and learning can proceed in a biologically plausible fashion. Cortical responses can be seen as the brain\\u2019s attempt to minimize the free energy induced by a stimulus and thereby encode the most likely cause of that stimulus. Similarly, learning emerges from changes in synaptic efficacy that minimize the free energy, averaged over all stimuli encountered. The underlying scheme rests on empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organization and responses. The aim of this article is to encompass many apparently unrelated anatomical, physiological and psychophysical attributes of the brain within a single theoretical perspective.In terms of cortical architectures, the theoretical treatment predicts that sensory cortex should be arranged hierarchically, that connections should be reciprocal and that forward and backward connections should show a functional asymmetry (forward connections are driving, whereas backward connections are both driving and modulatory). In terms of synaptic physiology, it predicts associative plasticity and, for dynamic models, spike-timing-dependent plasticity. In terms of electrophysiology, it accounts for classical and extra classical receptive field effects and long-latency or endogenous components of evoked cortical responses. It predicts the attenuation of responses encoding prediction error with perceptual learning and explains many phenomena such as repetition suppression, mismatch negativity (MMN) and the P300 in electroencephalography. In psychophysical terms, it accounts for the behavioural correlates of these physiological phenomena, for example, priming and global precedence. The final focus of this article is on perceptual learning as measured with the MMN and the implications for empirical studies of coupling among cortical areas using evoked sensory responses.\",\"publicationTitle\":\"Philosophical Transactions of the Royal Society B: Biological Sciences\"},{\"title\":\"Bilinear Sparse Coding for Invariant Vision\",\"year\":\"2005\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David B.\",\"lastName\":\"Grimes\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Recent algorithms for sparse coding and independent component analysis (ICA) have demonstrated how localized features can be learned from natural images. However, these approaches do not take image transformations into account. We describe an unsupervised algorithm for learning both localized features and their transformations directly from images using a sparse bilinear generative model. We show that from an arbitrary set of natural images, the algorithm produces oriented basis filters that can simultaneously represent features in an image and their transformations. The learned generative model can be used to translate features to different locations, thereby reducing the need to learn the same feature at multiple locations, a limitation of previous approaches to sparse coding and ICA. Our results suggest that by explicitly modeling the interaction between local image features and their transformations, the sparse bilinear approach can provide a basis for achieving transformation-invariant vision.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Learning the Lie Groups of Visual Invariance\",\"year\":\"2007\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Xu\",\"lastName\":\"Miao\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A fundamental problem in biological and machine vision is visual invariance: How are objects perceived to be the same despite transformations such as translations, rotations, and scaling? In this letter, we describe a new, unsupervised approach to learning invariances based on Lie group theory. Unlike traditional approaches that sacrifice information about transformations to achieve invariance, the Lie group approach explicitly models the effects of transformations in images. As a result, estimates of transformations are available for other purposes, such as pose estimation and visuomotor control. Previous approaches based on first-order Taylor series expansions of images can be regarded as special cases of the Lie group approach, which utilizes a matrix-exponential-based generative model of images and can handle arbitrarily large transformations. We present an unsupervised expectation-maximization algorithm for learning Lie transformation operators directly from image data containing examples of transformations. Our experimental results show that the Lie operators learned by the algorithm from an artificial data set containing six types of affine transformations closely match the analytically predicted affine operators. We then demonstrate that the algorithm can also recover novel transformation operators from natural image sequences. We conclude by showing that the learned operators can be used to both generate and estimate transformations in images, thereby providing a basis for achieving visual invariance.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Learning Lie Groups for Invariant Visual Perception\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Daniel\",\"lastName\":\"Ruderman\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Advances in Neural Information Processing Systems\"},{\"title\":\"A new approach to linear filtering and prediction problems\",\"year\":\"1960\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rudolph Emil\",\"lastName\":\"Kalman\"}],\"topic\":\"Math\",\"notes\":\"\",\"publicationTitle\":\"\"},{\"title\":\"Development of localized oriented receptive fields by learning a translation-invariant code for natural images\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Dana H.\",\"lastName\":\"Ballard\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Neurons in the mammalian primary visual cortex are known to possess spatially localized, oriented receptive fields. It has previously been suggested that these distinctive properties may reflect an efficient image encoding strategy based on maximizing the sparseness of the distribution of output neuronal activities or alternately, extracting the independent components of natural image ensembles. Here, we show that a strategy for transformation-invariant coding of images based on a first-order Taylor series expansion of an image also causes localized, oriented receptive fields to be learned from natural image inputs. These receptive fields, which approximate localized first-order differential operators at various orientations, allow a pair of cooperating neural networks, one estimating object identity (\\u2018what\\u2019) and the other estimating object transformations (\\u2018where\\u2019), to simultaneously recognize an object and estimate its pose by jointly maximizing the a posteriori probability of generating the observed visual data. We provide experimental results demonstrating the ability of such networks to factor retinal stimuli into object-centred features and object-invariant transformation estimates*This work was performed at teh Department of Computer Science, University of Rochester, Rochester,NY,USA.\",\"publicationTitle\":\"Network: Computation in Neural Systems\"},{\"title\":\"A Neural Substrate of Prediction and Reward\",\"year\":\"1997\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Wolfram\",\"lastName\":\"Schultz\"},{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Dayan\"},{\"creatorType\":\"author\",\"firstName\":\"P. Read\",\"lastName\":\"Montague\"}],\"topic\":\"Reinforcement Learning\",\"notes\":\"The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.\",\"publicationTitle\":\"Science\"},{\"title\":\"Internal models in the cerebellum\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Daniel M\",\"lastName\":\"Wolpert\"},{\"creatorType\":\"author\",\"firstName\":\"R. Chris\",\"lastName\":\"Miall\"},{\"creatorType\":\"author\",\"firstName\":\"Mitsuo\",\"lastName\":\"Kawato\"}],\"topic\":\"Neurophysiology\",\"notes\":\"This review will focus on the possibility that the cerebellum contains an internal model or models of the motor apparatus. Inverse internal models can provide the neural command necessary to achieve some desired trajectory. First, we review the necessity of such a model and the evidence, based on the ocular following response, that inverse models are found within the cerebellar circuitry. Forward internal models predict the consequences of actions and can be used to overcome time delays associated with feedback control. Secondly, we review the evidence that the cerebellum generates predictions using such a forward model. Finally, we review a computational model that includes multiple paired forward and inverse models and show how such an arrangement can be advantageous for motor learning and control.\",\"publicationTitle\":\"Trends in Cognitive Sciences\"},{\"title\":\"Synaptic plasticity in a cerebellum-like structure depends on temporal order\",\"year\":\"1997\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Curtis C.\",\"lastName\":\"Bell\"},{\"creatorType\":\"author\",\"firstName\":\"Victor Z.\",\"lastName\":\"Han\"},{\"creatorType\":\"author\",\"firstName\":\"Yoshiko\",\"lastName\":\"Sugawara\"},{\"creatorType\":\"author\",\"firstName\":\"Kirsty\",\"lastName\":\"Grant\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Cerebellum-like structures in fish appear to act as adaptive sensory processors, in which learned predictions about sensory input are generated and subtracted from actual sensory input, allowing unpredicted inputs to stand out1\\u20133. Pairing sensory input with centrally originating predictive signals, such as corollary discharge signals linked to motor commands, results in neural responses to the predictive signals alone that are Negative images' of the previously paired sensory responses. Adding these 'negative images' to actual sensory inputs minimizes the neural response to predictable sensory features. At the cellular level, sensory input is relayed to the basal region of Purkinje-like cells, whereas predictive signals are relayed by parallel fibres to the apical dendrites of the same cells4. The generation of negative images could be explained by plasticity at parallel fibre synapses5\\u20137. We show here that such plasticity exists in the electrosensory lobe of mormyrid electric fish and that it has the necessary properties for such a model: it is reversible, anti-hebbian (excitatory postsynaptic potentials (EPSPs) are depressed after pairing with a postsynaptic spike) and tightly dependent on the sequence of pre- and postsynaptic events, with depression occurring only if the postsynaptic spike follows EPSP onset within 60 ms.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Dynamic Model of Visual Recognition Predicts Neural Response Properties in the Visual Cortex\",\"year\":\"1997\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Dana H.\",\"lastName\":\"Ballard\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The responses of visual cortical neurons during fixation tasks can be significantly modulated by stimuli from beyond the classical receptive field. Modulatory effects in neural responses have also been recently reported in a task where a monkey freely views a natural scene. In this article, we describe a hierarchical network model of visual recognition that explains these experimental observations by using a form of the extended Kalman filter as given by the minimum description length (MDL) principle. The model dynamically combines input-driven bottom-up signals with expectation-driven top-down signals to predict current recognition state. Synaptic weights in the model are adapted in a Hebbian manner according to a learning rule also derived from the MDL principle. The resulting prediction-learning scheme can be viewed as implementing a form of the expectation-maximization (EM) algorithm. The architecture of the model posits an active computational role for the reciprocal connections between adjoining visual cortical areas in determining neural response properties. In particular, the model demonstrates the possible role of feedback from higher cortical areas in mediating neurophysiological effects due to stimuli from beyond the classical receptive field. Simulations of the model are provided that help explain the experimental observations regarding neural responses in both free viewing and fixating conditions.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Temporal decorrelation: a theory of lagged and nonlagged responses in the lateral geniculate nucleus\",\"year\":\"1995\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Dawei W\",\"lastName\":\"Dong\"},{\"creatorType\":\"author\",\"firstName\":\"Joseph J\",\"lastName\":\"Atick\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Network: Computation in neural systems\"},{\"title\":\"Predictive coding: a fresh view of inhibition in the retina\",\"year\":\"1982\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Mandyam Veerambudi\",\"lastName\":\"Srinivasan\"},{\"creatorType\":\"author\",\"firstName\":\"Simon Barry\",\"lastName\":\"Laughlin\"},{\"creatorType\":\"author\",\"firstName\":\"Andreas\",\"lastName\":\"Dubs\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Proceedings of the Royal Society of London. Series B. Biological Sciences\"},{\"title\":\"Handbuch der physiologischen Optik: mit 213 in den Text eingedruckten Holzschnitten und 11 Tafeln\",\"year\":\"1867\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Hermann\",\"lastName\":\"Von Helmholtz\"}],\"topic\":\"Bayesian Perception\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Perceptions as hypotheses\",\"year\":\"1980\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Richard Langton\",\"lastName\":\"Gregory\"},{\"creatorType\":\"author\",\"firstName\":\"Hugh Christopher\",\"lastName\":\"Longuet-Higgins\"},{\"creatorType\":\"author\",\"firstName\":\"N. S.\",\"lastName\":\"Sutherland\"}],\"topic\":\"Bayesian Perception\",\"notes\":\"Perceptions may be compared with hypotheses in science. The methods of acquiring scientific knowledge provide a working paradigm for investigating processes of perception. Much as the information channels of instruments, such as radio telescopes, transmit signals which are processed according to various assumptions to give useful data, so neural signals are processed to give data for perception. To understand perception, the signal codes and the stored knowledge or assumptions used for deriving perceptual hypotheses must be discovered. Systematic perceptual errors are important clues for appreciating signal channel limitations, and for discovering hypothesis-generating procedures. Although this distinction between \\u2018physiological\\u2019 and \\u2018cognitive\\u2019 aspects of perception may be logically clear, it is in practice surprisingly difficult to establish which are responsible even for clearly established phenomena such as the classical distortion illusions. Experimental results are presented, aimed at distinguishing between and discovering what happens when there is mismatch with the neural signal channel, and when neural signals are processed inappropriately for the current situation. This leads us to make some distinctions between perceptual and scientific hypotheses, which raise in a new form the problem: What are \\u2018objects\\u2019?\",\"publicationTitle\":\"Philosophical Transactions of the Royal Society of London. B, Biological Sciences\"},{\"title\":\"Feedback Connections Act on the Early Part of the Responses in Monkey Visual Cortex\",\"year\":\"2001\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jean-Michel\",\"lastName\":\"Hup\\u00e9\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew C.\",\"lastName\":\"James\"},{\"creatorType\":\"author\",\"firstName\":\"Pascal\",\"lastName\":\"Girard\"},{\"creatorType\":\"author\",\"firstName\":\"Stephen G.\",\"lastName\":\"Lomber\"},{\"creatorType\":\"author\",\"firstName\":\"Bertram R.\",\"lastName\":\"Payne\"},{\"creatorType\":\"author\",\"firstName\":\"Jean\",\"lastName\":\"Bullier\"}],\"topic\":\"Predictive Coding\",\"notes\":\"We previously showed that feedback connections from MT play a role in figure\\/ground segmentation. Figure\\/ground coding has been described at the V1 level in the late part of the neuronal responses to visual stimuli, and it has been suggested that these late modulations depend on feedback connections. In the present work we tested whether it actually takes time for this information to be fed back to lower order areas. We analyzed the extracellular responses of 169 V1, V2, and V3 neurons that we recorded in two anesthetized macaque monkeys. MT was inactivated by cooling. We studied the time course of the responses of the neurons that were significantly affected by the inactivation of MT to see whether the effects were delayed relative to the onset of the response. We first measured the time course of the feedback influences from MT on V1, V2, and V3 neurons tested with moving stimuli. For the large majority of the 51 neurons for which the response decreased, the effect was present from the beginning of the response. In the responses averaged after normalization, the decrease of response was significant in the first 10-ms bin of response. A similar result was found for six neurons for which the response significantly increased when MT was inactivated. We then looked at the time course of the responses to flashed stimuli (95 neurons). We observed 15 significant decreases of response and 14 significant increases. In both populations, the effects were significant within the first 10 ms of response. For some neurons with increased responses we even observed a shorter latency when MT was inactivated. We measured the latency of the response to the flashed stimuli. We found that even the earliest responding neurons were affected early by the feedback from MT. This was true for the response to flashed and to moving stimuli. These results show that feedback connections are recruited very early for the treatment of visual information. It further indicates that the presence or absence of feedback effects cannot be deduced from the time course of the response modulations.\",\"publicationTitle\":\"Journal of Neurophysiology\"},{\"title\":\"Synaptic plasticity as Bayesian inference\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Laurence\",\"lastName\":\"Aitchison\"},{\"creatorType\":\"author\",\"firstName\":\"Jannes\",\"lastName\":\"Jegminat\"},{\"creatorType\":\"author\",\"firstName\":\"Jorge Aurelio\",\"lastName\":\"Menendez\"},{\"creatorType\":\"author\",\"firstName\":\"Jean-Pascal\",\"lastName\":\"Pfister\"},{\"creatorType\":\"author\",\"firstName\":\"Alexandre\",\"lastName\":\"Pouget\"},{\"creatorType\":\"author\",\"firstName\":\"Peter E.\",\"lastName\":\"Latham\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Spatio-temporal Representations of Uncertainty in Spiking Neural Networks\",\"year\":\"2014\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Cristina\",\"lastName\":\"Savin\"},{\"creatorType\":\"author\",\"firstName\":\"Sophie\",\"lastName\":\"Den\\u00e8ve\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Advances in Neural Information Processing Systems\"},{\"title\":\"Cortical ensembles selective for context\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jordan P.\",\"lastName\":\"Hamm\"},{\"creatorType\":\"author\",\"firstName\":\"Yuriy\",\"lastName\":\"Shymkiv\"},{\"creatorType\":\"author\",\"firstName\":\"Shuting\",\"lastName\":\"Han\"},{\"creatorType\":\"author\",\"firstName\":\"Weijian\",\"lastName\":\"Yang\"},{\"creatorType\":\"author\",\"firstName\":\"Rafael\",\"lastName\":\"Yuste\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Neural processing of sensory information is strongly influenced by context. For instance, cortical responses are reduced to predictable stimuli, while responses are increased to novel stimuli that deviate from contextual regularities. Such bidirectional modulation based on preceding sensory context is likely a critical component or manifestation of attention, learning, and behavior, yet how it arises in cortical circuits remains unclear. Using volumetric two-photon calcium imaging and local field potentials in primary visual cortex (V1) from awake mice presented with visual \\u201coddball\\u201d paradigms, we identify both reductions and augmentations of stimulus-evoked responses depending, on whether the stimulus was redundant or deviant, respectively. Interestingly, deviance-augmented responses were limited to a specific subset of neurons mostly in supragranular layers. These deviance-detecting cells were spatially intermixed with other visually responsive neurons and were functionally correlated, forming a neuronal ensemble. Optogenetic suppression of prefrontal inputs to V1 reduced the contextual selectivity of deviance-detecting ensembles, demonstrating a causal role for top-down inputs. The presence of specialized context-selective ensembles in primary sensory cortex, modulated by higher cortical areas, provides a circuit substrate for the brain\\u2019s construction and selection of prediction errors, computations which are key for survival and deficient in many psychiatric disorders.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"A Large-Scale Circuit Mechanism for Hierarchical Dynamical Processing in the Primate Cortex\",\"year\":\"2015\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rishidev\",\"lastName\":\"Chaudhuri\"},{\"creatorType\":\"author\",\"firstName\":\"Kenneth\",\"lastName\":\"Knoblauch\"},{\"creatorType\":\"author\",\"firstName\":\"Marie-Alice\",\"lastName\":\"Gariel\"},{\"creatorType\":\"author\",\"firstName\":\"Henry\",\"lastName\":\"Kennedy\"},{\"creatorType\":\"author\",\"firstName\":\"Xiao-Jing\",\"lastName\":\"Wang\"}],\"topic\":\"Neurophysiology\",\"notes\":\"We developed a large-scale dynamical model of the\\u00a0macaque neocortex, which is based on recently acquired directed- and weighted-connectivity data from tract-tracing experiments, and which incorporates heterogeneity across areas. A hierarchy of timescales naturally emerges from this system: sensory areas show brief, transient responses to input (appropriate for sensory processing), whereas association areas integrate inputs over time and exhibit persistent activity (suitable for decision-making and working memory). The model displays multiple temporal hierarchies, as evidenced by contrasting responses to visual versus somatosensory stimulation. Moreover, slower prefrontal and temporal areas have a disproportionate impact on global brain dynamics. These findings establish a circuit mechanism for \\u201ctemporal receptive windows\\u201d that are progressively enlarged along the cortical hierarchy, suggest an extension of time integration in decision making from local to large circuits, and should prompt a re-evaluation of the analysis of functional connectivity (measured by fMRI or electroencephalography\\/magnetoencephalography) by taking into account inter-areal heterogeneity.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Survey of spiking in the mouse visual system reveals functional hierarchy\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Joshua H.\",\"lastName\":\"Siegle\"},{\"creatorType\":\"author\",\"firstName\":\"Xiaoxuan\",\"lastName\":\"Jia\"},{\"creatorType\":\"author\",\"firstName\":\"S\\u00e9verine\",\"lastName\":\"Durand\"},{\"creatorType\":\"author\",\"firstName\":\"Sam\",\"lastName\":\"Gale\"},{\"creatorType\":\"author\",\"firstName\":\"Corbett\",\"lastName\":\"Bennett\"},{\"creatorType\":\"author\",\"firstName\":\"Nile\",\"lastName\":\"Graddis\"},{\"creatorType\":\"author\",\"firstName\":\"Greggory\",\"lastName\":\"Heller\"},{\"creatorType\":\"author\",\"firstName\":\"Tamina K.\",\"lastName\":\"Ramirez\"},{\"creatorType\":\"author\",\"firstName\":\"Hannah\",\"lastName\":\"Choi\"},{\"creatorType\":\"author\",\"firstName\":\"Jennifer A.\",\"lastName\":\"Luviano\"},{\"creatorType\":\"author\",\"firstName\":\"Peter A.\",\"lastName\":\"Groblewski\"},{\"creatorType\":\"author\",\"firstName\":\"Ruweida\",\"lastName\":\"Ahmed\"},{\"creatorType\":\"author\",\"firstName\":\"Anton\",\"lastName\":\"Arkhipov\"},{\"creatorType\":\"author\",\"firstName\":\"Amy\",\"lastName\":\"Bernard\"},{\"creatorType\":\"author\",\"firstName\":\"Yazan N.\",\"lastName\":\"Billeh\"},{\"creatorType\":\"author\",\"firstName\":\"Dillan\",\"lastName\":\"Brown\"},{\"creatorType\":\"author\",\"firstName\":\"Michael A.\",\"lastName\":\"Buice\"},{\"creatorType\":\"author\",\"firstName\":\"Nicolas\",\"lastName\":\"Cain\"},{\"creatorType\":\"author\",\"firstName\":\"Shiella\",\"lastName\":\"Caldejon\"},{\"creatorType\":\"author\",\"firstName\":\"Linzy\",\"lastName\":\"Casal\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew\",\"lastName\":\"Cho\"},{\"creatorType\":\"author\",\"firstName\":\"Maggie\",\"lastName\":\"Chvilicek\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy C.\",\"lastName\":\"Cox\"},{\"creatorType\":\"author\",\"firstName\":\"Kael\",\"lastName\":\"Dai\"},{\"creatorType\":\"author\",\"firstName\":\"Daniel J.\",\"lastName\":\"Denman\"},{\"creatorType\":\"author\",\"firstName\":\"Saskia E. J.\",\"lastName\":\"de Vries\"},{\"creatorType\":\"author\",\"firstName\":\"Roald\",\"lastName\":\"Dietzman\"},{\"creatorType\":\"author\",\"firstName\":\"Luke\",\"lastName\":\"Esposito\"},{\"creatorType\":\"author\",\"firstName\":\"Colin\",\"lastName\":\"Farrell\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Feng\"},{\"creatorType\":\"author\",\"firstName\":\"John\",\"lastName\":\"Galbraith\"},{\"creatorType\":\"author\",\"firstName\":\"Marina\",\"lastName\":\"Garrett\"},{\"creatorType\":\"author\",\"firstName\":\"Emily C.\",\"lastName\":\"Gelfand\"},{\"creatorType\":\"author\",\"firstName\":\"Nicole\",\"lastName\":\"Hancock\"},{\"creatorType\":\"author\",\"firstName\":\"Julie A.\",\"lastName\":\"Harris\"},{\"creatorType\":\"author\",\"firstName\":\"Robert\",\"lastName\":\"Howard\"},{\"creatorType\":\"author\",\"firstName\":\"Brian\",\"lastName\":\"Hu\"},{\"creatorType\":\"author\",\"firstName\":\"Ross\",\"lastName\":\"Hytnen\"},{\"creatorType\":\"author\",\"firstName\":\"Ramakrishnan\",\"lastName\":\"Iyer\"},{\"creatorType\":\"author\",\"firstName\":\"Erika\",\"lastName\":\"Jessett\"},{\"creatorType\":\"author\",\"firstName\":\"Katelyn\",\"lastName\":\"Johnson\"},{\"creatorType\":\"author\",\"firstName\":\"India\",\"lastName\":\"Kato\"},{\"creatorType\":\"author\",\"firstName\":\"Justin\",\"lastName\":\"Kiggins\"},{\"creatorType\":\"author\",\"firstName\":\"Sophie\",\"lastName\":\"Lambert\"},{\"creatorType\":\"author\",\"firstName\":\"Jerome\",\"lastName\":\"Lecoq\"},{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Ledochowitsch\"},{\"creatorType\":\"author\",\"firstName\":\"Jung Hoon\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Arielle\",\"lastName\":\"Leon\"},{\"creatorType\":\"author\",\"firstName\":\"Yang\",\"lastName\":\"Li\"},{\"creatorType\":\"author\",\"firstName\":\"Elizabeth\",\"lastName\":\"Liang\"},{\"creatorType\":\"author\",\"firstName\":\"Fuhui\",\"lastName\":\"Long\"},{\"creatorType\":\"author\",\"firstName\":\"Kyla\",\"lastName\":\"Mace\"},{\"creatorType\":\"author\",\"firstName\":\"Jose\",\"lastName\":\"Melchior\"},{\"creatorType\":\"author\",\"firstName\":\"Daniel\",\"lastName\":\"Millman\"},{\"creatorType\":\"author\",\"firstName\":\"Tyler\",\"lastName\":\"Mollenkopf\"},{\"creatorType\":\"author\",\"firstName\":\"Chelsea\",\"lastName\":\"Nayan\"},{\"creatorType\":\"author\",\"firstName\":\"Lydia\",\"lastName\":\"Ng\"},{\"creatorType\":\"author\",\"firstName\":\"Kiet\",\"lastName\":\"Ngo\"},{\"creatorType\":\"author\",\"firstName\":\"Thuyahn\",\"lastName\":\"Nguyen\"},{\"creatorType\":\"author\",\"firstName\":\"Philip R.\",\"lastName\":\"Nicovich\"},{\"creatorType\":\"author\",\"firstName\":\"Kat\",\"lastName\":\"North\"},{\"creatorType\":\"author\",\"firstName\":\"Gabriel Koch\",\"lastName\":\"Ocker\"},{\"creatorType\":\"author\",\"firstName\":\"Doug\",\"lastName\":\"Ollerenshaw\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"Oliver\"},{\"creatorType\":\"author\",\"firstName\":\"Marius\",\"lastName\":\"Pachitariu\"},{\"creatorType\":\"author\",\"firstName\":\"Jed\",\"lastName\":\"Perkins\"},{\"creatorType\":\"author\",\"firstName\":\"Melissa\",\"lastName\":\"Reding\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Reid\"},{\"creatorType\":\"author\",\"firstName\":\"Miranda\",\"lastName\":\"Robertson\"},{\"creatorType\":\"author\",\"firstName\":\"Kara\",\"lastName\":\"Ronellenfitch\"},{\"creatorType\":\"author\",\"firstName\":\"Sam\",\"lastName\":\"Seid\"},{\"creatorType\":\"author\",\"firstName\":\"Cliff\",\"lastName\":\"Slaughterbeck\"},{\"creatorType\":\"author\",\"firstName\":\"Michelle\",\"lastName\":\"Stoecklin\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Sullivan\"},{\"creatorType\":\"author\",\"firstName\":\"Ben\",\"lastName\":\"Sutton\"},{\"creatorType\":\"author\",\"firstName\":\"Jackie\",\"lastName\":\"Swapp\"},{\"creatorType\":\"author\",\"firstName\":\"Carol\",\"lastName\":\"Thompson\"},{\"creatorType\":\"author\",\"firstName\":\"Kristen\",\"lastName\":\"Turner\"},{\"creatorType\":\"author\",\"firstName\":\"Wayne\",\"lastName\":\"Wakeman\"},{\"creatorType\":\"author\",\"firstName\":\"Jennifer D.\",\"lastName\":\"Whitesell\"},{\"creatorType\":\"author\",\"firstName\":\"Derric\",\"lastName\":\"Williams\"},{\"creatorType\":\"author\",\"firstName\":\"Ali\",\"lastName\":\"Williford\"},{\"creatorType\":\"author\",\"firstName\":\"Rob\",\"lastName\":\"Young\"},{\"creatorType\":\"author\",\"firstName\":\"Hongkui\",\"lastName\":\"Zeng\"},{\"creatorType\":\"author\",\"firstName\":\"Sarah\",\"lastName\":\"Naylor\"},{\"creatorType\":\"author\",\"firstName\":\"John W.\",\"lastName\":\"Phillips\"},{\"creatorType\":\"author\",\"firstName\":\"R. Clay\",\"lastName\":\"Reid\"},{\"creatorType\":\"author\",\"firstName\":\"Stefan\",\"lastName\":\"Mihalas\"},{\"creatorType\":\"author\",\"firstName\":\"Shawn R.\",\"lastName\":\"Olsen\"},{\"creatorType\":\"author\",\"firstName\":\"Christof\",\"lastName\":\"Koch\"}],\"topic\":\"Neurophysiology\",\"notes\":\"The anatomy of the mammalian visual system, from the retina to the neocortex, is organized hierarchically1. However, direct observation of cellular-level functional interactions across this hierarchy is lacking due to the challenge of simultaneously recording activity across numerous regions. Here we describe a large, open dataset\\u2014part of the Allen Brain Observatory2\\u2014that surveys spiking from tens of thousands of units in six cortical and two thalamic regions in the brains of mice responding to a battery of visual stimuli. Using cross-correlation analysis, we reveal that the organization of inter-area functional connectivity during visual stimulation mirrors the anatomical hierarchy from the Allen Mouse Brain Connectivity Atlas3. We find that four classical hierarchical measures\\u2014response latency, receptive-field size, phase-locking to drifting gratings and response decay timescale\\u2014are all correlated with the hierarchy. Moreover, recordings obtained during a visual task reveal that the correlation between neural activity and behavioural choice also increases along the hierarchy. Our study provides a foundation for understanding coding and signal propagation across hierarchically organized cortical and thalamic visual areas.\",\"publicationTitle\":\"Nature\"},{\"title\":\"A Comparative Study of Shape Representation in Macaque Visual Areas V2 and V4\",\"year\":\"2007\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jay\",\"lastName\":\"Hegd\\u00e9\"},{\"creatorType\":\"author\",\"firstName\":\"David C.\",\"lastName\":\"Van Essen\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Cerebral Cortex\"},{\"title\":\"Responses to Contour Features in Macaque Area V4\",\"year\":\"1999\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Anitha\",\"lastName\":\"Pasupathy\"},{\"creatorType\":\"author\",\"firstName\":\"Charles E.\",\"lastName\":\"Connor\"}],\"topic\":\"Neurophysiology\",\"notes\":\"The ventral pathway in visual cortex is responsible for the perception of shape. Area V4 is an important intermediate stage in this pathway, and provides the major input to the final stages in inferotemporal cortex. The role of V4 in processing shape information is not yet clear. We studied V4 responses to contour features (angles and curves), which many theorists have proposed as intermediate shape primitives. We used a large parametric set of contour features to test the responses of 152 V4 cells in two awake macaque monkeys. Most cells responded better to contour features than to edges or bars, and about one-third exhibited systematic tuning for contour features. In particular, many cells were selective for contour feature orientation, responding to angles and curves pointing in a particular direction. There was a strong bias toward convex (as opposed to concave) features, implying a neural basis for the well-known perceptual dominance of convexity. Our results suggest that V4 processes information about contour features as a step toward complex shape recognition.\",\"publicationTitle\":\"Journal of Neurophysiology\"},{\"title\":\"Selectivity for Complex Shapes in Primate Visual Area V2\",\"year\":\"2000\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jay\",\"lastName\":\"Hegd\\u00e9\"},{\"creatorType\":\"author\",\"firstName\":\"David C.\",\"lastName\":\"Van Essen\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"The Journal of Neuroscience\"},{\"title\":\"Distributed Hierarchical Processing in the Primate Cerebral Cortex\",\"year\":\"1991\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"D. J.\",\"lastName\":\"Felleman\"},{\"creatorType\":\"author\",\"firstName\":\"D. C.\",\"lastName\":\"Van Essen\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Cerebral Cortex\"},{\"title\":\"Where is the sun?\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jennifer\",\"lastName\":\"Sun\"},{\"creatorType\":\"author\",\"firstName\":\"Pietro\",\"lastName\":\"Perona\"}],\"topic\":\"Bayesian Perception\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Neural bases of binocular rivalry\",\"year\":\"2006\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Frank\",\"lastName\":\"Tong\"},{\"creatorType\":\"author\",\"firstName\":\"Ming\",\"lastName\":\"Meng\"},{\"creatorType\":\"author\",\"firstName\":\"Randolph\",\"lastName\":\"Blake\"}],\"topic\":\"Bayesian Perception\",\"notes\":\"\",\"publicationTitle\":\"Trends in Cognitive Sciences\"},{\"title\":\"With or without you: predictive coding and Bayesian inference in the brain\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Laurence\",\"lastName\":\"Aitchison\"},{\"creatorType\":\"author\",\"firstName\":\"M\\u00e1t\\u00e9\",\"lastName\":\"Lengyel\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Two theoretical ideas have emerged recently with the ambition to provide a unifying functional explanation of neural population coding and dynamics: predictive coding and Bayesian inference. Here, we describe the two theories and their combination into a single framework: Bayesian predictive coding. We clarify how the two theories can be distinguished, despite sharing core computational concepts and addressing an overlapping set of empirical phenomena. We argue that predictive coding is an algorithmic\\/representational motif that can serve several different computational goals of which Bayesian inference is but one. Conversely, while Bayesian inference can utilize predictive coding, it can also be realized by a variety of other representations. We critically evaluate the experimental evidence supporting Bayesian predictive coding and discuss how to test it more directly.\",\"publicationTitle\":\"Current Opinion in Neurobiology\"},{\"title\":\"Mismatch Receptive Fields in Mouse Visual Cortex\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Pawel\",\"lastName\":\"Zmarz\"},{\"creatorType\":\"author\",\"firstName\":\"Georg B.\",\"lastName\":\"Keller\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Learning from unexpected events in the neocortical microcircuit\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Colleen J.\",\"lastName\":\"Gillon\"},{\"creatorType\":\"author\",\"firstName\":\"Jason E.\",\"lastName\":\"Pina\"},{\"creatorType\":\"author\",\"firstName\":\"J\\u00e9r\\u00f4me A.\",\"lastName\":\"Lecoq\"},{\"creatorType\":\"author\",\"firstName\":\"Ruweida\",\"lastName\":\"Ahmed\"},{\"creatorType\":\"author\",\"firstName\":\"Yazan\",\"lastName\":\"Billeh\"},{\"creatorType\":\"author\",\"firstName\":\"Shiella\",\"lastName\":\"Caldejon\"},{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Groblewski\"},{\"creatorType\":\"author\",\"firstName\":\"Tim M.\",\"lastName\":\"Henley\"},{\"creatorType\":\"author\",\"firstName\":\"India\",\"lastName\":\"Kato\"},{\"creatorType\":\"author\",\"firstName\":\"Eric\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Jennifer\",\"lastName\":\"Luviano\"},{\"creatorType\":\"author\",\"firstName\":\"Kyla\",\"lastName\":\"Mace\"},{\"creatorType\":\"author\",\"firstName\":\"Chelsea\",\"lastName\":\"Nayan\"},{\"creatorType\":\"author\",\"firstName\":\"Thuyanh\",\"lastName\":\"Nguyen\"},{\"creatorType\":\"author\",\"firstName\":\"Kat\",\"lastName\":\"North\"},{\"creatorType\":\"author\",\"firstName\":\"Jed\",\"lastName\":\"Perkins\"},{\"creatorType\":\"author\",\"firstName\":\"Sam\",\"lastName\":\"Seid\"},{\"creatorType\":\"author\",\"firstName\":\"Matthew\",\"lastName\":\"Valley\"},{\"creatorType\":\"author\",\"firstName\":\"Ali\",\"lastName\":\"Williford\"},{\"creatorType\":\"author\",\"firstName\":\"Yoshua\",\"lastName\":\"Bengio\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy P.\",\"lastName\":\"Lillicrap\"},{\"creatorType\":\"author\",\"firstName\":\"Blake A.\",\"lastName\":\"Richards\"},{\"creatorType\":\"author\",\"firstName\":\"Joel\",\"lastName\":\"Zylberberg\"}],\"topic\":\"Predictive Coding\",\"notes\":\"<h3>Abstract<\\/h3> <p>Scientists have long conjectured that the neocortex learns the structure of the environment in a predictive, hierarchical manner. To do so, expected, predictable features are differentiated from unexpected ones by comparing bottom-up and top-down streams of data. It is theorized that the neocortex then changes the representation of incoming stimuli, guided by differences in the responses to expected and unexpected events. Such differences in cortical responses have been observed; however, it remains unknown whether these unexpected event signals govern subsequent changes in the brain\\u2019s stimulus representations, and, thus, govern learning. Here, we show that unexpected event signals predict subsequent changes in responses to expected and unexpected stimuli in individual neurons and distal apical dendrites that are tracked over a period of days. These findings were obtained by observing layer 2\\/3 and layer 5 pyramidal neurons in primary visual cortex of awake, behaving mice using two-photon calcium imaging. We found that many neurons in both layers 2\\/3 and 5 showed large differences between their responses to expected and unexpected events. These unexpected event signals also determined how the responses evolved over subsequent days, in a manner that was different between the somata and distal apical dendrites. This difference between the somata and distal apical dendrites may be important for hierarchical computation, given that these two compartments tend to receive bottom-up and top-down information, respectively. Together, our results provide novel evidence that the neocortex indeed instantiates a predictive hierarchical model in which unexpected events drive learning.<\\/p>\",\"publicationTitle\":\"bioRxiv\"},{\"title\":\"Activity recall in a visual cortical ensemble\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Shengjin\",\"lastName\":\"Xu\"},{\"creatorType\":\"author\",\"firstName\":\"Wanchen\",\"lastName\":\"Jiang\"},{\"creatorType\":\"author\",\"firstName\":\"Mu-ming\",\"lastName\":\"Poo\"},{\"creatorType\":\"author\",\"firstName\":\"Yang\",\"lastName\":\"Dan\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Recording in the rat primary visual cortex, this study finds that after repeated exposure to a light spot moving along the same path, just seeing the static spot at its start position is sufficient to cause the sequence of activity associated with the movements of the spot along its path. This activity may contribute to cue-triggered recall of learned sequences.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Learned spatiotemporal sequence recognition and prediction in primary visual cortex\",\"year\":\"2014\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jeffrey P.\",\"lastName\":\"Gavornik\"},{\"creatorType\":\"author\",\"firstName\":\"Mark F.\",\"lastName\":\"Bear\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Here the authors report that repeated presentations of a visual sequence over a course of days causes evoked response potentiation in mouse V1 that is highly specific for stimulus order and timing. After V1 is trained to recognize a sequence, cortical activity regenerates the full sequence even when individual stimulus elements are omitted.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Limited Evidence for Sensory Prediction Error Responses in Visual Cortex of Macaques and Humans\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Selina S\",\"lastName\":\"Solomon\"},{\"creatorType\":\"author\",\"firstName\":\"Huizhen\",\"lastName\":\"Tang\"},{\"creatorType\":\"author\",\"firstName\":\"Elyse\",\"lastName\":\"Sussman\"},{\"creatorType\":\"author\",\"firstName\":\"Adam\",\"lastName\":\"Kohn\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A recent formulation of predictive coding theory proposes that a subset of neurons in each cortical area encodes sensory prediction errors, the difference between predictions relayed from higher cortex and the sensory input. Here, we test for evidence of prediction error responses in spiking responses and local field potentials (LFP) recorded in primary visual cortex and area V4 of macaque monkeys, and in complementary electroencephalographic (EEG) scalp recordings in human participants. We presented a fixed sequence of visual stimuli on most trials, and violated the expected ordering on a small subset of trials. Under predictive coding theory, pattern-violating stimuli should trigger robust prediction errors, but we found that spiking, LFP and EEG responses to expected and pattern-violating stimuli were nearly identical. Our results challenge the assertion that a fundamental computational motif in sensory cortex is to signal prediction errors, at least those based on predictions derived from temporal patterns of visual stimulation.\",\"publicationTitle\":\"Cerebral Cortex\"},{\"title\":\"Theory of cortical function\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David J.\",\"lastName\":\"Heeger\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Most models of sensory processing in the brain have a feedforward architecture in which each stage comprises simple linear filtering operations and nonlinearities. Models of this form have been used to explain a wide range of neurophysiological and psychophysical data, and many recent successes in artificial intelligence (with deep convolutional neural nets) are based on this architecture. However, neocortex is not a feedforward architecture. This paper proposes a first step toward an alternative computational framework in which neural activity in each brain area depends on a combination of feedforward drive (bottom-up from the previous processing stage), feedback drive (top-down context from the next stage), and prior drive (expectation). The relative contributions of feedforward drive, feedback drive, and prior drive are controlled by a handful of state parameters, which I hypothesize correspond to neuromodulators and oscillatory activity. In some states, neural responses are dominated by the feedforward drive and the theory is identical to a conventional feedforward model, thereby preserving all of the desirable features of those models. In other states, the theory is a generative model that constructs a sensory representation from an abstract representation, like memory recall. In still other states, the theory combines prior expectation with sensory input, explores different possible perceptual interpretations of ambiguous sensory inputs, and predicts forward in time. The theory, therefore, offers an empirically testable framework for understanding how the cortex accomplishes inference, exploration, and prediction.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Generation of end-inhibition in the visual cortex via interlaminar connections\",\"year\":\"1986\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"J\\u00fcrgen\",\"lastName\":\"Bolz\"},{\"creatorType\":\"author\",\"firstName\":\"Charles D.\",\"lastName\":\"Gilbert\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"How to Train Your Energy-Based Models\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yang\",\"lastName\":\"Song\"},{\"creatorType\":\"author\",\"firstName\":\"Diederik P.\",\"lastName\":\"Kingma\"}],\"topic\":\"Generative Models\",\"notes\":\"Energy-Based Models (EBMs), also known as non-normalized probabilistic models, specify probability density or mass functions up to an unknown normalizing constant. Unlike most other probabilistic models, EBMs do not place a restriction on the tractability of the normalizing constant, thus are more flexible to parameterize and can model a more expressive family of probability distributions. However, the unknown normalizing constant of EBMs makes training particularly difficult. Our goal is to provide a friendly introduction to modern approaches for EBM training. We start by explaining maximum likelihood training with Markov chain Monte Carlo (MCMC), and proceed to elaborate on MCMC-free approaches, including Score Matching (SM) and Noise Constrastive Estimation (NCE). We highlight theoretical connections among these three approaches, and end with a brief survey on alternative training methods, which are still under active research. Our tutorial is targeted at an audience with basic understanding of generative models who want to apply EBMs or start a research project in this direction.\",\"publicationTitle\":\"arXiv:2101.03288 [cs, stat]\"},{\"title\":\"Motion Integration and Postdiction in Visual Awareness\",\"year\":\"2000\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David M.\",\"lastName\":\"Eagleman\"},{\"creatorType\":\"author\",\"firstName\":\"Terrence J.\",\"lastName\":\"Sejnowski\"}],\"topic\":\"Predictive Coding\",\"notes\":\"In the flash-lag illusion, a flash and a moving object in the same location appear to be offset. A series of psychophysical experiments yields data inconsistent with two previously proposed explanations: motion extrapolation (a predictive model) and latency difference (an online model). We propose an alternative in which visual awareness is neither predictive nor online but is postdictive, so that the percept attributed to the time of the flash is a function of events that happen in the \\u223c80 milliseconds after the flash. The results here show how interpolation of the past is the only framework of the three models that provides a unified explanation for the flash-lag phenomenon.\",\"publicationTitle\":\"Science\"},{\"title\":\"Dynamics of Orientation Selectivity in the Primary Visual Cortex and the Importance of Cortical Inhibition\",\"year\":\"2003\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Robert\",\"lastName\":\"Shapley\"},{\"creatorType\":\"author\",\"firstName\":\"Michael\",\"lastName\":\"Hawken\"},{\"creatorType\":\"author\",\"firstName\":\"Dario L.\",\"lastName\":\"Ringach\"}],\"topic\":\"Predictive Coding\",\"notes\":\"To test theories of orientation selectivity in primary visual cortex (V1), we have done experiments to measure the dynamics of orientation tuning of single neurons in the V1 cortex of macaque monkeys. Based on our dynamics results, we propose that a V1 cell's orientation selectivity is generated mainly by both tuned enhancement and global suppression. Enhancement near the preferred orientation is probably caused by feed-forward input from LGN (plus amplification by cortical-cortical interaction). Global suppression could be supplied by cortical inhibition. Additionally, in about 1\\/3 of V1 neurons (usually the most sharply tuned) there is tuned suppression, centered near the cell's preferred orientation but broader than tuned enhancement. These mechanisms also can explain important features of steady-state selectivity in the V1 neuron population. Furthermore, similar neuronal mechanisms may be used generally throughout the cerebral cortex.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Specificity and timescales of cortical adaptation as inferences about natural movie statistics\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Michoel\",\"lastName\":\"Snow\"},{\"creatorType\":\"author\",\"firstName\":\"Ruben\",\"lastName\":\"Coen-Cagli\"},{\"creatorType\":\"author\",\"firstName\":\"Odelia\",\"lastName\":\"Schwartz\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Journal of Vision\"},{\"title\":\"Feedback generates a second receptive field in neurons of the visual cortex\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Andreas J.\",\"lastName\":\"Keller\"},{\"creatorType\":\"author\",\"firstName\":\"Morgane M.\",\"lastName\":\"Roth\"},{\"creatorType\":\"author\",\"firstName\":\"Massimo\",\"lastName\":\"Scanziani\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Animals sense the environment through pathways that link sensory organs to the brain. In the visual system, these feedforward pathways define the classical feedforward receptive field (ffRF), the area in space in which visual stimuli excite a neuron1. The visual system also uses visual context\\u2014the visual scene surrounding a stimulus\\u2014to predict the content of the stimulus2, and accordingly, neurons have been identified that are excited by stimuli outside their ffRF3\\u20138. However, the mechanisms that generate excitation to stimuli outside the ffRF are unclear. Here we show that feedback projections onto excitatory neurons in the mouse primary visual cortex generate a second receptive field that is driven by stimuli outside the ffRF. The stimulation of this feedback receptive field (fbRF) elicits responses that are slower and are delayed in comparison with those resulting from the stimulation of the ffRF. These responses are preferentially reduced by anaesthesia and by silencing higher visual areas. Feedback inputs from higher visual areas have scattered receptive fields relative to their putative targets in the primary visual cortex, which enables the generation of the fbRF. Neurons with fbRFs are located in cortical layers that receive strong feedback projections and are absent in the main input layer, which is consistent with a laminar processing hierarchy. The observation that large, uniform stimuli\\u2014which cover both the fbRF and the ffRF\\u2014suppress these responses indicates that the fbRF and the ffRF are mutually antagonistic. Whereas somatostatin-expressing inhibitory neurons are driven by these large stimuli, inhibitory neurons that express parvalbumin and vasoactive intestinal peptide have mutually antagonistic fbRF and ffRF, similar to excitatory neurons. Feedback projections may therefore enable neurons to use context to estimate information that is missing from the ffRF and to report differences in stimulus features across visual space, regardless of whether excitation occurs inside or outside the ffRF. By complementing the ffRF, the fbRF that we identify here could contribute to predictive processing.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Efficient auditory coding\",\"year\":\"2006\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Evan C.\",\"lastName\":\"Smith\"},{\"creatorType\":\"author\",\"firstName\":\"Michael S.\",\"lastName\":\"Lewicki\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The auditory neural code must serve a wide range of auditory tasks that require great sensitivity in time and frequency and be effective over the diverse array of sounds present in natural acoustic environments. It has been suggested1,2,3,4,5 that sensory systems might have evolved highly efficient coding strategies to maximize the information conveyed to the brain while minimizing the required energy and neural resources. Here we show that, for natural sounds, the complete acoustic waveform can be represented efficiently with a nonlinear model based on a population spike code. In this model, idealized spikes encode the precise temporal positions and magnitudes of underlying acoustic features. We find that when the features are optimized for coding either natural sounds or speech, they show striking similarities to time-domain cochlear filter estimates, have a frequency-bandwidth dependence similar to that of auditory nerve fibres, and yield significantly greater coding efficiency than conventional signal representations. These results indicate that the auditory code might approach an information theoretic optimum and that the acoustic structure of speech might be adapted to the coding capacity of the mammalian auditory system.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Neurons along the auditory pathway exhibit a hierarchical organization of prediction error\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Gloria G.\",\"lastName\":\"Parras\"},{\"creatorType\":\"author\",\"firstName\":\"Javier\",\"lastName\":\"Nieto-Diego\"},{\"creatorType\":\"author\",\"firstName\":\"Guillermo V.\",\"lastName\":\"Carbajal\"},{\"creatorType\":\"author\",\"firstName\":\"Catalina\",\"lastName\":\"Vald\\u00e9s-Baizabal\"},{\"creatorType\":\"author\",\"firstName\":\"Carles\",\"lastName\":\"Escera\"},{\"creatorType\":\"author\",\"firstName\":\"Manuel S.\",\"lastName\":\"Malmierca\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Perception is characterized by a reciprocal exchange of predictions and prediction error signals between neural regions. However, the relationship between such sensory mismatch responses and hierarchical predictive processing has not yet been demonstrated at the neuronal level in the auditory pathway. We recorded single-neuron activity from different auditory centers in anaesthetized rats and awake mice while animals were played a sequence of sounds, designed to separate the responses due to prediction error from those due to adaptation effects. Here we report that prediction error is organized hierarchically along the central auditory pathway. These prediction error signals are detectable in subcortical regions and increase as the signals move towards auditory cortex, which in turn demonstrates a large-scale mismatch potential. Finally, the predictive activity of single auditory neurons underlies automatic deviance detection at subcortical levels of processing. These results demonstrate that prediction error is a fundamental component of singly auditory neuron responses.\",\"publicationTitle\":\"Nature Communications\"},{\"title\":\"Sensory cortex is optimized for prediction of future input\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yosef\",\"lastName\":\"Singer\"},{\"creatorType\":\"author\",\"firstName\":\"Yayoi\",\"lastName\":\"Teramoto\"},{\"creatorType\":\"author\",\"firstName\":\"Ben DB\",\"lastName\":\"Willmore\"},{\"creatorType\":\"author\",\"firstName\":\"Jan WH\",\"lastName\":\"Schnupp\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew J\",\"lastName\":\"King\"},{\"creatorType\":\"author\",\"firstName\":\"Nicol S\",\"lastName\":\"Harper\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Neurons in sensory cortex are tuned to diverse features in natural scenes. But what determines which features neurons become selective to? Here we explore the idea that neuronal selectivity is optimized to represent features in the recent sensory past that best predict immediate future inputs. We tested this hypothesis using simple feedforward neural networks, which were trained to predict the next few moments of video or audio in clips of natural scenes. The networks developed receptive fields that closely matched those of real cortical neurons in different mammalian species, including the oriented spatial tuning of primary visual cortex, the frequency selectivity of primary auditory cortex and, most notably, their temporal tuning properties. Furthermore, the better a network predicted future inputs the more closely its receptive fields resembled those in the brain. This suggests that sensory processing is optimized to extract those features with the most capacity to predict future input.\\n          , \\n            A large part of our brain is devoted to processing the sensory inputs that we receive from the world. This allows us to tell, for example, whether we are looking at a cat or a dog, and if we are hearing a bark or a meow. Neurons in the sensory cortex respond to these stimuli by generating spikes of activity. Within each sensory area, neurons respond best to stimuli with precise properties: those in the primary visual cortex prefer edge-like structures that move in a certain direction at a given speed, while neurons in the primary auditory cortex favour sounds that change in loudness over a particular range of frequencies.\\n            Singer et al. sought to understand why neurons respond to the particular features of stimuli that they do. Why do visual neurons react more to moving edges than to, say, rotating hexagons? And why do auditory neurons respond more to certain changing sounds than to, say, constant tones? One leading idea is that the brain tries to use as few spikes as possible to represent real-world stimuli. Known as sparse coding, this principle can account for much of the behaviour of sensory neurons.\\n            Another possibility is that sensory areas respond the way they do because it enables them to best predict future sensory input. To test this idea, Singer et al. used a computer to simulate a network of neurons and trained this network to predict the next few frames of video clips using the previous few frames. When the network had learned this task, Singer et al. examined the neurons\\u2019 preferred stimuli. Like neurons in primary visual cortex, the simulated neurons typically responded most to edges that moved over time.\\n            The same network was also trained in a similar way, but this time using sound. As for neurons in primary auditory cortex, the simulated neurons preferred sounds that changed in loudness at particular frequencies. Notably, for both vision and audition, the simulated neurons favoured recent inputs over those further into the past. In this way and others, they were more similar to real neurons than simulated neurons that used sparse coding.\\n            Both artificial networks trained to foretell sensory input and the brain therefore favour the same types of stimuli: the ones that are good at helping to grasp future information. This suggests that the brain represents the sensory world so as to be able to best predict the future.\\n            Knowing how the brain handles information from our senses may help to understand disorders associated with sensory processing, such as dyslexia and tinnitus. It may also inspire approaches for training machines to process sensory inputs, improving artificial intelligence.\",\"publicationTitle\":\"eLife\"},{\"title\":\"Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects\",\"year\":\"1999\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Dana H.\",\"lastName\":\"Ballard\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"A goal-driven modular neural network predicts parietofrontal neural dynamics during grasping\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jonathan A.\",\"lastName\":\"Michaels\"},{\"creatorType\":\"author\",\"firstName\":\"Stefan\",\"lastName\":\"Schaffelhofer\"},{\"creatorType\":\"author\",\"firstName\":\"Andres\",\"lastName\":\"Agudelo-Toro\"},{\"creatorType\":\"author\",\"firstName\":\"Hansj\\u00f6rg\",\"lastName\":\"Scherberger\"}],\"topic\":\"Co-processors\",\"notes\":\"One of the primary ways we interact with the world is using our hands. In macaques, the circuit spanning the anterior intraparietal area, the hand area of the ventral premotor cortex, and the primary motor cortex is necessary for transforming visual information into grasping movements. However, no comprehensive model exists that links all steps of processing from vision to action. We hypothesized that a recurrent neural network mimicking the modular structure of the anatomical circuit and trained to use visual features of objects to generate the required muscle dynamics used by primates to grasp objects would give insight into the computations of the grasping circuit. Internal activity of modular networks trained with these constraints strongly resembled neural activity recorded from the grasping circuit during grasping and paralleled the similarities between brain regions. Network activity during the different phases of the task could be explained by linear dynamics for maintaining a distributed movement plan across the network in the absence of visual stimulus and then generating the required muscle kinematics based on these initial conditions in a module-specific way. These modular models also outperformed alternative models at explaining neural data, despite the absence of neural data during training, suggesting that the inputs, outputs, and architectural constraints imposed were sufficient for recapitulating processing in the grasping circuit. Finally, targeted lesioning of modules produced deficits similar to those observed in lesion studies of the grasping circuit, providing a potential model for how brain regions may coordinate during the visually guided grasping of objects.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Low-frequency stimulation enhances ensemble co-firing and dexterity after stroke\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Preeya\",\"lastName\":\"Khanna\"},{\"creatorType\":\"author\",\"firstName\":\"Douglas\",\"lastName\":\"Totten\"},{\"creatorType\":\"author\",\"firstName\":\"Lisa\",\"lastName\":\"Novik\"},{\"creatorType\":\"author\",\"firstName\":\"Jeffrey\",\"lastName\":\"Roberts\"},{\"creatorType\":\"author\",\"firstName\":\"Robert J.\",\"lastName\":\"Morecraft\"},{\"creatorType\":\"author\",\"firstName\":\"Karunesh\",\"lastName\":\"Ganguly\"}],\"topic\":\"Co-processors\",\"notes\":\"Electrical stimulation is a promising tool for modulating brain networks. However, it is unclear how stimulation interacts with neural patterns underlying behavior. Speci\\ufb01cally, how might external stimulation that is not sensitive to the state of ongoing neural dynamics reliably augment neural processing and improve function? Here, we tested how low-frequency epidural alternating current stimulation (ACS) in non-human primates recovering from stroke interacted with task-related activity in perilesional cortex and affected grasping. We found that ACS increased co-\\ufb01ring within task-related ensembles and improved dexterity. Using a neural network model, we found that simulated ACS drove ensemble co-\\ufb01ring and enhanced propagation of neural activity through parts of the network with impaired connectivity, suggesting a mechanism to link increased co-\\ufb01ring to enhanced dexterity. Together, our results demonstrate that ACS restores neural processing in impaired networks and improves dexterity following stroke. More broadly, these results demonstrate approaches to optimize stimulation to target neural dynamics.\",\"publicationTitle\":\"Cell\"},{\"title\":\"A spiking neural model of adaptive arm control\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Travis\",\"lastName\":\"DeWolf\"},{\"creatorType\":\"author\",\"firstName\":\"Terrence C.\",\"lastName\":\"Stewart\"},{\"creatorType\":\"author\",\"firstName\":\"Jean-Jacques\",\"lastName\":\"Slotine\"},{\"creatorType\":\"author\",\"firstName\":\"Chris\",\"lastName\":\"Eliasmith\"}],\"topic\":\"Co-processors\",\"notes\":\"We present a spiking neuron model of the motor cortices and cerebellum of the motor control system. The model consists of anatomically organized spiking neurons encompassing premotor, primary motor, and cerebellar cortices. The model proposes novel neural computations within these areas to control a nonlinear three-link arm model that can adapt to unknown changes in arm dynamics and kinematic structure. We demonstrate the mathematical stability of both forms of adaptation, suggesting that this is a robust approach for common biological problems of changing body size (e.g. during growth), and unexpected dynamic perturbations (e.g. when moving through different media, such as water or mud). To demonstrate the plausibility of the proposed neural mechanisms, we show that the model accounts for data across 19 studies of the motor control system. These data include a mix of behavioural and neural spiking activity, across subjects performing adaptive and static tasks. Given this proposed characterization of the biological processes involved in motor control of the arm, we provide several experimentally testable predictions that distinguish our model from previous work.\",\"publicationTitle\":\"Proceedings of the Royal Society B: Biological Sciences\"},{\"title\":\"Reflections of action in sensory cortex\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David M\",\"lastName\":\"Schneider\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Current Opinion in Neurobiology\"},{\"title\":\"A cortical filter that learns to suppress the acoustic consequences of movement\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David M.\",\"lastName\":\"Schneider\"},{\"creatorType\":\"author\",\"firstName\":\"Janani\",\"lastName\":\"Sundararajan\"},{\"creatorType\":\"author\",\"firstName\":\"Richard\",\"lastName\":\"Mooney\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"Experience-dependent spatial expectations in mouse visual cortex\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Aris\",\"lastName\":\"Fiser\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Mahringer\"},{\"creatorType\":\"author\",\"firstName\":\"Hassana K.\",\"lastName\":\"Oyibo\"},{\"creatorType\":\"author\",\"firstName\":\"Anders V.\",\"lastName\":\"Petersen\"},{\"creatorType\":\"author\",\"firstName\":\"Marcus\",\"lastName\":\"Leinweber\"},{\"creatorType\":\"author\",\"firstName\":\"Georg B.\",\"lastName\":\"Keller\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The authors find that activity in rodent visual cortex can depend on the animal's location in a virtual environment and can predict upcoming visual stimuli. Omitting a stimulus that a mouse expects to see results in a strong mismatch signal, implying that visual cortex compares visual signals to expectations in familiar environments.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Sensorimotor Mismatch Signals in Primary Visual Cortex of the Behaving Mouse\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Georg\\u00a0B.\",\"lastName\":\"Keller\"},{\"creatorType\":\"author\",\"firstName\":\"Tobias\",\"lastName\":\"Bonhoeffer\"},{\"creatorType\":\"author\",\"firstName\":\"Mark\",\"lastName\":\"H\\u00fcbener\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Studies in anesthetized animals have suggested that activity in early visual cortex is mainly driven by visual input and is well described by a feedforward processing hierarchy. However, evidence from experiments on awake animals has shown that both eye movements and behavioral state can strongly modulate responses of neurons in visual cortex; the functional signi\\ufb01cance of this modulation, however, remains elusive. Using visual-\\ufb02ow feedback manipulations during locomotion in a virtual reality environment, we found that responses in layer 2\\/3 of mouse primary visual cortex are strongly driven by locomotion and by mismatch between actual and expected visual feedback. These data suggest that processing in visual cortex may be based on predictive coding strategies that use motor-related and visual input to detect mismatches between predicted and actual visual feedback.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Opposing Influence of Top-down and Bottom-up Input on Excitatory Layer 2\\/3 Neurons in Mouse Primary Visual Cortex\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rebecca\",\"lastName\":\"Jordan\"},{\"creatorType\":\"author\",\"firstName\":\"Georg B.\",\"lastName\":\"Keller\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Processing in cortical circuits is driven by combinations of cortical and subcortical inputs. These inputs are often conceptually categorized as bottom-up, conveying sensory information, and top-down, conveying contextual information. Using intracellular recordings in mouse primary visual cortex, we measured neuronal responses to visual input, locomotion, and visuomotor mismatches. We show that layer 2\\/3 (L2\\/3) neurons compute a difference between top-down motor-related input and bottom-up visual \\ufb02ow input. Most L2\\/3 neurons responded to visuomotor mismatch with either hyperpolarization or depolarization, and the size of this response was correlated with distinct physiological properties. Consistent with a subtraction of bottom-up and top-down input, visual and motor-related inputs had opposing in\\ufb02uence on L2\\/3 neurons. In infragranular neurons, we found no evidence of a difference computation and responses were consistent with positive integration of visuomotor inputs. Our results provide evidence that L2\\/3 functions as a bidirectional comparator of top-down and bottom-up input.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Visual behaviour mediated by retinal projections directed to the auditory pathway\",\"year\":\"2000\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Laurie\",\"lastName\":\"von Melchner\"},{\"creatorType\":\"author\",\"firstName\":\"Sarah L.\",\"lastName\":\"Pallas\"},{\"creatorType\":\"author\",\"firstName\":\"Mriganka\",\"lastName\":\"Sur\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"Induction of visual orientation modules in auditory cortex\",\"year\":\"2000\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jitendra\",\"lastName\":\"Sharma\"},{\"creatorType\":\"author\",\"firstName\":\"Alessandra\",\"lastName\":\"Angelucci\"},{\"creatorType\":\"author\",\"firstName\":\"Mriganka\",\"lastName\":\"Sur\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"Attractor Network Models\",\"year\":\"2009\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"X.-J.\",\"lastName\":\"Wang\"}],\"topic\":\"Attractors\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Linear-time inference in Hierarchical HMMs\",\"year\":\"2002\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Kevin P\",\"lastName\":\"Murphy\"},{\"creatorType\":\"author\",\"firstName\":\"Mark\",\"lastName\":\"Paskin\"},{\"creatorType\":\"editor\",\"firstName\":\"T.\",\"lastName\":\"Dietterich\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Becker\"},{\"creatorType\":\"editor\",\"firstName\":\"Z.\",\"lastName\":\"Ghahramani\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Improved Conditional VRNNs for Video Prediction\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Lluis\",\"lastName\":\"Castrejon\"},{\"creatorType\":\"author\",\"firstName\":\"Nicolas\",\"lastName\":\"Ballas\"},{\"creatorType\":\"author\",\"firstName\":\"Aaron\",\"lastName\":\"Courville\"}],\"topic\":\"Variational Inference\",\"notes\":\"Predicting future frames for a video sequence is a challenging generative modeling task. Promising approaches include probabilistic latent variable models such as the Variational Auto-Encoder. While VAEs can handle uncertainty and model multiple possible future outcomes, they have a tendency to produce blurry predictions. In this work we argue that this is a sign of underfitting. To address this issue, we propose to increase the expressiveness of the latent distributions and to use higher capacity likelihood models. Our approach relies on a hierarchy of latent variables, which defines a family of flexible prior and posterior distributions in order to better model the probability of future sequences. We validate our proposal through a series of ablation experiments and compare our approach to current state-of-the-art latent variable models. Our method performs favorably under several metrics in three different datasets.\",\"publicationTitle\":\"arXiv:1904.12165 [cs]\"},{\"title\":\"Computational Optimal Transport\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Gabriel\",\"lastName\":\"Peyr\\u00e9\"},{\"creatorType\":\"author\",\"firstName\":\"Marco\",\"lastName\":\"Cuturi\"}],\"topic\":\"Math\",\"notes\":\"Optimal transport (OT) theory can be informally described using the words of the French mathematician Gaspard Monge (1746-1818): A worker with a shovel in hand has to move a large pile of sand lying on a construction site. The goal of the worker is to erect with all that sand a target pile with a prescribed shape (for example, that of a giant sand castle). Naturally, the worker wishes to minimize her total effort, quantified for instance as the total distance or time spent carrying shovelfuls of sand. Mathematicians interested in OT cast that problem as that of comparing two probability distributions, two different piles of sand of the same volume. They consider all of the many possible ways to morph, transport or reshape the first pile into the second, and associate a \\\"global\\\" cost to every such transport, using the \\\"local\\\" consideration of how much it costs to move a grain of sand from one place to another. Recent years have witnessed the spread of OT in several fields, thanks to the emergence of approximate solvers that can scale to sizes and dimensions that are relevant to data sciences. Thanks to this newfound scalability, OT is being increasingly used to unlock various problems in imaging sciences (such as color or texture processing), computer vision and graphics (for shape manipulation) or machine learning (for regression, classification and density fitting). This short book reviews OT with a bias toward numerical methods and their applications in data sciences, and sheds lights on the theoretical properties of OT that make it particularly useful for some of these applications.\",\"publicationTitle\":\"arXiv:1803.00567 [stat]\"},{\"title\":\"VAE with a VampPrior\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jakub M.\",\"lastName\":\"Tomczak\"},{\"creatorType\":\"author\",\"firstName\":\"Max\",\"lastName\":\"Welling\"}],\"topic\":\"Variational Inference\",\"notes\":\"Many different methods to train deep generative models have been introduced in the past. In this paper, we propose to extend the variational auto-encoder (VAE) framework with a new type of prior which we call \\\"Variational Mixture of Posteriors\\\" prior, or VampPrior for short. The VampPrior consists of a mixture distribution (e.g., a mixture of Gaussians) with components given by variational posteriors conditioned on learnable pseudo-inputs. We further extend this prior to a two layer hierarchical model and show that this architecture with a coupled prior and posterior, learns significantly better models. The model also avoids the usual local optima issues related to useless latent dimensions that plague VAEs. We provide empirical studies on six datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes, Frey Faces and Histopathology patches, and show that applying the hierarchical VampPrior delivers state-of-the-art results on all datasets in the unsupervised permutation invariant setting and the best results or comparable to SOTA methods for the approach with convolutional networks.\",\"publicationTitle\":\"arXiv:1705.07120 [cs, stat]\"},{\"title\":\"Distributed coding of choice, action and engagement across the mouse brain\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Nicholas A.\",\"lastName\":\"Steinmetz\"},{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Zatka-Haas\"},{\"creatorType\":\"author\",\"firstName\":\"Matteo\",\"lastName\":\"Carandini\"},{\"creatorType\":\"author\",\"firstName\":\"Kenneth D.\",\"lastName\":\"Harris\"}],\"topic\":\"To-Read\",\"notes\":\"Vision, choice, action and behavioural engagement arise from neuronal activity that may be distributed across brain regions. Here we delineate the spatial distribution of neurons underlying these processes. We used Neuropixels probes1,2 to record from approximately 30,000 neurons in 42 brain regions of mice performing a visual discrimination task3. Neurons in nearly all regions responded non-specifically when the mouse initiated an action. By contrast, neurons encoding visual stimuli and upcoming choices occupied restricted regions in the\\u00a0neocortex, basal ganglia and midbrain. Choice signals were rare and emerged with indistinguishable timing across regions. Midbrain neurons were activated before contralateral choices and were suppressed before ipsilateral choices, whereas forebrain neurons could prefer either side. Brain-wide pre-stimulus activity predicted engagement in individual trials and in the overall task, with enhanced subcortical but suppressed neocortical activity during engagement. These results reveal organizing principles for the distribution of neurons encoding behaviourally relevant variables across the mouse brain.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Stimulus onset quenches neural variability: a widespread cortical phenomenon\",\"year\":\"2010\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Mark M.\",\"lastName\":\"Churchland\"},{\"creatorType\":\"author\",\"firstName\":\"Byron M.\",\"lastName\":\"Yu\"},{\"creatorType\":\"author\",\"firstName\":\"John P.\",\"lastName\":\"Cunningham\"},{\"creatorType\":\"author\",\"firstName\":\"Leo P.\",\"lastName\":\"Sugrue\"},{\"creatorType\":\"author\",\"firstName\":\"Marlene R.\",\"lastName\":\"Cohen\"},{\"creatorType\":\"author\",\"firstName\":\"Greg S.\",\"lastName\":\"Corrado\"},{\"creatorType\":\"author\",\"firstName\":\"William T.\",\"lastName\":\"Newsome\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew M.\",\"lastName\":\"Clark\"},{\"creatorType\":\"author\",\"firstName\":\"Paymon\",\"lastName\":\"Hosseini\"},{\"creatorType\":\"author\",\"firstName\":\"Benjamin B.\",\"lastName\":\"Scott\"},{\"creatorType\":\"author\",\"firstName\":\"David C.\",\"lastName\":\"Bradley\"},{\"creatorType\":\"author\",\"firstName\":\"Matthew A.\",\"lastName\":\"Smith\"},{\"creatorType\":\"author\",\"firstName\":\"Adam\",\"lastName\":\"Kohn\"},{\"creatorType\":\"author\",\"firstName\":\"J. Anthony\",\"lastName\":\"Movshon\"},{\"creatorType\":\"author\",\"firstName\":\"Katherine M.\",\"lastName\":\"Armstrong\"},{\"creatorType\":\"author\",\"firstName\":\"Tirin\",\"lastName\":\"Moore\"},{\"creatorType\":\"author\",\"firstName\":\"Steve W.\",\"lastName\":\"Chang\"},{\"creatorType\":\"author\",\"firstName\":\"Lawrence H.\",\"lastName\":\"Snyder\"},{\"creatorType\":\"author\",\"firstName\":\"Stephen G.\",\"lastName\":\"Lisberger\"},{\"creatorType\":\"author\",\"firstName\":\"Nicholas J.\",\"lastName\":\"Priebe\"},{\"creatorType\":\"author\",\"firstName\":\"Ian M.\",\"lastName\":\"Finn\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Ferster\"},{\"creatorType\":\"author\",\"firstName\":\"Stephen I.\",\"lastName\":\"Ryu\"},{\"creatorType\":\"author\",\"firstName\":\"Gopal\",\"lastName\":\"Santhanam\"},{\"creatorType\":\"author\",\"firstName\":\"Maneesh\",\"lastName\":\"Sahani\"},{\"creatorType\":\"author\",\"firstName\":\"Krishna V.\",\"lastName\":\"Shenoy\"}],\"topic\":\"Neural Variability\",\"notes\":\"The authors measured the variability of neuronal responses across a large number of datasets and cortical areas. They found that variability decreased in response to all stimuli tested, whether the animal was awake, behaving or anesthetized, suggesting that the stabilization of cortex in response to an input is a general cortical property.\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Introducing a Bayesian model of selective attention based on active inference\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"M. Berk\",\"lastName\":\"Mirza\"},{\"creatorType\":\"author\",\"firstName\":\"Rick A.\",\"lastName\":\"Adams\"},{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Parr\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"Information gathering comprises actions whose (sensory) consequences resolve uncertainty (i.e., are salient). In other words, actions that solicit salient information cause the greatest shift in beliefs (i.e., information gain) about the causes of our sensations. However, not all information is relevant to the task at hand: this is especially the case in complex, naturalistic scenes. This paper introduces a formal model of selective attention based on active inference and contextual epistemic foraging. We consider a visual search task with a special emphasis on goal-directed and task-relevant exploration. In this scheme, attention modulates the expected fidelity (precision) of the mapping between observations and hidden states in a state-dependent or context-sensitive manner. This ensures task-irrelevant observations have little expected information gain, and so the agent \\u2013 driven to reduce expected surprise (i.e., uncertainty) \\u2013 does not actively seek them out. Instead, it selectively samples task-relevant observations, which inform (task-relevant) hidden states. We further show, through simulations, that the atypical exploratory behaviours in conditions such as autism and anxiety may be due to a failure to appropriately modulate sensory precision in a context-specific way.\",\"publicationTitle\":\"Scientific Reports\"},{\"title\":\"Active inference on discrete state-spaces: a synthesis\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Lancelot\",\"lastName\":\"Da Costa\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Parr\"},{\"creatorType\":\"author\",\"firstName\":\"Noor\",\"lastName\":\"Sajid\"},{\"creatorType\":\"author\",\"firstName\":\"Sebastijan\",\"lastName\":\"Veselic\"},{\"creatorType\":\"author\",\"firstName\":\"Victorita\",\"lastName\":\"Neacsu\"},{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"Active inference is a normative principle underwriting perception, action, planning, decision-making and learning in biological or arti\\ufb01cial agents. From its inception, its associated process theory has grown to incorporate complex generative models, enabling simulation of a wide range of complex behaviours. Due to successive developments in active inference, it is often dif\\ufb01cult to see how its underlying principle relates to process theories and practical implementation. In this paper, we try to bridge this gap by providing a complete mathematical synthesis of active inference on discrete state-space models. This technical summary provides an overview of the theory, derives neuronal dynamics from \\ufb01rst principles and relates this dynamics to biological processes. Furthermore, this paper provides a fundamental building block needed to understand active inference for mixed generative models; allowing continuous sensations to inform discrete representations. This paper may be used as follows: to guide research towards outstanding challenges, a practical guide on how to implement active inference to simulate experimental behaviour, or a pointer towards various in-silico neurophysiological responses that may be used to make empirical predictions.\",\"publicationTitle\":\"arXiv:2001.07203 [q-bio]\"},{\"title\":\"Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Sergey\",\"lastName\":\"Levine\"}],\"topic\":\"Reinforcement Learning\",\"notes\":\"The framework of reinforcement learning or optimal control provides a mathematical formalization of intelligent decision making that is powerful and broadly applicable. While the general form of the reinforcement learning problem enables effective reasoning about uncertainty, the connection between reinforcement learning and inference in probabilistic models is not immediately obvious. However, such a connection has considerable value when it comes to algorithm design: formalizing a problem as probabilistic inference in principle allows us to bring to bear a wide array of approximate inference tools, extend the model in flexible and powerful ways, and reason about compositionality and partial observability. In this article, we will discuss how a generalization of the reinforcement learning or optimal control problem, which is sometimes termed maximum entropy reinforcement learning, is equivalent to exact probabilistic inference in the case of deterministic dynamics, and variational inference in the case of stochastic dynamics. We will present a detailed derivation of this framework, overview prior work that has drawn on this and related ideas to propose new reinforcement learning and control algorithms, and describe perspectives on future research.\",\"publicationTitle\":\"arXiv:1805.00909 [cs, stat]\"},{\"title\":\"Active Inference: Demystified and Compared\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Noor\",\"lastName\":\"Sajid\"},{\"creatorType\":\"author\",\"firstName\":\"Philip J.\",\"lastName\":\"Ball\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Parr\"},{\"creatorType\":\"author\",\"firstName\":\"Karl J.\",\"lastName\":\"Friston\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"Active inference is a first principle account of how autonomous agents operate in dynamic, nonstationary environments. This problem is also considered in reinforcement learning, but limited work exists on comparing the two approaches on the same discrete-state environments. In this letter, we provide (1) an accessible overview of the discrete-state formulation of active inference, highlighting natural behaviors in active inference that are generally engineered in reinforcement learning, and (2)\\u00a0an explicit discrete-state comparison between active inference and reinforcement learning on an OpenAI gym baseline. We begin by providing a condensed overview of the active inference literature, in particular viewing the various natural behaviors of active inference agents through the lens of reinforcement learning. We show that by operating in a pure belief-based setting, active inference agents can carry out epistemic exploration\\u2014and account for uncertainty about their environment\\u2014in a Bayes-optimal fashion. Furthermore, we show that the reliance on an explicit reward signal in reinforcement learning is removed in active inference, where reward can simply be treated as another observation we have a preference over; even in the total absence of rewards, agent behaviors are learned through preference learning. We make these properties explicit by showing two scenarios in which active inference agents can infer behaviors in reward-free environments compared to both Q-learning and Bayesian model-based reinforcement learning agents and by placing zero prior preferences over rewards and learning the prior preferences over the observations corresponding to reward. We conclude by noting that this formalism can be applied to more complex settings (e.g., robotic arm movement, Atari games) if appropriate generative models can be formulated. In short, we aim to demystify the behavior of active inference agents by presenting an accessible discrete state-space and time formulation and demonstrate these behaviors in a OpenAI gym environment, alongside reinforcement learning agents.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Recurrent Models of Visual Attention\",\"year\":\"2014\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Volodymyr\",\"lastName\":\"Mnih\"},{\"creatorType\":\"author\",\"firstName\":\"Nicolas\",\"lastName\":\"Heess\"},{\"creatorType\":\"author\",\"firstName\":\"Alex\",\"lastName\":\"Graves\"},{\"creatorType\":\"author\",\"firstName\":\"Koray\",\"lastName\":\"Kavukcuoglu\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Applying convolutional neural networks to large images is computationally expensive because the amount of computation scales linearly with the number of image pixels. We present a novel recurrent neural network model that is capable of extracting information from an image or video by adaptively selecting a sequence of regions or locations and only processing the selected regions at high resolution. Like convolutional neural networks, the proposed model has a degree of translation invariance built-in, but the amount of computation it performs can be controlled independently of the input image size. While the model is non-differentiable, it can be trained using reinforcement learning methods to learn task-specific policies. We evaluate our model on several image classification tasks, where it significantly outperforms a convolutional neural network baseline on cluttered images, and on a dynamic visual control problem, where it learns to track a simple object without an explicit training signal for doing so.\",\"publicationTitle\":\"arXiv:1406.6247 [cs, stat]\"},{\"title\":\"Introducing a Bayesian model of selective attention based on active inference\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"M. Berk\",\"lastName\":\"Mirza\"},{\"creatorType\":\"author\",\"firstName\":\"Rick A.\",\"lastName\":\"Adams\"},{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Parr\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Abstract\\n            \\n              Information gathering comprises actions whose (sensory) consequences resolve uncertainty (i.e., are salient). In other words, actions that solicit salient information cause the greatest shift in beliefs (i.e., information gain) about the causes of our sensations. However, not all information is relevant to the task at hand: this is especially the case in complex, naturalistic scenes. This paper introduces a formal model of\\n              selective attention\\n              based on active inference and\\n              contextual\\n              epistemic foraging. We consider a visual search task with a special emphasis on goal-directed and task-relevant exploration. In this scheme, attention modulates the expected fidelity (precision) of the mapping between observations and hidden states in a state-dependent or context-sensitive manner. This ensures task-irrelevant observations have little expected information gain, and so the agent \\u2013 driven to reduce expected surprise (i.e., uncertainty) \\u2013 does not actively seek them out. Instead, it selectively samples task-relevant observations, which inform (task-relevant) hidden states. We further show, through simulations, that the atypical exploratory behaviours in conditions such as autism and anxiety may be due to a failure to appropriately modulate sensory precision in a context-specific way.\",\"publicationTitle\":\"Scientific Reports\"},{\"title\":\"Recurrent Independent Mechanisms\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Anirudh\",\"lastName\":\"Goyal\"},{\"creatorType\":\"author\",\"firstName\":\"Alex\",\"lastName\":\"Lamb\"},{\"creatorType\":\"author\",\"firstName\":\"Jordan\",\"lastName\":\"Hoffmann\"},{\"creatorType\":\"author\",\"firstName\":\"Shagun\",\"lastName\":\"Sodhani\"},{\"creatorType\":\"author\",\"firstName\":\"Sergey\",\"lastName\":\"Levine\"},{\"creatorType\":\"author\",\"firstName\":\"Yoshua\",\"lastName\":\"Bengio\"},{\"creatorType\":\"author\",\"firstName\":\"Bernhard\",\"lastName\":\"Sch\\u00f6lkopf\"}],\"topic\":\"Predictive Coding\",\"notes\":\"We explore the hypothesis that learning modular structures which re\\ufb02ect the dynamics of the environment can lead to better generalization and robustness to changes that only affect a few of the underlying causes. We propose Recurrent Independent Mechanisms (RIMs), a new recurrent architecture in which multiple groups of recurrent cells operate with nearly independent transition dynamics, communicate only sparingly through the bottleneck of attention, and compete with each other so they are updated only at time steps where they are most relevant. We show that this leads to specialization amongst the RIMs, which in turn allows for remarkably improved generalization on tasks where some factors of variation differ systematically between training and evaluation.\",\"publicationTitle\":\"arXiv:1909.10893 [cs, stat]\"},{\"title\":\"Learning Hierarchical Features from Generative Models\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Shengjia\",\"lastName\":\"Zhao\"},{\"creatorType\":\"author\",\"firstName\":\"Jiaming\",\"lastName\":\"Song\"},{\"creatorType\":\"author\",\"firstName\":\"Stefano\",\"lastName\":\"Ermon\"}],\"topic\":\"Variational Inference\",\"notes\":\"Deep neural networks have been shown to be very successful at learning feature hierarchies in supervised learning tasks. Generative models, on the other hand, have benefited less from hierarchical models with multiple layers of latent variables. In this paper, we prove that hierarchical latent variable models do not take advantage of the hierarchical structure when trained with existing variational methods, and provide some limitations on the kind of features existing models can learn. Finally we propose an alternative architecture that do not suffer from these limitations. Our model is able to learn highly interpretable and disentangled hierarchical features on several natural image datasets with no task specific regularization or prior knowledge.\",\"publicationTitle\":\"arXiv:1702.08396 [cs, stat]\"},{\"title\":\"RECASTING GRADIENT-BASED META-LEARNING AS HIERARCHICAL BAYES\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Erin\",\"lastName\":\"Grant\"},{\"creatorType\":\"author\",\"firstName\":\"Chelsea\",\"lastName\":\"Finn\"},{\"creatorType\":\"author\",\"firstName\":\"Sergey\",\"lastName\":\"Levine\"},{\"creatorType\":\"author\",\"firstName\":\"Trevor\",\"lastName\":\"Darrell\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Grif\\ufb01ths\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al. (2017) as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identi\\ufb01cation of MAML as hierarchical Bayes provides a way to understand the algorithm\\u2019s operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for ef\\ufb01cient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.\",\"publicationTitle\":\"\"},{\"title\":\"Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Nat\",\"lastName\":\"Dilokthanakul\"},{\"creatorType\":\"author\",\"firstName\":\"Pedro A. M.\",\"lastName\":\"Mediano\"},{\"creatorType\":\"author\",\"firstName\":\"Marta\",\"lastName\":\"Garnelo\"},{\"creatorType\":\"author\",\"firstName\":\"Matthew C. H.\",\"lastName\":\"Lee\"},{\"creatorType\":\"author\",\"firstName\":\"Hugh\",\"lastName\":\"Salimbeni\"},{\"creatorType\":\"author\",\"firstName\":\"Kai\",\"lastName\":\"Arulkumaran\"},{\"creatorType\":\"author\",\"firstName\":\"Murray\",\"lastName\":\"Shanahan\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"We study a variant of the variational autoencoder model (VAE) with a Gaussian mixture as a prior distribution, with the goal of performing unsupervised clustering through deep generative models. We observe that the known problem of over-regularisation that has been shown to arise in regular VAEs also manifests itself in our model and leads to cluster degeneracy. We show that a heuristic called minimum information constraint that has been shown to mitigate this effect in VAEs can also be applied to improve unsupervised clustering performance with our model. Furthermore we analyse the effect of this heuristic and provide an intuition of the various processes with the help of visualizations. Finally, we demonstrate the performance of our model on synthetic data, MNIST and SVHN, showing that the obtained clusters are distinct, interpretable and result in achieving competitive performance on unsupervised clustering to the state-of-the-art results.\",\"publicationTitle\":\"arXiv:1611.02648 [cs, stat]\"},{\"title\":\"Value Iteration Networks\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Aviv\",\"lastName\":\"Tamar\"},{\"creatorType\":\"author\",\"firstName\":\"Yi\",\"lastName\":\"Wu\"},{\"creatorType\":\"author\",\"firstName\":\"Garrett\",\"lastName\":\"Thomas\"},{\"creatorType\":\"author\",\"firstName\":\"Sergey\",\"lastName\":\"Levine\"},{\"creatorType\":\"author\",\"firstName\":\"Pieter\",\"lastName\":\"Abbeel\"}],\"topic\":\"Reinforcement Learning\",\"notes\":\"We introduce the value iteration network (VIN): a fully differentiable neural network with a `planning module' embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.\",\"publicationTitle\":\"arXiv:1602.02867 [cs, stat]\"},{\"title\":\"Gradient Origin Networks\",\"year\":\"2021\",\"author\":[],\"topic\":\"Variational Inference\",\"notes\":\"This paper proposes a new type of generative model that is able to quickly learn a latent representation without an encoder. This is achieved using empirical Bayes to calculate the expectation of the posterior, which is implemented by initialising a latent vector with zeros, then using the gradient of the log-likelihood of the data with respect to this zero vector as new latent points. The approach has similar characteristics to autoencoders, but with a simpler architecture, and is demonstrated in a variational autoencoder equivalent that permits sampling. This also allows implicit representation networks to learn a space of implicit functions without requiring a hypernetwork, retaining their representation advantages across datasets. The experiments show that the proposed method converges faster, with signi\\ufb01cantly lower reconstruction error than autoencoders, while requiring half the parameters.\",\"publicationTitle\":\"\"},{\"title\":\"Variational Auto-Decoder: A Method for Neural Generative Modeling from Incomplete Data\",\"year\":\"2021\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Amir\",\"lastName\":\"Zadeh\"},{\"creatorType\":\"author\",\"firstName\":\"Yao-Chong\",\"lastName\":\"Lim\"},{\"creatorType\":\"author\",\"firstName\":\"Paul Pu\",\"lastName\":\"Liang\"},{\"creatorType\":\"author\",\"firstName\":\"Louis-Philippe\",\"lastName\":\"Morency\"}],\"topic\":\"Variational Inference\",\"notes\":\"Learning a generative model from partial data (data with missingness) is a challenging area of machine learning research. We study a specific implementation of the Auto-Encoding Variational Bayes (AEVB) algorithm, named in this paper as a Variational Auto-Decoder (VAD). VAD is a generic framework which uses Variational Bayes and Markov Chain Monte Carlo (MCMC) methods to learn a generative model from partial data. The main distinction between VAD and Variational Auto-Encoder (VAE) is the encoder component, as VAD does not have one. Using a proposed efficient inference method from a multivariate Gaussian approximate posterior, VAD models allow inference to be performed via simple gradient ascent rather than MCMC sampling from a probabilistic decoder. This technique reduces the inference computational cost, allows for using more complex optimization techniques during latent space inference (which are shown to be crucial due to a high degree of freedom in the VAD latent space), and keeps the framework simple to implement. Through extensive experiments over several datasets and different missing ratios, we show that encoders cannot efficiently marginalize the input volatility caused by imputed missing values. We study multimodal datasets in this paper, which is a particular area of impact for VAD models.\",\"publicationTitle\":\"arXiv:1903.00840 [cs, stat]\"},{\"title\":\"Causal inference in statistics: An overview\",\"year\":\"2009\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Judea\",\"lastName\":\"Pearl\"}],\"topic\":\"To-Read\",\"notes\":\"This review presents empirical researchers with recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and uni\\ufb01es other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the e\\ufb00ects of potential interventions, (also called \\u201ccausal e\\ufb00ects\\u201d or \\u201cpolicy evaluation\\u201d) (2) queries about probabilities of counterfactuals, (including assessment of \\u201cregret,\\u201d \\u201cattribution\\u201d or \\u201ccauses of e\\ufb00ects\\u201d) and (3) queries about direct and indirect e\\ufb00ects (also known as \\u201cmediation\\u201d). Finally, the paper de\\ufb01nes the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.\",\"publicationTitle\":\"Statistics Surveys\"},{\"title\":\"Meta-Learning with Latent Embedding Optimization\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Andrei A.\",\"lastName\":\"Rusu\"},{\"creatorType\":\"author\",\"firstName\":\"Dushyant\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"Jakub\",\"lastName\":\"Sygnowski\"},{\"creatorType\":\"author\",\"firstName\":\"Oriol\",\"lastName\":\"Vinyals\"},{\"creatorType\":\"author\",\"firstName\":\"Razvan\",\"lastName\":\"Pascanu\"},{\"creatorType\":\"author\",\"firstName\":\"Simon\",\"lastName\":\"Osindero\"},{\"creatorType\":\"author\",\"firstName\":\"Raia\",\"lastName\":\"Hadsell\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"Gradient-based meta-learning techniques are both widely applicable and proficient at solving challenging few-shot learning and fast adaptation problems. However, they have practical difficulties when operating on high-dimensional parameter spaces in extreme low-data regimes. We show that it is possible to bypass these limitations by learning a data-dependent latent generative representation of model parameters, and performing gradient-based meta-learning in this low-dimensional latent space. The resulting approach, latent embedding optimization (LEO), decouples the gradient-based adaptation procedure from the underlying high-dimensional space of model parameters. Our evaluation shows that LEO can achieve state-of-the-art performance on the competitive miniImageNet and tieredImageNet few-shot classification tasks. Further analysis indicates LEO is able to capture uncertainty in the data, and can perform adaptation more effectively by optimizing in latent space.\",\"publicationTitle\":\"arXiv:1807.05960 [cs, stat]\"},{\"title\":\"Bayesianism and Causality, or, Why I am Only a Half-Bayesian\",\"year\":\"2001\",\"author\":[{\"creatorType\":\"seriesEditor\",\"firstName\":\"Dov M.\",\"lastName\":\"Gabbay\"},{\"creatorType\":\"seriesEditor\",\"firstName\":\"Jon\",\"lastName\":\"Barwise\"},{\"creatorType\":\"editor\",\"firstName\":\"David\",\"lastName\":\"Corfield\"},{\"creatorType\":\"editor\",\"firstName\":\"Jon\",\"lastName\":\"Williamson\"},{\"creatorType\":\"author\",\"firstName\":\"Judea\",\"lastName\":\"Pearl\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Building machines that learn and think like people\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Brenden M.\",\"lastName\":\"Lake\"},{\"creatorType\":\"author\",\"firstName\":\"Tomer D.\",\"lastName\":\"Ullman\"},{\"creatorType\":\"author\",\"firstName\":\"Joshua B.\",\"lastName\":\"Tenenbaum\"},{\"creatorType\":\"author\",\"firstName\":\"Samuel J.\",\"lastName\":\"Gershman\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"Recent progress in arti\\ufb01cial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Speci\\ufb01cally, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and psychology to support and enrich the knowledge that is learned; and (3) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes toward these goals that can combine the strengths of recent neural network advances with more structured cognitive models.\",\"publicationTitle\":\"Behavioral and Brain Sciences\"},{\"title\":\"Human-level concept learning through probabilistic program induction\",\"year\":\"2015\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"B. M.\",\"lastName\":\"Lake\"},{\"creatorType\":\"author\",\"firstName\":\"R.\",\"lastName\":\"Salakhutdinov\"},{\"creatorType\":\"author\",\"firstName\":\"J. B.\",\"lastName\":\"Tenenbaum\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"\",\"publicationTitle\":\"Science\"},{\"title\":\"Learning with Hierarchical-Deep Models\",\"year\":\"2013\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"R.\",\"lastName\":\"Salakhutdinov\"},{\"creatorType\":\"author\",\"firstName\":\"J. B.\",\"lastName\":\"Tenenbaum\"},{\"creatorType\":\"author\",\"firstName\":\"A.\",\"lastName\":\"Torralba\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"We introduce HD (or \\u201cHierarchical-Deep\\u201d) models, a new compositional learning architecture that integrates deep learning models with structured hierarchical Bayesian (HB) models. Specifically, we show how we can learn a hierarchical Dirichlet process (HDP) prior over the activities of the top-level features in a deep Boltzmann machine (DBM). This compound HDP-DBM model learns to learn novel concepts from very few training example by learning low-level generic features, high-level features that capture correlations among low-level features, and a category hierarchy for sharing priors over the high-level features that are typical of different kinds of concepts. We present efficient learning and inference algorithms for the HDP-DBM model and show that it is able to learn new concepts from very few examples on CIFAR-100 object recognition, handwritten character recognition, and human motion capture datasets.\",\"publicationTitle\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\"},{\"title\":\"One-Shot Generalization in Deep Generative Models\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Danilo Jimenez\",\"lastName\":\"Rezende\"},{\"creatorType\":\"author\",\"firstName\":\"Shakir\",\"lastName\":\"Mohamed\"},{\"creatorType\":\"author\",\"firstName\":\"Ivo\",\"lastName\":\"Danihelka\"},{\"creatorType\":\"author\",\"firstName\":\"Karol\",\"lastName\":\"Gregor\"},{\"creatorType\":\"author\",\"firstName\":\"Daan\",\"lastName\":\"Wierstra\"}],\"topic\":\"Meta\\/Few-Shot learning\",\"notes\":\"Humans have an impressive ability to reason about new concepts and experiences from just a single example. In particular, humans have an ability for one-shot generalization: an ability to encounter a new concept, understand its structure, and then be able to generate compelling alternative variations of the concept. We develop machine learning systems with this important capacity by developing new deep generative models, models that combine the representational power of deep learning with the inferential power of Bayesian reasoning. We develop a class of sequential generative models that are built on the principles of feedback and attention. These two characteristics lead to generative models that are among the state-of-the art in density estimation and image generation. We demonstrate the one-shot generalization ability of our models using three tasks: unconditional sampling, generating new exemplars of a given concept, and generating new exemplars of a family of concepts. In all cases our models are able to generate compelling and diverse samples---having seen new examples just once---providing an important class of general-purpose models for one-shot machine learning.\",\"publicationTitle\":\"arXiv:1603.05106 [cs, stat]\"},{\"title\":\"Attention in Psychology, Neuroscience, and Machine Learning\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Grace W.\",\"lastName\":\"Lindsay\"}],\"topic\":\"To-Read\",\"notes\":\"Attention is the important ability to flexibly control limited computational resources. It has been studied in conjunction with many other topics in neuroscience and psychology including awareness, vigilance, saliency, executive control, and learning. It has also recently been applied in several domains in machine learning. The relationship between the study of biological attention and its use as a tool to enhance artificial neural networks is not always clear. This review starts by providing an overview of how attention is conceptualized in the neuroscience and psychology literature. It then covers several use cases of attention in machine learning, indicating their biological counterparts where they exist. Finally, the ways in which artificial attention can be further inspired by biology for the production of complex and integrative systems is explored.\",\"publicationTitle\":\"Frontiers in Computational Neuroscience\"},{\"title\":\"Continual learning with hypernetworks\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Johannes\",\"lastName\":\"von Oswald\"},{\"creatorType\":\"author\",\"firstName\":\"Christian\",\"lastName\":\"Henning\"},{\"creatorType\":\"author\",\"firstName\":\"Jo\\u00e3o\",\"lastName\":\"Sacramento\"},{\"creatorType\":\"author\",\"firstName\":\"Benjamin F.\",\"lastName\":\"Grewe\"}],\"topic\":\"Hypernetworks\",\"notes\":\"Artificial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less difficult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-specific weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-of-the-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10\\/100 image datasets.\",\"publicationTitle\":\"arXiv:1906.00695 [cs, stat]\"},{\"title\":\"The Consciousness Prior\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yoshua\",\"lastName\":\"Bengio\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A new prior is proposed for learning representations of high-level concepts of the kind we manipulate with language. This prior can be combined with other priors in order to help disentangling abstract factors from each other. It is inspired by cognitive neuroscience theories of consciousness, seen as a bottleneck through which just a few elements, after having been selected by attention from a broader pool, are then broadcast and condition further processing, both in perception and decision-making. The set of recently selected elements one becomes aware of is seen as forming a low-dimensional conscious state. This conscious state is combining the few concepts constituting a conscious thought, i.e., what one is immediately conscious of at a particular moment. We claim that this architectural and information-processing constraint corresponds to assumptions about the joint distribution between high-level concepts. To the extent that these assumptions are generally true (and the form of natural language seems consistent with them), they can form a useful prior for representation learning. A low-dimensional thought or conscious state is analogous to a sentence: it involves only a few variables and yet can make a statement with very high probability of being true. This is consistent with a joint distribution (over high-level concepts) which has the form of a sparse factor graph, i.e., where the dependencies captured by each factor of the factor graph involve only very few variables while creating a strong dip in the overall energy function. The consciousness prior also makes it natural to map conscious states to natural language utterances or to express classical AI knowledge in a form similar to facts and rules, albeit capturing uncertainty as well as efficient search mechanisms implemented by attention mechanisms.\",\"publicationTitle\":\"arXiv:1709.08568 [cs, stat]\"},{\"title\":\"Improving Sequential Latent Variable Models with Autoregressive Flows\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Joseph\",\"lastName\":\"Marino\"},{\"creatorType\":\"author\",\"firstName\":\"Lei\",\"lastName\":\"Chen\"},{\"creatorType\":\"author\",\"firstName\":\"Jiawei\",\"lastName\":\"He\"},{\"creatorType\":\"author\",\"firstName\":\"Stephan\",\"lastName\":\"Mandt\"}],\"topic\":\"Variational Inference\",\"notes\":\"We propose an approach for improving sequence modeling based on autoregressive normalizing flows. Each autoregressive transform, acting across time, serves as a moving frame of reference, removing temporal correlations, and simplifying the modeling of higher-level dynamics. This technique provides a simple, general-purpose method for improving sequence modeling, with connections to existing and classical techniques. We demonstrate the proposed approach both with standalone flow-based models and as a component within sequential latent variable models. Results are presented on three benchmark video datasets, where autoregressive flow-based dynamics improve log-likelihood performance over baseline models. Finally, we illustrate the decorrelation and improved generalization properties of using flow-based dynamics.\",\"publicationTitle\":\"arXiv:2010.03172 [cs]\"},{\"title\":\"Does predictive coding have a future?\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Neuroscience-Inspired Artificial Intelligence\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Demis\",\"lastName\":\"Hassabis\"},{\"creatorType\":\"author\",\"firstName\":\"Dharshan\",\"lastName\":\"Kumaran\"},{\"creatorType\":\"author\",\"firstName\":\"Christopher\",\"lastName\":\"Summerfield\"},{\"creatorType\":\"author\",\"firstName\":\"Matthew\",\"lastName\":\"Botvinick\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Deep Reinforcement Learning and Its Neuroscientific Implications\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Matthew\",\"lastName\":\"Botvinick\"},{\"creatorType\":\"author\",\"firstName\":\"Jane X.\",\"lastName\":\"Wang\"},{\"creatorType\":\"author\",\"firstName\":\"Will\",\"lastName\":\"Dabney\"},{\"creatorType\":\"author\",\"firstName\":\"Kevin J.\",\"lastName\":\"Miller\"},{\"creatorType\":\"author\",\"firstName\":\"Zeb\",\"lastName\":\"Kurth-Nelson\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Backpropagation and the brain\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Timothy P.\",\"lastName\":\"Lillicrap\"},{\"creatorType\":\"author\",\"firstName\":\"Adam\",\"lastName\":\"Santoro\"},{\"creatorType\":\"author\",\"firstName\":\"Luke\",\"lastName\":\"Marris\"},{\"creatorType\":\"author\",\"firstName\":\"Colin J.\",\"lastName\":\"Akerman\"},{\"creatorType\":\"author\",\"firstName\":\"Geoffrey\",\"lastName\":\"Hinton\"}],\"topic\":\"To-Read\",\"notes\":\"During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on past and recent developments to argue that feedback connections may instead induce neural activities whose differences can be used to locally approximate these signals and hence drive effective learning in deep networks in the brain.\",\"publicationTitle\":\"Nature Reviews Neuroscience\"},{\"title\":\"A tutorial on the free-energy framework for modelling perception and learning\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rafal\",\"lastName\":\"Bogacz\"}],\"topic\":\"To-Read\",\"notes\":\"This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.\",\"publicationTitle\":\"Journal of Mathematical Psychology\"},{\"title\":\"A cortical filter that learns to suppress the acoustic consequences of movement\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David M.\",\"lastName\":\"Schneider\"},{\"creatorType\":\"author\",\"firstName\":\"Janani\",\"lastName\":\"Sundararajan\"},{\"creatorType\":\"author\",\"firstName\":\"Richard\",\"lastName\":\"Mooney\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"Probabilistic brains: knowns and unknowns\",\"year\":\"2013\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Alexandre\",\"lastName\":\"Pouget\"},{\"creatorType\":\"author\",\"firstName\":\"Jeffrey M\",\"lastName\":\"Beck\"},{\"creatorType\":\"author\",\"firstName\":\"Wei Ji\",\"lastName\":\"Ma\"},{\"creatorType\":\"author\",\"firstName\":\"Peter E\",\"lastName\":\"Latham\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Top-Down-Mediated Facilitation in the Visual Cortex Is Gated by Subcortical Neuromodulation\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Diego E.\",\"lastName\":\"Pafundo\"},{\"creatorType\":\"author\",\"firstName\":\"Mark A.\",\"lastName\":\"Nicholas\"},{\"creatorType\":\"author\",\"firstName\":\"Ruilin\",\"lastName\":\"Zhang\"},{\"creatorType\":\"author\",\"firstName\":\"Sandra J.\",\"lastName\":\"Kuhlman\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Response properties in primary sensory cortices are highly dependent on behavioral state. For example, the nucleus basalis of the forebrain plays a critical role in enhancing response properties of excitatory neurons in primary visual cortex (V1) during active exploration and learning. Given the strong reciprocal connections between hierarchically arranged cortical regions, how are increases in sensory response gain constrained to prevent runaway excitation? To explore this, we used in vivo two-photon guided cell-attached recording in conjunction with spatially restricted optogenetic photo-inhibition of higher-order visual cortex in mice. We found that the principle feedback projection to V1 originating from the lateral medial area (LM) facilitated visual responses in layer 2\\/3 excitatory neurons by \\u223c20%. This facilitation was reduced by half during basal forebrain activation due to differential response properties between LM and V1. Our results demonstrate that basal-forebrain-mediated increases in response gain are localized to V1 and are not propagated to LM and establish that subcortical modulation of visual cortex is regionally distinct.\\nSIGNIFICANCE STATEMENT Reciprocal connectivity among brain regions is a prominent feature of all sensory cortices. In primary visual cortex (V1), top-down signals from association areas aid in context-dependent perception of visual scenes by altering the response properties of individual neurons. Sensory-evoked responses in V1 are also highly dependent on subcortical neuromodulation pathways that regulate brain state. Here, with cell-type-specific resolution, we addressed how corticocortical and subcortical pathways interact to regulate responsiveness of V1. Our results provide insight into the rules and conditions governing activity propagation in reciprocally connected networks.\",\"publicationTitle\":\"Journal of Neuroscience\"},{\"title\":\"Inference Suboptimality in Variational Autoencoders\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Chris\",\"lastName\":\"Cremer\"},{\"creatorType\":\"author\",\"firstName\":\"Xuechen\",\"lastName\":\"Li\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Duvenaud\"}],\"topic\":\"Variational Inference\",\"notes\":\"Amortized inference allows latent-variable models trained via variational learning to scale to large datasets. The quality of approximate inference is determined by two factors: a) the capacity of the variational distribution to match the true posterior and b) the ability of the recognition network to produce good variational parameters for each datapoint. We examine approximate inference in variational autoencoders in terms of these factors. We find that divergence from the true posterior is often due to imperfect recognition networks, rather than the limited complexity of the approximating distribution. We show that this is due partly to the generator learning to accommodate the choice of approximation. Furthermore, we show that the parameters used to increase the expressiveness of the approximation play a role in generalizing inference rather than simply improving the complexity of the approximation.\",\"publicationTitle\":\"arXiv:1801.03558 [cs, stat]\"},{\"title\":\"Normalization as a canonical neural computation\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Matteo\",\"lastName\":\"Carandini\"},{\"creatorType\":\"author\",\"firstName\":\"David J.\",\"lastName\":\"Heeger\"}],\"topic\":\"To-Read\",\"notes\":\"Normalization computes a ratio between the response of an individual neuron and the summed activity of a pool of neurons.The normalization model was developed to explain responses in the primary visual cortex (V1), and has been seen to operate in a variety of other regions of the visual system: light adaptation in the retina, contrast normalization in the retina and lateral geniculate nucleus, and visual processing in higher visual cortical areas beyond V1.Normalization has also been proposed to be at the root of the modulatory effects of visual attention on neural responses in the visual cortex.Normalization is seen in multiple species and brain regions. These include olfactory processing and representation in the fruitfly antennal lobe, the encoding of value in the posterior parietal cortex, multisensory integration of visual motion and vestibular signals, and auditory processing in the primary auditory cortex.Different (feedforward and feedback) neural circuits and mechanisms might perform normalization, including presynaptic inhibition, shunting inhibition, synaptic depression, changes in the amplitude of ongoing activity and balanced amplification.The effects of normalization can be measured behaviourally.The computational benefits of normalization include maximizing sensitivity, providing invariance with respect to some stimulus dimensions at the expense of others, facilitating the decoding of a distributed neural representation, facilitating the discrimination among representations of different stimuli, providing max-pooling (winner-take-all competition) and reducing redundancy.Understanding canonical neural computations such as normalization may shed light on psychiatric, neurological and developmental disorders.\",\"publicationTitle\":\"Nature Reviews Neuroscience\"},{\"title\":\"Predictive Coding, Variational Autoencoders, and Biological Connections\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Joseph\",\"lastName\":\"Marino\"}],\"topic\":\"Predictive Coding\",\"notes\":\"This paper identifies connections between predictive coding, from theoretical neuroscience, and variational autoencoders, from machine learning. These connections imply striking correspondences for biological neural circuits, suggesting that pyramidal dendrites are functionally analogous to non-linear deep networks and lateral inhibition is functionally analogous to normalizing flows. Connecting these areas provides new directions for further investigations.\",\"publicationTitle\":\"arXiv:2011.07464 [cs]\"},{\"title\":\"Predictive Processing: A Canonical Cortical Computation\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Georg B.\",\"lastName\":\"Keller\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas D.\",\"lastName\":\"Mrsic-Flogel\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Large-Scale Cortical Networks for Hierarchical Prediction and Prediction Error in the Primate Brain\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Zenas C.\",\"lastName\":\"Chao\"},{\"creatorType\":\"author\",\"firstName\":\"Kana\",\"lastName\":\"Takaura\"},{\"creatorType\":\"author\",\"firstName\":\"Liping\",\"lastName\":\"Wang\"},{\"creatorType\":\"author\",\"firstName\":\"Naotaka\",\"lastName\":\"Fujii\"},{\"creatorType\":\"author\",\"firstName\":\"Stanislas\",\"lastName\":\"Dehaene\"}],\"topic\":\"Predictive Coding\",\"notes\":\"According to predictive-coding theory, cortical areas continuously generate and update predictions of sensory inputs at different hierarchical levels and emit prediction errors when the predicted and actual inputs differ. However, predictions and prediction errors are simultaneous and interdependent processes, making it dif\\ufb01cult to disentangle their constituent neural network organization. Here, we test the theory by using high-density electrocorticography (ECoG) in monkeys during an auditory \\u2018\\u2018localglobal\\u2019\\u2019 paradigm in which the temporal regularities of the stimuli were controlled at two hierarchical levels. We decomposed the broadband data and identi\\ufb01ed lower- and higher-level prediction-error signals in early auditory cortex and anterior temporal cortex, respectively, and a prediction-update signal sent from prefrontal cortex back to temporal cortex. The prediction-error and prediction-update signals were transmitted via g (>40 Hz) and a\\/b (<30 Hz) oscillations, respectively. Our \\ufb01ndings provide strong support for hierarchical predictive coding and outline how it is dynamically implemented using distinct cortical areas and frequencies.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"HyperNetworks\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Ha\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew\",\"lastName\":\"Dai\"},{\"creatorType\":\"author\",\"firstName\":\"Quoc V.\",\"lastName\":\"Le\"}],\"topic\":\"Hypernetworks\",\"notes\":\"This work explores hypernetworks: an approach of using a one network, also known as a hypernetwork, to generate the weights for another network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype \\u2013 the hypernetwork \\u2013 and a phenotype \\u2013 the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve near state-of-the-art results on a variety of sequence modelling tasks including character-level language modelling, handwriting generation and neural machine translation, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.\",\"publicationTitle\":\"arXiv:1609.09106 [cs]\"},{\"title\":\"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Tim\",\"lastName\":\"Salimans\"},{\"creatorType\":\"author\",\"firstName\":\"Diederik P.\",\"lastName\":\"Kingma\"}],\"topic\":\"Misc\",\"notes\":\"We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.\",\"publicationTitle\":\"arXiv:1602.07868 [cs]\"},{\"title\":\"Vector-based navigation using grid-like representations in artificial agents\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Andrea\",\"lastName\":\"Banino\"},{\"creatorType\":\"author\",\"firstName\":\"Caswell\",\"lastName\":\"Barry\"},{\"creatorType\":\"author\",\"firstName\":\"Benigno\",\"lastName\":\"Uria\"},{\"creatorType\":\"author\",\"firstName\":\"Charles\",\"lastName\":\"Blundell\"},{\"creatorType\":\"author\",\"firstName\":\"Timothy\",\"lastName\":\"Lillicrap\"},{\"creatorType\":\"author\",\"firstName\":\"Piotr\",\"lastName\":\"Mirowski\"},{\"creatorType\":\"author\",\"firstName\":\"Alexander\",\"lastName\":\"Pritzel\"},{\"creatorType\":\"author\",\"firstName\":\"Martin J.\",\"lastName\":\"Chadwick\"},{\"creatorType\":\"author\",\"firstName\":\"Thomas\",\"lastName\":\"Degris\"},{\"creatorType\":\"author\",\"firstName\":\"Joseph\",\"lastName\":\"Modayil\"},{\"creatorType\":\"author\",\"firstName\":\"Greg\",\"lastName\":\"Wayne\"},{\"creatorType\":\"author\",\"firstName\":\"Hubert\",\"lastName\":\"Soyer\"},{\"creatorType\":\"author\",\"firstName\":\"Fabio\",\"lastName\":\"Viola\"},{\"creatorType\":\"author\",\"firstName\":\"Brian\",\"lastName\":\"Zhang\"},{\"creatorType\":\"author\",\"firstName\":\"Ross\",\"lastName\":\"Goroshin\"},{\"creatorType\":\"author\",\"firstName\":\"Neil\",\"lastName\":\"Rabinowitz\"},{\"creatorType\":\"author\",\"firstName\":\"Razvan\",\"lastName\":\"Pascanu\"},{\"creatorType\":\"author\",\"firstName\":\"Charlie\",\"lastName\":\"Beattie\"},{\"creatorType\":\"author\",\"firstName\":\"Stig\",\"lastName\":\"Petersen\"},{\"creatorType\":\"author\",\"firstName\":\"Amir\",\"lastName\":\"Sadik\"},{\"creatorType\":\"author\",\"firstName\":\"Stephen\",\"lastName\":\"Gaffney\"},{\"creatorType\":\"author\",\"firstName\":\"Helen\",\"lastName\":\"King\"},{\"creatorType\":\"author\",\"firstName\":\"Koray\",\"lastName\":\"Kavukcuoglu\"},{\"creatorType\":\"author\",\"firstName\":\"Demis\",\"lastName\":\"Hassabis\"},{\"creatorType\":\"author\",\"firstName\":\"Raia\",\"lastName\":\"Hadsell\"},{\"creatorType\":\"author\",\"firstName\":\"Dharshan\",\"lastName\":\"Kumaran\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Nature\"},{\"title\":\"The hippocampus as a predictive map\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Kimberly L\",\"lastName\":\"Stachenfeld\"},{\"creatorType\":\"author\",\"firstName\":\"Matthew M\",\"lastName\":\"Botvinick\"},{\"creatorType\":\"author\",\"firstName\":\"Samuel J\",\"lastName\":\"Gershman\"}],\"topic\":\"To-Read\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Computational roles of plastic probabilistic synapses\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Milton\",\"lastName\":\"Llera-Montero\"},{\"creatorType\":\"author\",\"firstName\":\"Rui Ponte\",\"lastName\":\"Costa\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Current Opinion in Neurobiology\"},{\"title\":\"Decision Making Under Uncertainty: A Neural Model Based on Partially Observable Markov Decision Processes\",\"year\":\"2010\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"}],\"topic\":\"Reinforcement Learning\",\"notes\":\"A fundamental problem faced by animals is learning to select actions based on noisy sensory information and incomplete knowledge of the world. It has been suggested that the brain engages in Bayesian inference during perception but how such probabilistic representations are used to select actions has remained unclear. Here we propose a neural model of action selection and decision making based on the theory of partially observable Markov decision processes (POMDPs). Actions are selected based not on a single \\u201coptimal\\u201d estimate of state but on the posterior distribution over states (the \\u201cbelief\\u201d state). We show how such a model provides a unified framework for explaining experimental results in decision making that involve both information gathering and overt actions. The model utilizes temporal difference (TD) learning for maximizing expected reward.The resulting neural architecture posits an active role for the neocortex in belief computation while ascribing a role to the basal ganglia in belief representation, value computation, and action selection. When applied to the random dots motion discrimination task, model neurons representing belief exhibit responses similar to those of LIP neurons in primate neocortex. The appropriate threshold for switching from information gathering to overt actions emerges naturally during reward maximization. Additionally, the time course of reward prediction error in the model shares similarities with dopaminergic responses in the basal ganglia during the random dots task. For tasks with a deadline, the model learns a decision making strategy that changes with elapsed time, predicting a collapsing decision threshold consistent with some experimental studies. The model provides a new framework for understanding neural decision making and suggests an important role for interactions between the neocortex and the basal ganglia in learning the mapping between probabilistic sensory representations and actions that maximize rewards.\",\"publicationTitle\":\"Frontiers in Computational Neuroscience\"},{\"title\":\"Attend, Infer, Repeat: Fast Scene Understanding with Generative Models\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"S. M. Ali\",\"lastName\":\"Eslami\"},{\"creatorType\":\"author\",\"firstName\":\"Nicolas\",\"lastName\":\"Heess\"},{\"creatorType\":\"author\",\"firstName\":\"Theophane\",\"lastName\":\"Weber\"},{\"creatorType\":\"author\",\"firstName\":\"Yuval\",\"lastName\":\"Tassa\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Szepesvari\"},{\"creatorType\":\"author\",\"firstName\":\"Koray\",\"lastName\":\"Kavukcuoglu\"},{\"creatorType\":\"author\",\"firstName\":\"Geoffrey E.\",\"lastName\":\"Hinton\"}],\"topic\":\"To-Read\",\"notes\":\"We present a framework for efficient inference in structured image models that explicitly reason about objects. We achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time. Crucially, the model itself learns to choose the appropriate number of inference steps. We use this scheme to learn to perform inference in partially specified 2D models (variable-sized variational auto-encoders) and fully specified 3D models (probabilistic renderers). We show that such models learn to identify multiple objects - counting, locating and classifying the elements of a scene - without any supervision, e.g., decomposing 3D images with various numbers of objects in a single forward pass of a neural network. We further show that the networks produce accurate inferences when compared to supervised counterparts, and that their structure leads to improved generalization.\",\"publicationTitle\":\"arXiv:1603.08575 [cs]\"},{\"title\":\"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Adam R.\",\"lastName\":\"Kosiorek\"},{\"creatorType\":\"author\",\"firstName\":\"Hyunjik\",\"lastName\":\"Kim\"},{\"creatorType\":\"author\",\"firstName\":\"Ingmar\",\"lastName\":\"Posner\"},{\"creatorType\":\"author\",\"firstName\":\"Yee Whye\",\"lastName\":\"Teh\"}],\"topic\":\"Predictive Coding\",\"notes\":\"We present Sequential Attend, Infer, Repeat (SQAIR), an interpretable deep generative model for videos of moving objects. It can reliably discover and track objects throughout the sequence of frames, and can also generate future frames conditioning on the current frame, thereby simulating expected motion of objects. This is achieved by explicitly encoding object presence, locations and appearances in the latent variables of the model. SQAIR retains all strengths of its predecessor, Attend, Infer, Repeat (AIR, Eslami et. al., 2016), including learning in an unsupervised manner, and addresses its shortcomings. We use a moving multi-MNIST dataset to show limitations of AIR in detecting overlapping or partially occluded objects, and show how SQAIR overcomes them by leveraging temporal consistency of objects. Finally, we also apply SQAIR to real-world pedestrian CCTV data, where it learns to reliably detect, track and generate walking pedestrians with no supervision.\",\"publicationTitle\":\"arXiv:1806.01794 [cs, stat]\"},{\"title\":\"A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Marco\",\"lastName\":\"Fraccaro\"},{\"creatorType\":\"author\",\"firstName\":\"Simon\",\"lastName\":\"Kamronn\"},{\"creatorType\":\"author\",\"firstName\":\"Ulrich\",\"lastName\":\"Paquet\"},{\"creatorType\":\"author\",\"firstName\":\"Ole\",\"lastName\":\"Winther\"}],\"topic\":\"Transformation, Disentanglement Rep.\",\"notes\":\"This paper takes a step towards temporal reasoning in a dynamically changing video, not in the pixel space that constitutes its frames, but in a latent space that describes the non-linear dynamics of the objects in its world. We introduce the Kalman variational auto-encoder, a framework for unsupervised learning of sequential data that disentangles two latent representations: an object's representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step. The model is trained end-to-end on videos of a variety of simulated physical systems, and outperforms competing methods in generative and missing data imputation tasks.\",\"publicationTitle\":\"arXiv:1710.05741 [cs, stat]\"},{\"title\":\"Layer and rhythm specificity for predictive routing\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Andr\\u00e9 M.\",\"lastName\":\"Bastos\"},{\"creatorType\":\"author\",\"firstName\":\"Mikael\",\"lastName\":\"Lundqvist\"},{\"creatorType\":\"author\",\"firstName\":\"Ayan S.\",\"lastName\":\"Waite\"},{\"creatorType\":\"author\",\"firstName\":\"Nancy\",\"lastName\":\"Kopell\"},{\"creatorType\":\"author\",\"firstName\":\"Earl K.\",\"lastName\":\"Miller\"}],\"topic\":\"To-Read\",\"notes\":\"In predictive coding, experience generates predictions that attenuate the feeding forward of predicted stimuli while passing forward unpredicted \\u201cerrors.\\u201d Different models have suggested distinct cortical layers, and rhythms implement predictive coding. We recorded spikes and local field potentials from laminar electrodes in five cortical areas (visual area 4 [V4], lateral intraparietal [LIP], posterior parietal area 7A, frontal eye field [FEF], and prefrontal cortex [PFC]) while monkeys performed a task that modulated visual stimulus predictability. During predictable blocks, there was enhanced alpha (8 to 14 Hz) or beta (15 to 30 Hz) power in all areas during stimulus processing and prestimulus beta (15 to 30 Hz) functional connectivity in deep layers of PFC to the other areas. Unpredictable stimuli were associated with increases in spiking and in gamma-band (40 to 90 Hz) power\\/connectivity that fed forward up the cortical hierarchy via superficial-layer cortex. Power and spiking modulation by predictability was stimulus specific. Alpha\\/beta power in LIP, FEF, and PFC inhibited spiking in deep layers of V4. Area 7A uniquely showed increases in high-beta (\\u223c22 to 28 Hz) power\\/connectivity to unpredictable stimuli. These results motivate a conceptual model, predictive routing. It suggests that predictive coding may be implemented via lower-frequency alpha\\/beta rhythms that \\u201cprepare\\u201d pathways processing-predicted inputs by inhibiting feedforward gamma rhythms and associated spiking.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Continual learning with hypernetworks\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Johannes\",\"lastName\":\"von Oswald\"},{\"creatorType\":\"author\",\"firstName\":\"Christian\",\"lastName\":\"Henning\"},{\"creatorType\":\"author\",\"firstName\":\"Jo\\u00e3o\",\"lastName\":\"Sacramento\"},{\"creatorType\":\"author\",\"firstName\":\"Benjamin F.\",\"lastName\":\"Grewe\"}],\"topic\":\"To-Read\",\"notes\":\"Arti\\ufb01cial neural networks suffer from catastrophic forgetting when they are sequentially trained on multiple tasks. To overcome this problem, we present a novel approach based on task-conditioned hypernetworks, i.e., networks that generate the weights of a target model based on task identity. Continual learning (CL) is less dif\\ufb01cult for this class of models thanks to a simple key feature: instead of recalling the input-output relations of all previously seen data, task-conditioned hypernetworks only require rehearsing task-speci\\ufb01c weight realizations, which can be maintained in memory using a simple regularizer. Besides achieving state-ofthe-art performance on standard CL benchmarks, additional experiments on long task sequences reveal that task-conditioned hypernetworks display a very large capacity to retain previous memories. Notably, such long memory lifetimes are achieved in a compressive regime, when the number of trainable hypernetwork weights is comparable or smaller than target network size. We provide insight into the structure of low-dimensional task embedding spaces (the input space of the hypernetwork) and show that task-conditioned hypernetworks demonstrate transfer learning. Finally, forward information transfer is further supported by empirical results on a challenging CL benchmark based on the CIFAR-10\\/100 image datasets.\",\"publicationTitle\":\"arXiv:1906.00695 [cs, stat]\"},{\"title\":\"Disentangled Sequential Autoencoder\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yingzhen\",\"lastName\":\"Li\"},{\"creatorType\":\"author\",\"firstName\":\"Stephan\",\"lastName\":\"Mandt\"}],\"topic\":\"Transformation, Disentanglement Rep.\",\"notes\":\"We present a VAE architecture for encoding and generating high dimensional sequential data, such as video or audio. Our deep generative model learns a latent representation of the data which is split into a static and dynamic part, allowing us to approximately disentangle latent time-dependent features (dynamics) from features which are preserved over time (content). This architecture gives us partial control over generating content and dynamics by conditioning on either one of these sets of features. In our experiments on artificially generated cartoon video clips and voice recordings, we show that we can convert the content of a given sequence into another one by such content swapping. For audio, this allows us to convert a male speaker into a female speaker and vice versa, while for video we can separately manipulate shapes and dynamics. Furthermore, we give empirical evidence for the hypothesis that stochastic RNNs as latent state models are more efficient at compressing and generating long sequences than deterministic ones, which may be relevant for applications in video compression.\",\"publicationTitle\":\"arXiv:1803.02991 [cs]\"},{\"title\":\"A Unifying Review of Linear Gaussian Models\",\"year\":\"1999\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Sam\",\"lastName\":\"Roweis\"},{\"creatorType\":\"author\",\"firstName\":\"Zoubin\",\"lastName\":\"Ghahramani\"}],\"topic\":\"Math\",\"notes\":\"Factor analysis, principal component analysis, mixtures of gaussian clusters, vector quantization, Kalman filter models, and hidden Markov models can all be unified as variations of unsupervised learning under a single basic generative model. This is achieved by collecting together disparate observations and derivations made by many previous authors and introducing a new way of linking discrete and continuous state models using a simple nonlinearity. Through the use of other nonlinearities, we show how independent component analysis is also a variation of the same basic generative model. We show that factor analysis and mixtures of gaussians can be implemented in autoencoder neural networks and learned using squared error plus the same regularization term. We introduce a new model for static data, known as sensible principal component analysis, as well as a novel concept of spatially adaptive observation noise. We also review some of the literature involving global and local mixtures of the basic models and provide pseudocode for inference and learning for all the basic models.\",\"publicationTitle\":\"\"},{\"title\":\"Bayesian Hypernetworks\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Krueger\"},{\"creatorType\":\"author\",\"firstName\":\"Chin-Wei\",\"lastName\":\"Huang\"},{\"creatorType\":\"author\",\"firstName\":\"Riashat\",\"lastName\":\"Islam\"},{\"creatorType\":\"author\",\"firstName\":\"Ryan\",\"lastName\":\"Turner\"},{\"creatorType\":\"author\",\"firstName\":\"Alexandre\",\"lastName\":\"Lacoste\"},{\"creatorType\":\"author\",\"firstName\":\"Aaron\",\"lastName\":\"Courville\"}],\"topic\":\"Hypernetworks\",\"notes\":\"We study Bayesian hypernetworks: a framework for approximate Bayesian inference in neural networks. A Bayesian hypernetwork $\\\\h$ is a neural network which learns to transform a simple noise distribution, $p(\\\\vec\\\\epsilon) = \\\\N(\\\\vec 0,\\\\mat I)$, to a distribution $q(\\\\pp) := q(h(\\\\vec\\\\epsilon))$ over the parameters $\\\\pp$ of another neural network (the \\\"primary network\\\")\\\\@. We train $q$ with variational inference, using an invertible $\\\\h$ to enable efficient estimation of the variational lower bound on the posterior $p(\\\\pp | \\\\D)$ via sampling. In contrast to most methods for Bayesian deep learning, Bayesian hypernets can represent a complex multimodal approximate posterior with correlations between parameters, while enabling cheap iid sampling of~$q(\\\\pp)$. In practice, Bayesian hypernets can provide a better defense against adversarial examples than dropout, and also exhibit competitive performance on a suite of tasks which evaluate model uncertainty, including regularization, active learning, and anomaly detection.\",\"publicationTitle\":\"arXiv:1710.04759 [cs, stat]\"},{\"title\":\"Large Associative Memory Problem in Neurobiology and Machine Learning\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Dmitry\",\"lastName\":\"Krotov\"},{\"creatorType\":\"author\",\"firstName\":\"John\",\"lastName\":\"Hopfield\"}],\"topic\":\"To-Read\",\"notes\":\"Dense Associative Memories or modern Hop\\ufb01eld networks permit storage and reliable retrieval of an exponentially large (in the dimension of feature space) number of memories. At the same time, their naive implementation is non-biological, since it seemingly requires the existence of many-body synaptic junctions between the neurons. We show that these models are effective descriptions of a more microscopic (written in terms of biological degrees of freedom) theory that has additional (hidden) neurons and only requires two-body interactions between them. For this reason our proposed microscopic theory is a valid model of large associative memory with a degree of biological plausibility. The dynamics of our network and its reduced dimensional equivalent both minimize energy (Lyapunov) functions. When certain dynamical variables (hidden neurons) are integrated out from our microscopic theory, one can recover many of the models that were previously discussed in the literature, e.g. the model presented in \\u201cHop\\ufb01eld Networks is All You Need\\u201d paper. We also provide an alternative derivation of the energy function and the update rule proposed in the aforementioned paper and clarify the relationships between various models of this class.\",\"publicationTitle\":\"arXiv:2008.06996 [cond-mat, q-bio, stat]\"},{\"title\":\"A Disentangled Recognition and Nonlinear Dynamics Model for Unsupervised Learning\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Marco\",\"lastName\":\"Fraccaro\"},{\"creatorType\":\"author\",\"firstName\":\"Simon\",\"lastName\":\"Kamronn\"},{\"creatorType\":\"author\",\"firstName\":\"Ulrich\",\"lastName\":\"Paquet\"},{\"creatorType\":\"author\",\"firstName\":\"Ole\",\"lastName\":\"Winther\"},{\"creatorType\":\"editor\",\"firstName\":\"I.\",\"lastName\":\"Guyon\"},{\"creatorType\":\"editor\",\"firstName\":\"U. V.\",\"lastName\":\"Luxburg\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Bengio\"},{\"creatorType\":\"editor\",\"firstName\":\"H.\",\"lastName\":\"Wallach\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Fergus\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Vishwanathan\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Garnett\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Sparse coding of time-varying natural images\",\"year\":\"2002\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Bruno A.\",\"lastName\":\"Olshausen\"}],\"topic\":\"Sparse Coding\",\"notes\":\"\",\"publicationTitle\":\"Journal of Vision\"},{\"title\":\"Predictive coding under the free-energy principle\",\"year\":\"2009\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"},{\"creatorType\":\"author\",\"firstName\":\"Stefan\",\"lastName\":\"Kiebel\"}],\"topic\":\"Predictive Coding\",\"notes\":\"This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs.\",\"publicationTitle\":\"Philosophical Transactions of the Royal Society B: Biological Sciences\"},{\"title\":\"Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Gerg\\u0151\",\"lastName\":\"Orb\\u00e1n\"},{\"creatorType\":\"author\",\"firstName\":\"Pietro\",\"lastName\":\"Berkes\"},{\"creatorType\":\"author\",\"firstName\":\"J\\u00f3zsef\",\"lastName\":\"Fiser\"},{\"creatorType\":\"author\",\"firstName\":\"M\\u00e1t\\u00e9\",\"lastName\":\"Lengyel\"}],\"topic\":\"Neural Variability\",\"notes\":\"Neural responses in the visual cortex are variable, and there is now an abundance of data characterizing how the magnitude and structure of this variability depends on the stimulus. Current theories of cortical computation fail to account for these data; they either ignore variability altogether or only model its unstructured Poisson-like aspects. We develop a theory in which the cortex performs probabilistic inference such that population activity patterns represent statistical samples from the inferred probability distribution. Our main prediction is that perceptual uncertainty is directly encoded by the variability, rather than the average, of cortical responses. Through direct comparisons to previously published data as well as original data analyses, we show that a sampling-based probabilistic representation accounts for the structure of noise, signal, and spontaneous response variability and correlations in the primary visual cortex. These results suggest a novel role for neural variability in cortical dynamics and computations.\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"William\",\"lastName\":\"Lotter\"},{\"creatorType\":\"author\",\"firstName\":\"Gabriel\",\"lastName\":\"Kreiman\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Cox\"}],\"topic\":\"Sparse Coding\",\"notes\":\"While great strides have been made in using deep learning algorithms to solve supervised learning tasks, the problem of unsupervised learning - leveraging unlabeled examples to learn about the structure of a domain - remains a difficult unsolved challenge. Here, we explore prediction of future frames in a video sequence as an unsupervised learning rule for learning about the structure of the visual world. We describe a predictive neural network (\\\"PredNet\\\") architecture that is inspired by the concept of \\\"predictive coding\\\" from the neuroscience literature. These networks learn to predict future frames in a video sequence, with each layer in the network making local predictions and only forwarding deviations from those predictions to subsequent network layers. We show that these networks are able to robustly learn to predict the movement of synthetic (rendered) objects, and that in doing so, the networks learn internal representations that are useful for decoding latent object parameters (e.g. pose) that support object recognition with fewer training views. We also show that these networks can scale to complex natural image streams (car-mounted camera videos), capturing key aspects of both egocentric movement and the movement of objects in the visual scene, and the representation learned in this setting is useful for estimating the steering angle. Altogether, these results suggest that prediction represents a powerful framework for unsupervised learning, allowing for implicit learning of object and scene structure.\",\"publicationTitle\":\"arXiv:1605.08104 [cs, q-bio]\"},{\"title\":\"Bayesian inference with probabilistic population codes\",\"year\":\"2006\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Wei Ji\",\"lastName\":\"Ma\"},{\"creatorType\":\"author\",\"firstName\":\"Jeffrey M\",\"lastName\":\"Beck\"},{\"creatorType\":\"author\",\"firstName\":\"Peter E\",\"lastName\":\"Latham\"},{\"creatorType\":\"author\",\"firstName\":\"Alexandre\",\"lastName\":\"Pouget\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Nature Neuroscience\"},{\"title\":\"Reverse correlation in neurophysiology\",\"year\":\"2004\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Dario\",\"lastName\":\"Ringach\"},{\"creatorType\":\"author\",\"firstName\":\"Robert\",\"lastName\":\"Shapley\"}],\"topic\":\"Neurophysiology\",\"notes\":\"This article presents a review of reverse correlation in neurophysiology. We discuss the basis of reverse correlation in linear transducers and in spiking neurons. The application of reverse correlation to measure the receptive \\ufb01elds of visual neurons using white noise and m-sequences, and classical \\ufb01ndings about spatial and color processing in the cortex resulting from such measurements, are emphasized. Finally, we describe new developments in reverse correlation, including \\u201csub-space\\u201d and categorical reverse-correlation. Recent results obtained by applying such methods in the orientation, spatial-frequency and Fourier domains have revealed the importance of cortical inhibition in the establishment of sharp tuning selectivity in single neurons.\",\"publicationTitle\":\"Cognitive Science\"},{\"title\":\"Statistics of Natural Time-Varying Images\",\"year\":\"1995\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Dawei W.\",\"lastName\":\"Dong\"},{\"creatorType\":\"author\",\"firstName\":\"Joseph J.\",\"lastName\":\"Atick\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Natural time-varying images possess substantial spatiotemporal correlations. We measure these correlations --- or equivalently the power spectrum --- for an ensemble of more than a thousand segments of motion pictures, and we find significant regularities. More precisely, our measurements show that the dependence of the power spectrum on the spatial frequency, f , and temporal frequency, w, is in general nonseparable and is given by f  0m01  F (w=f ), where F (w=f ) is a nontrivial function of the ratio w=f . We give a theoretical derivation of this scaling behaviour and show that it emerges from objects with a static power spectrum \\u00b8 f  0m  , appearing at a wide range of depths and moving with a distribution of velocities relative to the observer. We show that in the regime of relatively high temporal and low spatial frequencies, the power spectrum becomes independent of the details of the velocity distribution and it is separable into the product of spatial and temporal power spectra...\",\"publicationTitle\":null},{\"title\":\"Slow feature analysis yields a rich repertoire of complex cell properties\",\"year\":\"2005\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"P.\",\"lastName\":\"Berkes\"},{\"creatorType\":\"author\",\"firstName\":\"L.\",\"lastName\":\"Wiskott\"}],\"topic\":\"Predictive Coding\",\"notes\":\"In this study we investigate temporal slowness as a learning principle for receptive fields using slow feature analysis, a new algorithm to determine functions that extract slowly varying signals from the input data. We find a good qualitative and quantitative match between the set of learned functions trained on image sequences and the population of complex cells in the primary visual cortex (V1). The functions show many properties found also experimentally in complex cells, such as direction selectivity, non-orthogonal inhibition, end-inhibition, and side-inhibition. Our results demonstrate that a single unsupervised learning principle can account for such a rich repertoire of receptive field properties.\",\"publicationTitle\":\"Journal of Vision\"},{\"title\":\"Independent component analysis of natural image sequences yields spatio-temporal filters similar to simple cells in primary visual cortex\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"J H\",\"lastName\":\"van Hateren\"},{\"creatorType\":\"author\",\"firstName\":\"D L\",\"lastName\":\"Ruderman\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Proceedings of the Royal Society of London. Series B: Biological Sciences\"},{\"title\":\"Sensory cortex is optimized for prediction of future input\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yosef\",\"lastName\":\"Singer\"},{\"creatorType\":\"author\",\"firstName\":\"Yayoi\",\"lastName\":\"Teramoto\"},{\"creatorType\":\"author\",\"firstName\":\"Ben DB\",\"lastName\":\"Willmore\"},{\"creatorType\":\"author\",\"firstName\":\"Jan WH\",\"lastName\":\"Schnupp\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew J\",\"lastName\":\"King\"},{\"creatorType\":\"author\",\"firstName\":\"Nicol S\",\"lastName\":\"Harper\"},{\"creatorType\":\"editor\",\"firstName\":\"Jack L\",\"lastName\":\"Gallant\"},{\"creatorType\":\"editor\",\"firstName\":\"Sabine\",\"lastName\":\"Kastner\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Neurons in sensory cortex are tuned to diverse features in natural scenes. But what determines which features neurons become selective to? Here we explore the idea that neuronal selectivity is optimized to represent features in the recent sensory past that best predict immediate future inputs. We tested this hypothesis using simple feedforward neural networks, which were trained to predict the next few moments of video or audio in clips of natural scenes. The networks developed receptive fields that closely matched those of real cortical neurons in different mammalian species, including the oriented spatial tuning of primary visual cortex, the frequency selectivity of primary auditory cortex and, most notably, their temporal tuning properties. Furthermore, the better a network predicted future inputs the more closely its receptive fields resembled those in the brain. This suggests that sensory processing is optimized to extract those features with the most capacity to predict future input.\",\"publicationTitle\":\"eLife\"},{\"title\":\"A Structured Model of Video Reproduces Primary Visual Cortical Organisation\",\"year\":\"2009\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Pietro\",\"lastName\":\"Berkes\"},{\"creatorType\":\"author\",\"firstName\":\"Richard E.\",\"lastName\":\"Turner\"},{\"creatorType\":\"author\",\"firstName\":\"Maneesh\",\"lastName\":\"Sahani\"},{\"creatorType\":\"editor\",\"firstName\":\"Konrad\",\"lastName\":\"Kording\"}],\"topic\":\"Predictive Coding\",\"notes\":\"The visual system must learn to infer the presence of objects and features in the world from the images it encounters, and as such it must, either implicitly or explicitly, model the way these elements interact to create the image. Do the response properties of cells in the mammalian visual system reflect this constraint? To address this question, we constructed a probabilistic model in which the identity and attributes of simple visual elements were represented explicitly and learnt the parameters of this model from unparsed, natural video sequences. After learning, the behaviour and grouping of variables in the probabilistic model corresponded closely to functional and anatomical properties of simple and complex cells in the primary visual cortex (V1). In particular, feature identity variables were activated in a way that resembled the activity of complex cells, while feature attribute variables responded much like simple cells. Furthermore, the grouping of the attributes within the model closely parallelled the reported anatomical grouping of simple cells in cat V1. Thus, this generative model makes explicit an interpretation of complex and simple cells as elements in the segmentation of a visual scene into basic independent features, along with a parametrisation of their moment-by-moment appearances. We speculate that such a segmentation may form the initial stage of a hierarchical system that progressively separates the identity and appearance of more articulated visual elements, culminating in view-invariant object recognition.\",\"publicationTitle\":\"PLoS Computational Biology\"},{\"title\":\"Predictive coding\",\"year\":\"2011\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yanping\",\"lastName\":\"Huang\"},{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Predictive coding is a unifying framework for understanding redundancy reduction and efficient coding in the nervous system. By transmitting only the unpredicted portions of an incoming sensory signal, predictive coding allows the nervous system to reduce redundancy and make full use of the limited dynamic range of neurons. Starting with the hypothesis of efficient coding as a design principle in the sensory system, predictive coding provides a functional explanation for a range of neural responses and many aspects of brain organization. The lateral and temporal antagonism in receptive fields in the retina and lateral geniculate nucleus occur naturally as a consequence of predictive coding of natural images. In the higher visual system, predictive coding provides an explanation for oriented receptive fields and contextual effects as well as the hierarchical reciprocally connected organization of the cortex. Predictive coding has also been found to be consistent with a variety of neurophysiological and psychophysical data obtained from different areas of the brain. WIREs Cogni Sci 2011 2 580\\u2013593 DOI: 10.1002\\/wcs.142 This article is categorized under: Computer Science > Neural Networks\",\"publicationTitle\":\"WIREs Cognitive Science\"},{\"title\":\"Receptive-field dynamics in the central visual pathways\",\"year\":\"1995\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Gregory C.\",\"lastName\":\"DeAngelis\"},{\"creatorType\":\"author\",\"firstName\":\"Izumi\",\"lastName\":\"Ohzawa\"},{\"creatorType\":\"author\",\"firstName\":\"Ralph D.\",\"lastName\":\"Freeman\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Trends in Neurosciences\"},{\"title\":\"Neural Networks with Dynamic Synapses\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Misha\",\"lastName\":\"Tsodyks\"},{\"creatorType\":\"author\",\"firstName\":\"Klaus\",\"lastName\":\"Pawelzik\"},{\"creatorType\":\"author\",\"firstName\":\"Henry\",\"lastName\":\"Markram\"}],\"topic\":\"Neurophysiology\",\"notes\":\"Transmission across neocortical synapses depends on the frequency of presynaptic activity (Thomson & Deuchars, 1994). Interpyramidal synapses in layer V exhibit fast depression of synaptic transmission, while other types of synapses exhibit facilitation of transmission. To study the role of dynamic synapses in network computation, we propose a unified phenomenological model that allows computation of the postsynaptic current generated by both types of synapses when driven by an arbitrary pattern of action potential (AP) activity in a presynaptic population. Using this formalism, we analyze different regimes of synaptic transmission and demonstrate that dynamic synapses transmit different aspects of the presynaptic activity depending on the average presynaptic frequency. The model also allows for derivation of mean-field equations, which govern the activity of large, interconnected networks. We show that the dynamics of synaptic transmission results in complex sets of regular and irregular regimes of network activity.\",\"publicationTitle\":\"Neural Computation\"},{\"title\":\"Dynamic Synapses in the Cortex\",\"year\":\"1997\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Anthony M\",\"lastName\":\"Zador\"},{\"creatorType\":\"author\",\"firstName\":\"Lynn E\",\"lastName\":\"Dobrunz\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"Neuron\"},{\"title\":\"Receptive fields of single neurones in the cat's striate cortex\",\"year\":\"1959\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"D. H.\",\"lastName\":\"Hubel\"},{\"creatorType\":\"author\",\"firstName\":\"T. N.\",\"lastName\":\"Wiesel\"}],\"topic\":\"Neurophysiology\",\"notes\":\"\",\"publicationTitle\":\"The Journal of Physiology\"},{\"title\":\"Toward a unified theory of efficient, predictive, and sparse coding\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Matthew\",\"lastName\":\"Chalk\"},{\"creatorType\":\"author\",\"firstName\":\"Olivier\",\"lastName\":\"Marre\"},{\"creatorType\":\"author\",\"firstName\":\"Ga\\u0161per\",\"lastName\":\"Tka\\u010dik\"}],\"topic\":\"Predictive Coding\",\"notes\":\"A central goal in theoretical neuroscience is to predict the response properties of sensory neurons from first principles. To this end, \\u201cefficient coding\\u201d posits that sensory neurons encode maximal information about their inputs given internal constraints. There exist, however, many variants of efficient coding (e.g., redundancy reduction, different formulations of predictive coding, robust coding, sparse coding, etc.), differing in their regimes of applicability, in the relevance of signals to be encoded, and in the choice of constraints. It is unclear how these types of efficient coding relate or what is expected when different coding objectives are combined. Here we present a unified framework that encompasses previously proposed efficient coding models and extends to unique regimes. We show that optimizing neural responses to encode predictive information can lead them to either correlate or decorrelate their inputs, depending on the stimulus statistics; in contrast, at low noise, efficiently encoding the past always predicts decorrelation. Later, we investigate coding of naturalistic movies and show that qualitatively different types of visual motion tuning and levels of response sparsity are predicted, depending on whether the objective is to recover the past or predict the future. Our approach promises a way to explain the observed diversity of sensory neural responses, as due to multiple functional goals and constraints fulfilled by different cell types and\\/or circuits.\",\"publicationTitle\":\"Proceedings of the National Academy of Sciences\"},{\"title\":\"Sparse coding with an overcomplete basis set: A strategy employed by V1?\",\"year\":\"1997\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Bruno A.\",\"lastName\":\"Olshausen\"},{\"creatorType\":\"author\",\"firstName\":\"David J.\",\"lastName\":\"Field\"}],\"topic\":\"Sparse Coding\",\"notes\":\"\",\"publicationTitle\":\"Vision Research\"},{\"title\":\"The free-energy principle: a unified brain theory?\",\"year\":\"2010\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Karl\",\"lastName\":\"Friston\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories \\u2014 optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.\",\"publicationTitle\":\"Nature Reviews Neuroscience\"},{\"title\":\"A tutorial on the free-energy framework for modelling perception and learning\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rafal\",\"lastName\":\"Bogacz\"}],\"topic\":\"Free Energy Principle\",\"notes\":\"This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.\",\"publicationTitle\":\"Journal of Mathematical Psychology\"},{\"title\":\"A neural network trained for prediction mimics diverse features of biological neurons and perception\",\"year\":\"2020\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"William\",\"lastName\":\"Lotter\"},{\"creatorType\":\"author\",\"firstName\":\"Gabriel\",\"lastName\":\"Kreiman\"},{\"creatorType\":\"author\",\"firstName\":\"David\",\"lastName\":\"Cox\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":\"Nature Machine Intelligence\"},{\"title\":\"Dynamic Filter Networks\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Bert\",\"lastName\":\"De Brabandere\"},{\"creatorType\":\"author\",\"firstName\":\"Xu\",\"lastName\":\"Jia\"},{\"creatorType\":\"author\",\"firstName\":\"Tinne\",\"lastName\":\"Tuytelaars\"},{\"creatorType\":\"author\",\"firstName\":\"Luc\",\"lastName\":\"Van Gool\"}],\"topic\":\"Hypernetworks\",\"notes\":\"In a traditional convolutional layer, the learned filters stay fixed after training. In contrast, we introduce a new framework, the Dynamic Filter Network, where filters are generated dynamically conditioned on an input. We show that this architecture is a powerful one, with increased flexibility thanks to its adaptive nature, yet without an excessive increase in the number of model parameters. A wide variety of filtering operations can be learned this way, including local spatial transformations, but also others like selective (de)blurring or adaptive feature extraction. Moreover, multiple such layers can be combined, e.g. in a recurrent architecture. We demonstrate the effectiveness of the dynamic filter network on the tasks of video and stereo prediction, and reach state-of-the-art performance on the moving MNIST dataset with a much smaller model. By visualizing the learned filters, we illustrate that the network has picked up flow information by only looking at unlabelled training data. This suggests that the network can be used to pretrain networks for various supervised tasks in an unsupervised way, like optical flow and depth estimation.\",\"publicationTitle\":\"arXiv:1605.09673 [cs]\"},{\"title\":\"Spectral Changes in Cortical Surface Potentials during Motor Movement\",\"year\":\"2007\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"K. J.\",\"lastName\":\"Miller\"},{\"creatorType\":\"author\",\"firstName\":\"E. C.\",\"lastName\":\"Leuthardt\"},{\"creatorType\":\"author\",\"firstName\":\"G.\",\"lastName\":\"Schalk\"},{\"creatorType\":\"author\",\"firstName\":\"R. P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"author\",\"firstName\":\"N. R.\",\"lastName\":\"Anderson\"},{\"creatorType\":\"author\",\"firstName\":\"D. W.\",\"lastName\":\"Moran\"},{\"creatorType\":\"author\",\"firstName\":\"J. W.\",\"lastName\":\"Miller\"},{\"creatorType\":\"author\",\"firstName\":\"J. G.\",\"lastName\":\"Ojemann\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Journal of Neuroscience\"},{\"title\":\"Independent component analysis: algorithms and applications\",\"year\":\"2000\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"A.\",\"lastName\":\"Hyv\\u00e4rinen\"},{\"creatorType\":\"author\",\"firstName\":\"E.\",\"lastName\":\"Oja\"}],\"topic\":\"Math\",\"notes\":\"A fundamental problem in neural network research, as well as in many other disciplines, is \\ufb01nding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to \\ufb01nd a linear representation of nongaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.\",\"publicationTitle\":\"Neural Networks\"},{\"title\":\"Sparse-Coding Variational Auto-Encoders\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Gabriel\",\"lastName\":\"Barello\"},{\"creatorType\":\"author\",\"firstName\":\"Adam S.\",\"lastName\":\"Charles\"},{\"creatorType\":\"author\",\"firstName\":\"Jonathan W.\",\"lastName\":\"Pillow\"}],\"topic\":\"Sparse Coding\",\"notes\":\"The sparse coding model posits that the visual system has evolved to ef\\ufb01ciently code natural stimuli using a sparse set of features from an overcomplete dictionary. The classic sparse coding model suffers from two key limitations, however: (1) computing the neural response to an image patch requires minimizing a nonlinear objective function, which is not neurally plausible; and (2) \\ufb01tting the model to data has typically relied on an approximate inference method that does not take into account uncertainty. Here we address these two shortcomings by formulating a variational inference method for the sparse coding model inspired by the variational auto-encoder (VAE) framework. The sparse-coding variational auto-encoder (SVAE) augments the classic sparse coding model with a probabilistic recognition model, parametrized by a deep neural network. This recognition model provides a neurally plausible implementation for the mapping from image patches to neural activities, and enables a principled method for \\ufb01tting the sparse coding model to data via maximization of the evidence lower bound (ELBO). The SVAE differs from the traditional VAE in three important ways: the generative model is the sparse coding model instead of a deep network; the latent representation is overcomplete, with more latent dimensions than image pixels; and the prior over latent variables is a sparse or heavy-tailed instead of Gaussian. We \\ufb01t the SVAE to natural image data under different assumed prior distributions, and show that it obtains higher test performance than previous \\ufb01tting methods. Finally, we examine the response properties of the recognition network and show that it captures important nonlinear properties of neurons in the early visual pathway.\",\"publicationTitle\":null},{\"title\":\"An optimal estimation approach to visual perception and learning\",\"year\":\"1999\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P.N.\",\"lastName\":\"Rao\"}],\"topic\":\"Predictive Coding\",\"notes\":\"How does the visual system learn an internal model of the external environment? How is this internal model used during visual perception? How are occlusions and background clutter so effortlessly discounted for when recognizing a familiar object? How is a particular object of interest attended to and recognized in the presence of other objects in the \\ufb01eld of view? In this paper, we attempt to address these questions from the perspective of Bayesian optimal estimation theory. Using the concept of generative models and the statistical theory of Kalman \\ufb01ltering, we show how static and dynamic events occurring in the visual environment may be learned and recognized given only the input images. We also describe an extension of the Kalman \\ufb01lter model that can handle multiple objects in the \\ufb01eld of view. The resulting robust Kalman \\ufb01lter model demonstrates how certain forms of attention can be viewed as an emergent property of the interaction between top \\u2013 down expectations and bottom \\u2013 up signals. Experimental results are provided to help demonstrate the ability of such a model to perform robust segmentation and recognition of objects and image sequences in the presence of occlusions and clutter. \\u00a9 1999 Elsevier Science Ltd. All rights reserved.\",\"publicationTitle\":\"Vision Research\"},{\"title\":\"A Dataset To Evaluate The Representations Learned By Video Prediction Models\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Ryan\",\"lastName\":\"Szeto\"},{\"creatorType\":\"author\",\"firstName\":\"Simon\",\"lastName\":\"Stent\"},{\"creatorType\":\"author\",\"firstName\":\"German\",\"lastName\":\"Ros\"},{\"creatorType\":\"author\",\"firstName\":\"Jason J.\",\"lastName\":\"Corso\"}],\"topic\":\"Predictive Coding\",\"notes\":\"We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https:\\/\\/github.com\\/rszeto\\/moving-symbols .\",\"publicationTitle\":\"arXiv:1802.08936 [cs]\"},{\"title\":\"Learning to Decompose and Disentangle Representations for Video Prediction\",\"year\":\"2018\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Jun-Ting\",\"lastName\":\"Hsieh\"},{\"creatorType\":\"author\",\"firstName\":\"Bingbin\",\"lastName\":\"Liu\"},{\"creatorType\":\"author\",\"firstName\":\"De-An\",\"lastName\":\"Huang\"},{\"creatorType\":\"author\",\"firstName\":\"Li\",\"lastName\":\"Fei-Fei\"},{\"creatorType\":\"author\",\"firstName\":\"Juan Carlos\",\"lastName\":\"Niebles\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Our goal is to predict future video frames given a sequence of input frames. Despite large amounts of video data, this remains a challenging task because of the high-dimensionality of video frames. We address this challenge by proposing the Decompositional Disentangled Predictive Auto-Encoder (DDPAE), a framework that combines structured probabilistic models and deep networks to automatically (i) decompose the high-dimensional video that we aim to predict into components, and (ii) disentangle each component to have low-dimensional temporal dynamics that are easier to predict. Crucially, with an appropriately specified generative model of video frames, our DDPAE is able to learn both the latent decomposition and disentanglement without explicit supervision. For the Moving MNIST dataset, we show that DDPAE is able to recover the underlying components (individual digits) and disentanglement (appearance and location) as we would intuitively do. We further demonstrate that DDPAE can be applied to the Bouncing Balls dataset involving complex interactions between multiple objects to predict the video frame directly from the pixels and recover physical states without explicit supervision.\",\"publicationTitle\":\"arXiv:1806.04166 [cs, stat]\"},{\"title\":\"Correlates of Attention in a Model of Dynamic Visual Recognition\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Rajesh P. N.\",\"lastName\":\"Rao\"},{\"creatorType\":\"editor\",\"firstName\":\"M. I.\",\"lastName\":\"Jordan\"},{\"creatorType\":\"editor\",\"firstName\":\"M. J.\",\"lastName\":\"Kearns\"},{\"creatorType\":\"editor\",\"firstName\":\"S. A.\",\"lastName\":\"Solla\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Unsupervised Learning of Disentangled Representations from Video\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Emily L\",\"lastName\":\"Denton\"},{\"creatorType\":\"author\",\"firstName\":\"vighnesh\",\"lastName\":\"Birodkar\"},{\"creatorType\":\"editor\",\"firstName\":\"I.\",\"lastName\":\"Guyon\"},{\"creatorType\":\"editor\",\"firstName\":\"U. V.\",\"lastName\":\"Luxburg\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Bengio\"},{\"creatorType\":\"editor\",\"firstName\":\"H.\",\"lastName\":\"Wallach\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Fergus\"},{\"creatorType\":\"editor\",\"firstName\":\"S.\",\"lastName\":\"Vishwanathan\"},{\"creatorType\":\"editor\",\"firstName\":\"R.\",\"lastName\":\"Garnett\"}],\"topic\":\"Predictive Coding\",\"notes\":\"\",\"publicationTitle\":null},{\"title\":\"Hierarchical temporal prediction captures motion processing from retina to higher visual cortex\",\"year\":\"2019\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Yosef\",\"lastName\":\"Singer\"},{\"creatorType\":\"author\",\"firstName\":\"Ben D. B.\",\"lastName\":\"Willmore\"},{\"creatorType\":\"author\",\"firstName\":\"Andrew J.\",\"lastName\":\"King\"},{\"creatorType\":\"author\",\"firstName\":\"Nicol S.\",\"lastName\":\"Harper\"}],\"topic\":\"Predictive Coding\",\"notes\":\"Visual neurons respond selectively to specific features that become increasingly complex in their form and dynamics from the eyes to the cortex. Retinal neurons prefer localized flashing spots of light, primary visual cortical (V1) neurons moving bars, and those in higher cortical areas, such as middle temporal (MT) cortex, favor complex features like moving textures. Whether there are general computational principles behind this diversity of response properties remains unclear. To date, no single normative model has been able to account for the hierarchy of tuning to dynamic inputs along the visual pathway. Here we show that hierarchical application of temporal prediction - representing features that efficiently predict future sensory input from past sensory input - can explain how neuronal tuning properties, particularly those relating to motion, change from retina to higher visual cortex. This suggests that the brain may not have evolved to efficiently represent all incoming information, as implied by some leading theories. Instead, the selective representation of sensory inputs that help in predicting the future may be a general neural coding principle, which when applied hierarchically extracts temporally-structured features that depend on increasingly high-level statistics of the sensory input.\",\"publicationTitle\":null},{\"title\":\"Emergence of simple-cell receptive field properties by learning a sparse code for natural images\",\"year\":\"1996\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Bruno A.\",\"lastName\":\"Olshausen\"},{\"creatorType\":\"author\",\"firstName\":\"David J.\",\"lastName\":\"Field\"}],\"topic\":\"Sparse Coding\",\"notes\":\"THE receptive fields of simple cells in mammalian primary visual cortex can be characterized as being spatially localized, oriented1\\u20134 and bandpass (selective to structure at different spatial scales), comparable to the basis functions of wavelet transforms5,6. One approach to understanding such response properties of visual neurons has been to consider their relationship to the statistical structure of natural images in terms of efficient coding7\\u201312. Along these lines, a number of studies have attempted to train unsupervised learning algorithms on natural images in the hope of developing receptive fields with similar properties13\\u201318, but none has succeeded in producing a full set that spans the image space and contains all three of the above properties. Here we investigate the proposal8,12 that a coding strategy that maximizes sparseness is sufficient to account for these properties. We show that a learning algorithm that attempts to find sparse linear codes for natural scenes will develop a complete family of localized, oriented, bandpass receptive fields, similar to those found in the primary visual cortex. The resulting sparse image code provides a more efficient representation for later stages of processing because it possesses a higher degree of statistical independence among its outputs.\",\"publicationTitle\":\"Nature\"},{\"title\":\"Spike and slab variable selection: Frequentist and Bayesian strategies\",\"year\":\"2005\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Hemant\",\"lastName\":\"Ishwaran\"},{\"creatorType\":\"author\",\"firstName\":\"J. Sunil\",\"lastName\":\"Rao\"}],\"topic\":\"Sparse Coding\",\"notes\":\"Variable selection in the linear regression model takes many apparent faces from both frequentist and Bayesian standpoints. In this paper we introduce a variable selection method referred to as a rescaled spike and slab model. We study the importance of prior hierarchical specifications and draw connections to frequentist generalized ridge regression estimation. Specifically, we study the usefulness of continuous bimodal priors to model hypervariance parameters, and the effect scaling has on the posterior mean through its relationship to penalization. Several model selection strategies, some frequentist and some Bayesian in nature, are developed and studied theoretically. We demonstrate the importance of selective shrinkage for effective variable selection in terms of risk misclassification, and show this is achieved using the posterior from a rescaled spike and slab model. We also show how to verify a procedure\\u2019s ability to reduce model uncertainty in finite samples using a specialized forward selection strategy. Using this tool, we illustrate the effectiveness of rescaled spike and slab models in reducing model uncertainty.\",\"publicationTitle\":\"Annals of Statistics\"},{\"title\":\"Variational Inference: A Review for Statisticians\",\"year\":\"2017\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"David M.\",\"lastName\":\"Blei\"},{\"creatorType\":\"author\",\"firstName\":\"Alp\",\"lastName\":\"Kucukelbir\"},{\"creatorType\":\"author\",\"firstName\":\"Jon D.\",\"lastName\":\"McAuliffe\"}],\"topic\":\"Math\",\"notes\":\"One of the core problems of modern statistics is to approximate dif\\ufb01cult-to-compute probability densities. This problem is especially important in Bayesian statistics, which frames all inference about unknown quantities as a calculation involving the posterior density. In this paper, we review variational inference (VI), a method from machine learning that approximates probability densities through optimization. VI has been used in many applications and tends to be faster than classical methods, such as Markov chain Monte Carlo sampling. The idea behind VI is to \\ufb01rst posit a family of densities and then to \\ufb01nd the member of that family which is close to the target. Closeness is measured by Kullback-Leibler divergence. We review the ideas behind mean-\\ufb01eld variational inference, discuss the special case of VI applied to exponential family models, present a full example with a Bayesian mixture of Gaussians, and derive a variant that uses stochastic optimization to scale up to massive data. We discuss modern research in VI and highlight important open problems. VI is powerful, but it is not yet well understood. Our hope in writing this paper is to catalyze statistical research on this class of algorithms.\",\"publicationTitle\":\"Journal of the American Statistical Association\"},{\"title\":\"Bayesian and L1 Approaches to Sparse Unsupervised Learning\",\"year\":\"2012\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Shakir\",\"lastName\":\"Mohamed\"},{\"creatorType\":\"author\",\"firstName\":\"Katherine\",\"lastName\":\"Heller\"},{\"creatorType\":\"author\",\"firstName\":\"Zoubin\",\"lastName\":\"Ghahramani\"}],\"topic\":\"Sparse Coding\",\"notes\":\"The use of L1 regularisation for sparse learning has generated immense research interest, with many successful applications in diverse areas such as signal acquisition, image coding, genomics and collaborative \\ufb01ltering. While existing work highlights the many advantages of L1 methods, in this paper we \\ufb01nd that L1 regularisation often dramatically under-performs in terms of predictive performance when compared to other methods for inferring sparsity. We focus on unsupervised latent variable models, and develop L1 minimising factor models, Bayesian variants of \\u201cL1\\u201d, and Bayesian models with a stronger L0-like sparsity induced through spike-and-slab distributions. These spikeand-slab Bayesian factor models encourage sparsity while accounting for uncertainty in a principled manner, and avoid unnecessary shrinkage of non-zero values. We demonstrate on a number of data sets that in practice spike-and-slab Bayesian methods outperform L1 minimisation, even on a computational budget. We thus highlight the need to re-assess the wide use of L1 methods in sparsity-reliant applications, particularly when we care about generalising to previously unseen data, and provide an alternative that, over many varying conditions, provides improved generalisation performance.\",\"publicationTitle\":\"arXiv:1106.1157 [cs, stat]\"},{\"title\":\"The Hamiltonian Brain: Efficient Probabilistic Inference with Excitatory-Inhibitory Neural Circuit Dynamics\",\"year\":\"2016\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Laurence\",\"lastName\":\"Aitchison\"},{\"creatorType\":\"author\",\"firstName\":\"M\\u00e1t\\u00e9\",\"lastName\":\"Lengyel\"},{\"creatorType\":\"editor\",\"firstName\":\"Konrad P.\",\"lastName\":\"Kording\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"PLOS Computational Biology\"},{\"title\":\"A Hierarchical Model of Binocular Rivalry\",\"year\":\"1998\",\"author\":[{\"creatorType\":\"author\",\"firstName\":\"Peter\",\"lastName\":\"Dayan\"}],\"topic\":\"Neural Variability\",\"notes\":\"\",\"publicationTitle\":\"Neural Computation\"}]"
